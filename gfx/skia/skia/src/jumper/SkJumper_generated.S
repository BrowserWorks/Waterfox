# Copyright 2017 Google Inc.
#
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# This file is generated semi-automatically with this command:
#   $ src/jumper/build_stages.py

#if defined(__MACH__)
    #define HIDDEN .private_extern
#else
    #define HIDDEN .hidden
    .section .note.GNU-stack,"",%progbits
#endif
.text
#if defined(__aarch64__)
.balign 4

HIDDEN _sk_start_pipeline_aarch64
.globl _sk_start_pipeline_aarch64
_sk_start_pipeline_aarch64:
  .long  0xa9bd5bf7                          // stp           x23, x22, [sp, #-48]!
  .long  0xa90153f5                          // stp           x21, x20, [sp, #16]
  .long  0xa9027bf3                          // stp           x19, x30, [sp, #32]
  .long  0xaa0103f4                          // mov           x20, x1
  .long  0xf8408697                          // ldr           x23, [x20], #8
  .long  0xaa0003f5                          // mov           x21, x0
  .long  0xaa0303f3                          // mov           x19, x3
  .long  0x910012a8                          // add           x8, x21, #0x4
  .long  0xeb13011f                          // cmp           x8, x19
  .long  0xaa0203f6                          // mov           x22, x2
  .long  0x54000069                          // b.ls          34 <sk_start_pipeline_aarch64+0x34>  // b.plast
  .long  0xaa1503e0                          // mov           x0, x21
  .long  0x14000012                          // b             78 <sk_start_pipeline_aarch64+0x78>
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0x6f00e403                          // movi          v3.2d, #0x0
  .long  0x6f00e404                          // movi          v4.2d, #0x0
  .long  0x6f00e405                          // movi          v5.2d, #0x0
  .long  0x6f00e406                          // movi          v6.2d, #0x0
  .long  0x6f00e407                          // movi          v7.2d, #0x0
  .long  0xaa1503e0                          // mov           x0, x21
  .long  0xaa1403e1                          // mov           x1, x20
  .long  0xaa1603e2                          // mov           x2, x22
  .long  0xd63f02e0                          // blr           x23
  .long  0x910012a0                          // add           x0, x21, #0x4
  .long  0x910022a8                          // add           x8, x21, #0x8
  .long  0xeb13011f                          // cmp           x8, x19
  .long  0xaa0003f5                          // mov           x21, x0
  .long  0x54fffe09                          // b.ls          34 <sk_start_pipeline_aarch64+0x34>  // b.plast
  .long  0xa9427bf3                          // ldp           x19, x30, [sp, #32]
  .long  0xa94153f5                          // ldp           x21, x20, [sp, #16]
  .long  0xa8c35bf7                          // ldp           x23, x22, [sp], #48
  .long  0xd65f03c0                          // ret

HIDDEN _sk_just_return_aarch64
.globl _sk_just_return_aarch64
_sk_just_return_aarch64:
  .long  0xd65f03c0                          // ret

HIDDEN _sk_seed_shader_aarch64
.globl _sk_seed_shader_aarch64
_sk_seed_shader_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x3dc00046                          // ldr           q6, [x2]
  .long  0x4e040c00                          // dup           v0.4s, w0
  .long  0x4f0167e7                          // movi          v7.4s, #0x3f, lsl #24
  .long  0x4d40c901                          // ld1r          {v1.4s}, [x8]
  .long  0x4e21d800                          // scvtf         v0.4s, v0.4s
  .long  0x4e27d400                          // fadd          v0.4s, v0.4s, v7.4s
  .long  0x4f03f602                          // fmov          v2.4s, #1.000000000000000000e+00
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x6f00e403                          // movi          v3.2d, #0x0
  .long  0x6f00e404                          // movi          v4.2d, #0x0
  .long  0x6f00e405                          // movi          v5.2d, #0x0
  .long  0x4e26d400                          // fadd          v0.4s, v0.4s, v6.4s
  .long  0x6f00e406                          // movi          v6.2d, #0x0
  .long  0x4e27d421                          // fadd          v1.4s, v1.4s, v7.4s
  .long  0x6f00e407                          // movi          v7.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_constant_color_aarch64
.globl _sk_constant_color_aarch64
_sk_constant_color_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803ea                          // mov           x10, x8
  .long  0x4ddfc940                          // ld1r          {v0.4s}, [x10], #4
  .long  0x91002109                          // add           x9, x8, #0x8
  .long  0x91003108                          // add           x8, x8, #0xc
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0x4d40c903                          // ld1r          {v3.4s}, [x8]
  .long  0x4d40c941                          // ld1r          {v1.4s}, [x10]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clear_aarch64
.globl _sk_clear_aarch64
_sk_clear_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0x6f00e403                          // movi          v3.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcatop_aarch64
.globl _sk_srcatop_aarch64
_sk_srcatop_aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x6e27dc00                          // fmul          v0.4s, v0.4s, v7.4s
  .long  0x6e27dc21                          // fmul          v1.4s, v1.4s, v7.4s
  .long  0x6e27dc42                          // fmul          v2.4s, v2.4s, v7.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccc2                          // fmla          v2.4s, v6.4s, v16.4s
  .long  0x6e27de10                          // fmul          v16.4s, v16.4s, v7.4s
  .long  0x4e23ccf0                          // fmla          v16.4s, v7.4s, v3.4s
  .long  0x4eb01e03                          // mov           v3.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstatop_aarch64
.globl _sk_dstatop_aarch64
_sk_dstatop_aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea7d610                          // fsub          v16.4s, v16.4s, v7.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6e23de10                          // fmul          v16.4s, v16.4s, v3.4s
  .long  0x4e23ccf0                          // fmla          v16.4s, v7.4s, v3.4s
  .long  0x4e23cc80                          // fmla          v0.4s, v4.4s, v3.4s
  .long  0x4e23cca1                          // fmla          v1.4s, v5.4s, v3.4s
  .long  0x4e23ccc2                          // fmla          v2.4s, v6.4s, v3.4s
  .long  0x4eb01e03                          // mov           v3.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcin_aarch64
.globl _sk_srcin_aarch64
_sk_srcin_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e27dc00                          // fmul          v0.4s, v0.4s, v7.4s
  .long  0x6e27dc21                          // fmul          v1.4s, v1.4s, v7.4s
  .long  0x6e27dc42                          // fmul          v2.4s, v2.4s, v7.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstin_aarch64
.globl _sk_dstin_aarch64
_sk_dstin_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e24dc60                          // fmul          v0.4s, v3.4s, v4.4s
  .long  0x6e25dc61                          // fmul          v1.4s, v3.4s, v5.4s
  .long  0x6e26dc62                          // fmul          v2.4s, v3.4s, v6.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcout_aarch64
.globl _sk_srcout_aarch64
_sk_srcout_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea7d610                          // fsub          v16.4s, v16.4s, v7.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstout_aarch64
.globl _sk_dstout_aarch64
_sk_dstout_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f600                          // fmov          v0.4s, #1.000000000000000000e+00
  .long  0x4ea3d403                          // fsub          v3.4s, v0.4s, v3.4s
  .long  0x6e24dc60                          // fmul          v0.4s, v3.4s, v4.4s
  .long  0x6e25dc61                          // fmul          v1.4s, v3.4s, v5.4s
  .long  0x6e26dc62                          // fmul          v2.4s, v3.4s, v6.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcover_aarch64
.globl _sk_srcover_aarch64
_sk_srcover_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4e24ce00                          // fmla          v0.4s, v16.4s, v4.4s
  .long  0x4e25ce01                          // fmla          v1.4s, v16.4s, v5.4s
  .long  0x4e26ce02                          // fmla          v2.4s, v16.4s, v6.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstover_aarch64
.globl _sk_dstover_aarch64
_sk_dstover_aarch64:
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea41c90                          // mov           v16.16b, v4.16b
  .long  0x4ea7d634                          // fsub          v20.4s, v17.4s, v7.4s
  .long  0x4ea51cb1                          // mov           v17.16b, v5.16b
  .long  0x4ea61cd2                          // mov           v18.16b, v6.16b
  .long  0x4ea71cf3                          // mov           v19.16b, v7.16b
  .long  0x4e20ce90                          // fmla          v16.4s, v20.4s, v0.4s
  .long  0x4e21ce91                          // fmla          v17.4s, v20.4s, v1.4s
  .long  0x4e22ce92                          // fmla          v18.4s, v20.4s, v2.4s
  .long  0x4e23ce93                          // fmla          v19.4s, v20.4s, v3.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_modulate_aarch64
.globl _sk_modulate_aarch64
_sk_modulate_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e24dc00                          // fmul          v0.4s, v0.4s, v4.4s
  .long  0x6e25dc21                          // fmul          v1.4s, v1.4s, v5.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_multiply_aarch64
.globl _sk_multiply_aarch64
_sk_multiply_aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea7d613                          // fsub          v19.4s, v16.4s, v7.4s
  .long  0x4ea3d614                          // fsub          v20.4s, v16.4s, v3.4s
  .long  0x6e20de70                          // fmul          v16.4s, v19.4s, v0.4s
  .long  0x6e21de71                          // fmul          v17.4s, v19.4s, v1.4s
  .long  0x6e22de72                          // fmul          v18.4s, v19.4s, v2.4s
  .long  0x6e23de73                          // fmul          v19.4s, v19.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e34cc90                          // fmla          v16.4s, v4.4s, v20.4s
  .long  0x4e34ccb1                          // fmla          v17.4s, v5.4s, v20.4s
  .long  0x4e34ccd2                          // fmla          v18.4s, v6.4s, v20.4s
  .long  0x4e34ccf3                          // fmla          v19.4s, v7.4s, v20.4s
  .long  0x4e20cc90                          // fmla          v16.4s, v4.4s, v0.4s
  .long  0x4e21ccb1                          // fmla          v17.4s, v5.4s, v1.4s
  .long  0x4e22ccd2                          // fmla          v18.4s, v6.4s, v2.4s
  .long  0x4e23ccf3                          // fmla          v19.4s, v7.4s, v3.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_plus__aarch64
.globl _sk_plus__aarch64
_sk_plus__aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4e27d463                          // fadd          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_screen_aarch64
.globl _sk_screen_aarch64
_sk_screen_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e24d410                          // fadd          v16.4s, v0.4s, v4.4s
  .long  0x4e25d431                          // fadd          v17.4s, v1.4s, v5.4s
  .long  0x4e26d452                          // fadd          v18.4s, v2.4s, v6.4s
  .long  0x4e27d473                          // fadd          v19.4s, v3.4s, v7.4s
  .long  0x4ea4cc10                          // fmls          v16.4s, v0.4s, v4.4s
  .long  0x4ea5cc31                          // fmls          v17.4s, v1.4s, v5.4s
  .long  0x4ea6cc52                          // fmls          v18.4s, v2.4s, v6.4s
  .long  0x4ea7cc73                          // fmls          v19.4s, v3.4s, v7.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_xor__aarch64
.globl _sk_xor__aarch64
_sk_xor__aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea7d611                          // fsub          v17.4s, v16.4s, v7.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x6e20de20                          // fmul          v0.4s, v17.4s, v0.4s
  .long  0x6e21de21                          // fmul          v1.4s, v17.4s, v1.4s
  .long  0x6e22de22                          // fmul          v2.4s, v17.4s, v2.4s
  .long  0x6e23de23                          // fmul          v3.4s, v17.4s, v3.4s
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccc2                          // fmla          v2.4s, v6.4s, v16.4s
  .long  0x4e30cce3                          // fmla          v3.4s, v7.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_darken_aarch64
.globl _sk_darken_aarch64
_sk_darken_aarch64:
  .long  0x6e27dc10                          // fmul          v16.4s, v0.4s, v7.4s
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x6e27dc32                          // fmul          v18.4s, v1.4s, v7.4s
  .long  0x6e25dc73                          // fmul          v19.4s, v3.4s, v5.4s
  .long  0x4e31f610                          // fmax          v16.4s, v16.4s, v17.4s
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e27dc51                          // fmul          v17.4s, v2.4s, v7.4s
  .long  0x4e33f652                          // fmax          v18.4s, v18.4s, v19.4s
  .long  0x6e26dc73                          // fmul          v19.4s, v3.4s, v6.4s
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4e33f631                          // fmax          v17.4s, v17.4s, v19.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4eb2d421                          // fsub          v1.4s, v1.4s, v18.4s
  .long  0x4eb1d442                          // fsub          v2.4s, v2.4s, v17.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lighten_aarch64
.globl _sk_lighten_aarch64
_sk_lighten_aarch64:
  .long  0x6e27dc10                          // fmul          v16.4s, v0.4s, v7.4s
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x6e27dc32                          // fmul          v18.4s, v1.4s, v7.4s
  .long  0x6e25dc73                          // fmul          v19.4s, v3.4s, v5.4s
  .long  0x4eb1f610                          // fmin          v16.4s, v16.4s, v17.4s
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e27dc51                          // fmul          v17.4s, v2.4s, v7.4s
  .long  0x4eb3f652                          // fmin          v18.4s, v18.4s, v19.4s
  .long  0x6e26dc73                          // fmul          v19.4s, v3.4s, v6.4s
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4eb3f631                          // fmin          v17.4s, v17.4s, v19.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4eb2d421                          // fsub          v1.4s, v1.4s, v18.4s
  .long  0x4eb1d442                          // fsub          v2.4s, v2.4s, v17.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_difference_aarch64
.globl _sk_difference_aarch64
_sk_difference_aarch64:
  .long  0x6e27dc10                          // fmul          v16.4s, v0.4s, v7.4s
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x6e27dc32                          // fmul          v18.4s, v1.4s, v7.4s
  .long  0x6e25dc73                          // fmul          v19.4s, v3.4s, v5.4s
  .long  0x4eb1f610                          // fmin          v16.4s, v16.4s, v17.4s
  .long  0x4eb3f652                          // fmin          v18.4s, v18.4s, v19.4s
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0x4e30d610                          // fadd          v16.4s, v16.4s, v16.4s
  .long  0x6e27dc51                          // fmul          v17.4s, v2.4s, v7.4s
  .long  0x6e26dc73                          // fmul          v19.4s, v3.4s, v6.4s
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e32d650                          // fadd          v16.4s, v18.4s, v18.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4eb3f631                          // fmin          v17.4s, v17.4s, v19.4s
  .long  0x4eb0d421                          // fsub          v1.4s, v1.4s, v16.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4e31d631                          // fadd          v17.4s, v17.4s, v17.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4eb1d442                          // fsub          v2.4s, v2.4s, v17.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_exclusion_aarch64
.globl _sk_exclusion_aarch64
_sk_exclusion_aarch64:
  .long  0x4e24d410                          // fadd          v16.4s, v0.4s, v4.4s
  .long  0x6e24dc00                          // fmul          v0.4s, v0.4s, v4.4s
  .long  0x4e20d400                          // fadd          v0.4s, v0.4s, v0.4s
  .long  0x4ea0d600                          // fsub          v0.4s, v16.4s, v0.4s
  .long  0x4e25d430                          // fadd          v16.4s, v1.4s, v5.4s
  .long  0x6e25dc21                          // fmul          v1.4s, v1.4s, v5.4s
  .long  0x4e21d421                          // fadd          v1.4s, v1.4s, v1.4s
  .long  0x4ea1d601                          // fsub          v1.4s, v16.4s, v1.4s
  .long  0x4e26d450                          // fadd          v16.4s, v2.4s, v6.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0x4e22d442                          // fadd          v2.4s, v2.4s, v2.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea2d602                          // fsub          v2.4s, v16.4s, v2.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_colorburn_aarch64
.globl _sk_colorburn_aarch64
_sk_colorburn_aarch64:
  .long  0x4ea4d4f3                          // fsub          v19.4s, v7.4s, v4.4s
  .long  0x6e23de73                          // fmul          v19.4s, v19.4s, v3.4s
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x6e20fe73                          // fdiv          v19.4s, v19.4s, v0.4s
  .long  0x4ea7d634                          // fsub          v20.4s, v17.4s, v7.4s
  .long  0x4eb3f4f3                          // fmin          v19.4s, v7.4s, v19.4s
  .long  0x6e20de95                          // fmul          v21.4s, v20.4s, v0.4s
  .long  0x4eb3d4f3                          // fsub          v19.4s, v7.4s, v19.4s
  .long  0x4e24d6b6                          // fadd          v22.4s, v21.4s, v4.4s
  .long  0x4e33cc75                          // fmla          v21.4s, v3.4s, v19.4s
  .long  0x4ea5d4f3                          // fsub          v19.4s, v7.4s, v5.4s
  .long  0x6e23de73                          // fmul          v19.4s, v19.4s, v3.4s
  .long  0x6e21fe73                          // fdiv          v19.4s, v19.4s, v1.4s
  .long  0x4ea0d812                          // fcmeq         v18.4s, v0.4s, #0.0
  .long  0x4eb3f4f3                          // fmin          v19.4s, v7.4s, v19.4s
  .long  0x6e751c12                          // bsl           v18.16b, v0.16b, v21.16b
  .long  0x6e21de80                          // fmul          v0.4s, v20.4s, v1.4s
  .long  0x4eb3d4f3                          // fsub          v19.4s, v7.4s, v19.4s
  .long  0x4e25d415                          // fadd          v21.4s, v0.4s, v5.4s
  .long  0x4e33cc60                          // fmla          v0.4s, v3.4s, v19.4s
  .long  0x4ea0d833                          // fcmeq         v19.4s, v1.4s, #0.0
  .long  0x6e601c33                          // bsl           v19.16b, v1.16b, v0.16b
  .long  0x4ea6d4e0                          // fsub          v0.4s, v7.4s, v6.4s
  .long  0x6e23dc00                          // fmul          v0.4s, v0.4s, v3.4s
  .long  0x6e22fc00                          // fdiv          v0.4s, v0.4s, v2.4s
  .long  0x4ea0f4e0                          // fmin          v0.4s, v7.4s, v0.4s
  .long  0x6e22de81                          // fmul          v1.4s, v20.4s, v2.4s
  .long  0x4ea0d4e0                          // fsub          v0.4s, v7.4s, v0.4s
  .long  0x4e26d434                          // fadd          v20.4s, v1.4s, v6.4s
  .long  0x4e20cc61                          // fmla          v1.4s, v3.4s, v0.4s
  .long  0x4ea0d840                          // fcmeq         v0.4s, v2.4s, #0.0
  .long  0x4ea3d631                          // fsub          v17.4s, v17.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e27e490                          // fcmeq         v16.4s, v4.4s, v7.4s
  .long  0x6e611c40                          // bsl           v0.16b, v2.16b, v1.16b
  .long  0x4e31cc92                          // fmla          v18.4s, v4.4s, v17.4s
  .long  0x4e27e4a1                          // fcmeq         v1.4s, v5.4s, v7.4s
  .long  0x4e27e4c2                          // fcmeq         v2.4s, v6.4s, v7.4s
  .long  0x4e31ccb3                          // fmla          v19.4s, v5.4s, v17.4s
  .long  0x4e31ccc0                          // fmla          v0.4s, v6.4s, v17.4s
  .long  0x6e721ed0                          // bsl           v16.16b, v22.16b, v18.16b
  .long  0x6e731ea1                          // bsl           v1.16b, v21.16b, v19.16b
  .long  0x6e601e82                          // bsl           v2.16b, v20.16b, v0.16b
  .long  0x4e27ce23                          // fmla          v3.4s, v17.4s, v7.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_colordodge_aarch64
.globl _sk_colordodge_aarch64
_sk_colordodge_aarch64:
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x4ea0d474                          // fsub          v20.4s, v3.4s, v0.4s
  .long  0x6e25dc75                          // fmul          v21.4s, v3.4s, v5.4s
  .long  0x4ea1d476                          // fsub          v22.4s, v3.4s, v1.4s
  .long  0x4ea7d657                          // fsub          v23.4s, v18.4s, v7.4s
  .long  0x6e34fe31                          // fdiv          v17.4s, v17.4s, v20.4s
  .long  0x6e36feb4                          // fdiv          v20.4s, v21.4s, v22.4s
  .long  0x6e20def5                          // fmul          v21.4s, v23.4s, v0.4s
  .long  0x4eb1f4f1                          // fmin          v17.4s, v7.4s, v17.4s
  .long  0x4e23e413                          // fcmeq         v19.4s, v0.4s, v3.4s
  .long  0x4e24d6b6                          // fadd          v22.4s, v21.4s, v4.4s
  .long  0x4e31cc75                          // fmla          v21.4s, v3.4s, v17.4s
  .long  0x6e751c13                          // bsl           v19.16b, v0.16b, v21.16b
  .long  0x6e21dee0                          // fmul          v0.4s, v23.4s, v1.4s
  .long  0x4eb4f4f4                          // fmin          v20.4s, v7.4s, v20.4s
  .long  0x4e25d415                          // fadd          v21.4s, v0.4s, v5.4s
  .long  0x4e34cc60                          // fmla          v0.4s, v3.4s, v20.4s
  .long  0x4e23e434                          // fcmeq         v20.4s, v1.4s, v3.4s
  .long  0x6e601c34                          // bsl           v20.16b, v1.16b, v0.16b
  .long  0x6e26dc60                          // fmul          v0.4s, v3.4s, v6.4s
  .long  0x4ea2d461                          // fsub          v1.4s, v3.4s, v2.4s
  .long  0x6e21fc00                          // fdiv          v0.4s, v0.4s, v1.4s
  .long  0x6e22dee1                          // fmul          v1.4s, v23.4s, v2.4s
  .long  0x4ea0f4e0                          // fmin          v0.4s, v7.4s, v0.4s
  .long  0x4e26d437                          // fadd          v23.4s, v1.4s, v6.4s
  .long  0x4e20cc61                          // fmla          v1.4s, v3.4s, v0.4s
  .long  0x4e23e440                          // fcmeq         v0.4s, v2.4s, v3.4s
  .long  0x6e611c40                          // bsl           v0.16b, v2.16b, v1.16b
  .long  0x4ea3d641                          // fsub          v1.4s, v18.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea0d890                          // fcmeq         v16.4s, v4.4s, #0.0
  .long  0x4ea0d8b1                          // fcmeq         v17.4s, v5.4s, #0.0
  .long  0x4e21cc93                          // fmla          v19.4s, v4.4s, v1.4s
  .long  0x4e21ccb4                          // fmla          v20.4s, v5.4s, v1.4s
  .long  0x4ea0d8c2                          // fcmeq         v2.4s, v6.4s, #0.0
  .long  0x4e21ccc0                          // fmla          v0.4s, v6.4s, v1.4s
  .long  0x6e731ed0                          // bsl           v16.16b, v22.16b, v19.16b
  .long  0x6e741eb1                          // bsl           v17.16b, v21.16b, v20.16b
  .long  0x6e601ee2                          // bsl           v2.16b, v23.16b, v0.16b
  .long  0x4e27cc23                          // fmla          v3.4s, v1.4s, v7.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_hardlight_aarch64
.globl _sk_hardlight_aarch64
_sk_hardlight_aarch64:
  .long  0x4ea4d4f4                          // fsub          v20.4s, v7.4s, v4.4s
  .long  0x4ea0d475                          // fsub          v21.4s, v3.4s, v0.4s
  .long  0x6e34deb4                          // fmul          v20.4s, v21.4s, v20.4s
  .long  0x4e20d411                          // fadd          v17.4s, v0.4s, v0.4s
  .long  0x6e24dc12                          // fmul          v18.4s, v0.4s, v4.4s
  .long  0x6e27dc73                          // fmul          v19.4s, v3.4s, v7.4s
  .long  0x4e34d694                          // fadd          v20.4s, v20.4s, v20.4s
  .long  0x6e31e471                          // fcmge         v17.4s, v3.4s, v17.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4eb4d674                          // fsub          v20.4s, v19.4s, v20.4s
  .long  0x6e741e51                          // bsl           v17.16b, v18.16b, v20.16b
  .long  0x4ea5d4f2                          // fsub          v18.4s, v7.4s, v5.4s
  .long  0x4ea1d474                          // fsub          v20.4s, v3.4s, v1.4s
  .long  0x6e32de92                          // fmul          v18.4s, v20.4s, v18.4s
  .long  0x4e21d436                          // fadd          v22.4s, v1.4s, v1.4s
  .long  0x6e25dc35                          // fmul          v21.4s, v1.4s, v5.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x6e36e476                          // fcmge         v22.4s, v3.4s, v22.4s
  .long  0x4e35d6b5                          // fadd          v21.4s, v21.4s, v21.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x6e721eb6                          // bsl           v22.16b, v21.16b, v18.16b
  .long  0x4ea6d4f2                          // fsub          v18.4s, v7.4s, v6.4s
  .long  0x4ea2d475                          // fsub          v21.4s, v3.4s, v2.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x4ea7d615                          // fsub          v21.4s, v16.4s, v7.4s
  .long  0x4e22d454                          // fadd          v20.4s, v2.4s, v2.4s
  .long  0x6e20dea0                          // fmul          v0.4s, v21.4s, v0.4s
  .long  0x6e21dea1                          // fmul          v1.4s, v21.4s, v1.4s
  .long  0x6e22deb5                          // fmul          v21.4s, v21.4s, v2.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x6e34e474                          // fcmge         v20.4s, v3.4s, v20.4s
  .long  0x4e22d442                          // fadd          v2.4s, v2.4s, v2.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccd5                          // fmla          v21.4s, v6.4s, v16.4s
  .long  0x6e721c54                          // bsl           v20.16b, v2.16b, v18.16b
  .long  0x4e31d400                          // fadd          v0.4s, v0.4s, v17.4s
  .long  0x4e36d421                          // fadd          v1.4s, v1.4s, v22.4s
  .long  0x4e34d6a2                          // fadd          v2.4s, v21.4s, v20.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_overlay_aarch64
.globl _sk_overlay_aarch64
_sk_overlay_aarch64:
  .long  0x4ea4d4f4                          // fsub          v20.4s, v7.4s, v4.4s
  .long  0x4ea0d475                          // fsub          v21.4s, v3.4s, v0.4s
  .long  0x6e34deb4                          // fmul          v20.4s, v21.4s, v20.4s
  .long  0x4e24d491                          // fadd          v17.4s, v4.4s, v4.4s
  .long  0x6e24dc12                          // fmul          v18.4s, v0.4s, v4.4s
  .long  0x6e27dc73                          // fmul          v19.4s, v3.4s, v7.4s
  .long  0x4e34d694                          // fadd          v20.4s, v20.4s, v20.4s
  .long  0x6e31e4f1                          // fcmge         v17.4s, v7.4s, v17.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4eb4d674                          // fsub          v20.4s, v19.4s, v20.4s
  .long  0x6e741e51                          // bsl           v17.16b, v18.16b, v20.16b
  .long  0x4ea5d4f2                          // fsub          v18.4s, v7.4s, v5.4s
  .long  0x4ea1d474                          // fsub          v20.4s, v3.4s, v1.4s
  .long  0x6e32de92                          // fmul          v18.4s, v20.4s, v18.4s
  .long  0x4e25d4b6                          // fadd          v22.4s, v5.4s, v5.4s
  .long  0x6e25dc35                          // fmul          v21.4s, v1.4s, v5.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x6e36e4f6                          // fcmge         v22.4s, v7.4s, v22.4s
  .long  0x4e35d6b5                          // fadd          v21.4s, v21.4s, v21.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x6e721eb6                          // bsl           v22.16b, v21.16b, v18.16b
  .long  0x4ea6d4f2                          // fsub          v18.4s, v7.4s, v6.4s
  .long  0x4ea2d475                          // fsub          v21.4s, v3.4s, v2.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x4ea7d615                          // fsub          v21.4s, v16.4s, v7.4s
  .long  0x4e26d4d4                          // fadd          v20.4s, v6.4s, v6.4s
  .long  0x6e20dea0                          // fmul          v0.4s, v21.4s, v0.4s
  .long  0x6e21dea1                          // fmul          v1.4s, v21.4s, v1.4s
  .long  0x6e22deb5                          // fmul          v21.4s, v21.4s, v2.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x6e34e4f4                          // fcmge         v20.4s, v7.4s, v20.4s
  .long  0x4e22d442                          // fadd          v2.4s, v2.4s, v2.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccd5                          // fmla          v21.4s, v6.4s, v16.4s
  .long  0x6e721c54                          // bsl           v20.16b, v2.16b, v18.16b
  .long  0x4e31d400                          // fadd          v0.4s, v0.4s, v17.4s
  .long  0x4e36d421                          // fadd          v1.4s, v1.4s, v22.4s
  .long  0x4e34d6a2                          // fadd          v2.4s, v21.4s, v20.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_softlight_aarch64
.globl _sk_softlight_aarch64
_sk_softlight_aarch64:
  .long  0x4ea0c8f5                          // fcmgt         v21.4s, v7.4s, #0.0
  .long  0x6e27fc96                          // fdiv          v22.4s, v4.4s, v7.4s
  .long  0x6e27fcb8                          // fdiv          v24.4s, v5.4s, v7.4s
  .long  0x6e27fcd9                          // fdiv          v25.4s, v6.4s, v7.4s
  .long  0x4e351ed6                          // and           v22.16b, v22.16b, v21.16b
  .long  0x4e351f18                          // and           v24.16b, v24.16b, v21.16b
  .long  0x4e351f35                          // and           v21.16b, v25.16b, v21.16b
  .long  0x6ea1dad9                          // frsqrte       v25.4s, v22.4s
  .long  0x6e39df3d                          // fmul          v29.4s, v25.4s, v25.4s
  .long  0x4ebdfedd                          // frsqrts       v29.4s, v22.4s, v29.4s
  .long  0x6e3ddf39                          // fmul          v25.4s, v25.4s, v29.4s
  .long  0x4ea1db3d                          // frecpe        v29.4s, v25.4s
  .long  0x6ea0fada                          // fneg          v26.4s, v22.4s
  .long  0x6ea1db1b                          // frsqrte       v27.4s, v24.4s
  .long  0x4e3dff39                          // frecps        v25.4s, v25.4s, v29.4s
  .long  0x4e3dcf3a                          // fmla          v26.4s, v25.4s, v29.4s
  .long  0x6e3bdf7d                          // fmul          v29.4s, v27.4s, v27.4s
  .long  0x4ebdff1d                          // frsqrts       v29.4s, v24.4s, v29.4s
  .long  0x6e3ddf7b                          // fmul          v27.4s, v27.4s, v29.4s
  .long  0x4ea1db7d                          // frecpe        v29.4s, v27.4s
  .long  0x6ea0fb1c                          // fneg          v28.4s, v24.4s
  .long  0x6ea1dab9                          // frsqrte       v25.4s, v21.4s
  .long  0x4e3dff7b                          // frecps        v27.4s, v27.4s, v29.4s
  .long  0x4e3dcf7c                          // fmla          v28.4s, v27.4s, v29.4s
  .long  0x6e39df3d                          // fmul          v29.4s, v25.4s, v25.4s
  .long  0x4ebdfebd                          // frsqrts       v29.4s, v21.4s, v29.4s
  .long  0x6e3ddf39                          // fmul          v25.4s, v25.4s, v29.4s
  .long  0x4ea1db3d                          // frecpe        v29.4s, v25.4s
  .long  0x6ea0fabb                          // fneg          v27.4s, v21.4s
  .long  0x4e3dff39                          // frecps        v25.4s, v25.4s, v29.4s
  .long  0x4e3dcf3b                          // fmla          v27.4s, v25.4s, v29.4s
  .long  0x4e36d6d9                          // fadd          v25.4s, v22.4s, v22.4s
  .long  0x4f07f613                          // fmov          v19.4s, #-1.000000000000000000e+00
  .long  0x4e39d739                          // fadd          v25.4s, v25.4s, v25.4s
  .long  0x4e24d497                          // fadd          v23.4s, v4.4s, v4.4s
  .long  0x4e33d6dd                          // fadd          v29.4s, v22.4s, v19.4s
  .long  0x4e39cf39                          // fmla          v25.4s, v25.4s, v25.4s
  .long  0x4f00f794                          // fmov          v20.4s, #7.000000000000000000e+00
  .long  0x6e39dfb9                          // fmul          v25.4s, v29.4s, v25.4s
  .long  0x4e37d6f7                          // fadd          v23.4s, v23.4s, v23.4s
  .long  0x6e37e4f7                          // fcmge         v23.4s, v7.4s, v23.4s
  .long  0x4e36ce99                          // fmla          v25.4s, v20.4s, v22.4s
  .long  0x6e7a1f37                          // bsl           v23.16b, v25.16b, v26.16b
  .long  0x4e38d719                          // fadd          v25.4s, v24.4s, v24.4s
  .long  0x4e39d739                          // fadd          v25.4s, v25.4s, v25.4s
  .long  0x4e33d71a                          // fadd          v26.4s, v24.4s, v19.4s
  .long  0x4e39cf39                          // fmla          v25.4s, v25.4s, v25.4s
  .long  0x6e39df59                          // fmul          v25.4s, v26.4s, v25.4s
  .long  0x4e25d4ba                          // fadd          v26.4s, v5.4s, v5.4s
  .long  0x4e3ad75a                          // fadd          v26.4s, v26.4s, v26.4s
  .long  0x6e3ae4fa                          // fcmge         v26.4s, v7.4s, v26.4s
  .long  0x4e38ce99                          // fmla          v25.4s, v20.4s, v24.4s
  .long  0x6e7c1f3a                          // bsl           v26.16b, v25.16b, v28.16b
  .long  0x4e35d6bc                          // fadd          v28.4s, v21.4s, v21.4s
  .long  0x4e3cd79c                          // fadd          v28.4s, v28.4s, v28.4s
  .long  0x4e33d6b3                          // fadd          v19.4s, v21.4s, v19.4s
  .long  0x4e3ccf9c                          // fmla          v28.4s, v28.4s, v28.4s
  .long  0x6e3cde73                          // fmul          v19.4s, v19.4s, v28.4s
  .long  0x4e35ce93                          // fmla          v19.4s, v20.4s, v21.4s
  .long  0x4e26d4d4                          // fadd          v20.4s, v6.4s, v6.4s
  .long  0x4e34d694                          // fadd          v20.4s, v20.4s, v20.4s
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x6e34e4f4                          // fcmge         v20.4s, v7.4s, v20.4s
  .long  0x4e20d411                          // fadd          v17.4s, v0.4s, v0.4s
  .long  0x6e7b1e74                          // bsl           v20.16b, v19.16b, v27.16b
  .long  0x4ea7d65b                          // fsub          v27.4s, v18.4s, v7.4s
  .long  0x4ea31c70                          // mov           v16.16b, v3.16b
  .long  0x4e21d43d                          // fadd          v29.4s, v1.4s, v1.4s
  .long  0x4e22d45c                          // fadd          v28.4s, v2.4s, v2.4s
  .long  0x6e20df60                          // fmul          v0.4s, v27.4s, v0.4s
  .long  0x6e21df61                          // fmul          v1.4s, v27.4s, v1.4s
  .long  0x6e22df62                          // fmul          v2.4s, v27.4s, v2.4s
  .long  0x4ea3d63b                          // fsub          v27.4s, v17.4s, v3.4s
  .long  0x4eb6d656                          // fsub          v22.4s, v18.4s, v22.4s
  .long  0x4ea31c79                          // mov           v25.16b, v3.16b
  .long  0x4e3bced0                          // fmla          v16.4s, v22.4s, v27.4s
  .long  0x4ea3d7b6                          // fsub          v22.4s, v29.4s, v3.4s
  .long  0x4eb8d658                          // fsub          v24.4s, v18.4s, v24.4s
  .long  0x4ea31c73                          // mov           v19.16b, v3.16b
  .long  0x4e36cf19                          // fmla          v25.4s, v24.4s, v22.4s
  .long  0x4ea3d798                          // fsub          v24.4s, v28.4s, v3.4s
  .long  0x4eb5d655                          // fsub          v21.4s, v18.4s, v21.4s
  .long  0x4e38ceb3                          // fmla          v19.4s, v21.4s, v24.4s
  .long  0x6e27df7b                          // fmul          v27.4s, v27.4s, v7.4s
  .long  0x6e27ded6                          // fmul          v22.4s, v22.4s, v7.4s
  .long  0x6e27df18                          // fmul          v24.4s, v24.4s, v7.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e37df77                          // fmul          v23.4s, v27.4s, v23.4s
  .long  0x6e3aded6                          // fmul          v22.4s, v22.4s, v26.4s
  .long  0x6e34df14                          // fmul          v20.4s, v24.4s, v20.4s
  .long  0x4ea3d652                          // fsub          v18.4s, v18.4s, v3.4s
  .long  0x6e31e471                          // fcmge         v17.4s, v3.4s, v17.4s
  .long  0x6e3de475                          // fcmge         v21.4s, v3.4s, v29.4s
  .long  0x6e3ce47c                          // fcmge         v28.4s, v3.4s, v28.4s
  .long  0x6e24de10                          // fmul          v16.4s, v16.4s, v4.4s
  .long  0x6e25df39                          // fmul          v25.4s, v25.4s, v5.4s
  .long  0x6e26de73                          // fmul          v19.4s, v19.4s, v6.4s
  .long  0x4e23cc97                          // fmla          v23.4s, v4.4s, v3.4s
  .long  0x4e23ccb6                          // fmla          v22.4s, v5.4s, v3.4s
  .long  0x4e23ccd4                          // fmla          v20.4s, v6.4s, v3.4s
  .long  0x4e32cc80                          // fmla          v0.4s, v4.4s, v18.4s
  .long  0x4e32cca1                          // fmla          v1.4s, v5.4s, v18.4s
  .long  0x4e32ccc2                          // fmla          v2.4s, v6.4s, v18.4s
  .long  0x6e771e11                          // bsl           v17.16b, v16.16b, v23.16b
  .long  0x6e761f35                          // bsl           v21.16b, v25.16b, v22.16b
  .long  0x6e741e7c                          // bsl           v28.16b, v19.16b, v20.16b
  .long  0x4e31d400                          // fadd          v0.4s, v0.4s, v17.4s
  .long  0x4e35d421                          // fadd          v1.4s, v1.4s, v21.4s
  .long  0x4e3cd442                          // fadd          v2.4s, v2.4s, v28.4s
  .long  0x4e27ce43                          // fmla          v3.4s, v18.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_0_aarch64
.globl _sk_clamp_0_aarch64
_sk_clamp_0_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6f00e410                          // movi          v16.2d, #0x0
  .long  0x4e30f400                          // fmax          v0.4s, v0.4s, v16.4s
  .long  0x4e30f421                          // fmax          v1.4s, v1.4s, v16.4s
  .long  0x4e30f442                          // fmax          v2.4s, v2.4s, v16.4s
  .long  0x4e30f463                          // fmax          v3.4s, v3.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_1_aarch64
.globl _sk_clamp_1_aarch64
_sk_clamp_1_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4eb0f400                          // fmin          v0.4s, v0.4s, v16.4s
  .long  0x4eb0f421                          // fmin          v1.4s, v1.4s, v16.4s
  .long  0x4eb0f442                          // fmin          v2.4s, v2.4s, v16.4s
  .long  0x4eb0f463                          // fmin          v3.4s, v3.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_a_aarch64
.globl _sk_clamp_a_aarch64
_sk_clamp_a_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4eb0f463                          // fmin          v3.4s, v3.4s, v16.4s
  .long  0x4ea3f400                          // fmin          v0.4s, v0.4s, v3.4s
  .long  0x4ea3f421                          // fmin          v1.4s, v1.4s, v3.4s
  .long  0x4ea3f442                          // fmin          v2.4s, v2.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_set_rgb_aarch64
.globl _sk_set_rgb_aarch64
_sk_set_rgb_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x4ddfc920                          // ld1r          {v0.4s}, [x9], #4
  .long  0x91002108                          // add           x8, x8, #0x8
  .long  0x4d40c902                          // ld1r          {v2.4s}, [x8]
  .long  0x4d40c921                          // ld1r          {v1.4s}, [x9]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_swap_rb_aarch64
.globl _sk_swap_rb_aarch64
_sk_swap_rb_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea01c10                          // mov           v16.16b, v0.16b
  .long  0x4ea21c40                          // mov           v0.16b, v2.16b
  .long  0x4eb01e02                          // mov           v2.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_swap_aarch64
.globl _sk_swap_aarch64
_sk_swap_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea31c70                          // mov           v16.16b, v3.16b
  .long  0x4ea21c51                          // mov           v17.16b, v2.16b
  .long  0x4ea11c32                          // mov           v18.16b, v1.16b
  .long  0x4ea01c13                          // mov           v19.16b, v0.16b
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0x4eb31e64                          // mov           v4.16b, v19.16b
  .long  0x4eb21e45                          // mov           v5.16b, v18.16b
  .long  0x4eb11e26                          // mov           v6.16b, v17.16b
  .long  0x4eb01e07                          // mov           v7.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_move_src_dst_aarch64
.globl _sk_move_src_dst_aarch64
_sk_move_src_dst_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea01c04                          // mov           v4.16b, v0.16b
  .long  0x4ea11c25                          // mov           v5.16b, v1.16b
  .long  0x4ea21c46                          // mov           v6.16b, v2.16b
  .long  0x4ea31c67                          // mov           v7.16b, v3.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_move_dst_src_aarch64
.globl _sk_move_dst_src_aarch64
_sk_move_dst_src_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_premul_aarch64
.globl _sk_premul_aarch64
_sk_premul_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e23dc00                          // fmul          v0.4s, v0.4s, v3.4s
  .long  0x6e23dc21                          // fmul          v1.4s, v1.4s, v3.4s
  .long  0x6e23dc42                          // fmul          v2.4s, v2.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_unpremul_aarch64
.globl _sk_unpremul_aarch64
_sk_unpremul_aarch64:
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea0d870                          // fcmeq         v16.4s, v3.4s, #0.0
  .long  0x6e23fe31                          // fdiv          v17.4s, v17.4s, v3.4s
  .long  0x4e701e30                          // bic           v16.16b, v17.16b, v16.16b
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_from_srgb_aarch64
.globl _sk_from_srgb_aarch64
_sk_from_srgb_aarch64:
  .long  0x52a7d328                          // mov           w8, #0x3e990000
  .long  0x72933348                          // movk          w8, #0x999a
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x52a7e648                          // mov           w8, #0x3f320000
  .long  0x7291eb88                          // movk          w8, #0x8f5c
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a76468                          // mov           w8, #0x3b230000
  .long  0x729ae148                          // movk          w8, #0xd70a
  .long  0x4e040d12                          // dup           v18.4s, w8
  .long  0x52a7b3c8                          // mov           w8, #0x3d9e0000
  .long  0x72907228                          // movk          w8, #0x8391
  .long  0x6e22dc54                          // fmul          v20.4s, v2.4s, v2.4s
  .long  0x4eb11e35                          // mov           v21.16b, v17.16b
  .long  0x4eb11e37                          // mov           v23.16b, v17.16b
  .long  0x4e22ce11                          // fmla          v17.4s, v16.4s, v2.4s
  .long  0x4eb21e56                          // mov           v22.16b, v18.16b
  .long  0x4eb21e58                          // mov           v24.16b, v18.16b
  .long  0x4e34ce32                          // fmla          v18.4s, v17.4s, v20.4s
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a7ac28                          // mov           w8, #0x3d610000
  .long  0x6e20dc13                          // fmul          v19.4s, v0.4s, v0.4s
  .long  0x7288f5c8                          // movk          w8, #0x47ae
  .long  0x4e20ce15                          // fmla          v21.4s, v16.4s, v0.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e21dc34                          // fmul          v20.4s, v1.4s, v1.4s
  .long  0x4e33ceb6                          // fmla          v22.4s, v21.4s, v19.4s
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x4e21ce17                          // fmla          v23.4s, v16.4s, v1.4s
  .long  0x6e31dc15                          // fmul          v21.4s, v0.4s, v17.4s
  .long  0x6ea0e660                          // fcmgt         v0.4s, v19.4s, v0.4s
  .long  0x6e31dc30                          // fmul          v16.4s, v1.4s, v17.4s
  .long  0x6ea1e661                          // fcmgt         v1.4s, v19.4s, v1.4s
  .long  0x6e31dc51                          // fmul          v17.4s, v2.4s, v17.4s
  .long  0x6ea2e662                          // fcmgt         v2.4s, v19.4s, v2.4s
  .long  0x4e34cef8                          // fmla          v24.4s, v23.4s, v20.4s
  .long  0x6e761ea0                          // bsl           v0.16b, v21.16b, v22.16b
  .long  0x6e781e01                          // bsl           v1.16b, v16.16b, v24.16b
  .long  0x6e721e22                          // bsl           v2.16b, v17.16b, v18.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_to_srgb_aarch64
.globl _sk_to_srgb_aarch64
_sk_to_srgb_aarch64:
  .long  0x52a828e8                          // mov           w8, #0x41470000
  .long  0x728b8528                          // movk          w8, #0x5c29
  .long  0x4e040d12                          // dup           v18.4s, w8
  .long  0x52a7e608                          // mov           w8, #0x3f300000
  .long  0x728df9c8                          // movk          w8, #0x6fce
  .long  0x6ea1d811                          // frsqrte       v17.4s, v0.4s
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x52b7b948                          // mov           w8, #0xbdca0000
  .long  0x728af508                          // movk          w8, #0x57a8
  .long  0x6ea1d834                          // frsqrte       v20.4s, v1.4s
  .long  0x6e31de36                          // fmul          v22.4s, v17.4s, v17.4s
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x52a77188                          // mov           w8, #0x3b8c0000
  .long  0x6ea1d855                          // frsqrte       v21.4s, v2.4s
  .long  0x6e34de98                          // fmul          v24.4s, v20.4s, v20.4s
  .long  0x4eb6fc16                          // frsqrts       v22.4s, v0.4s, v22.4s
  .long  0x729ce088                          // movk          w8, #0xe704
  .long  0x6e35deb9                          // fmul          v25.4s, v21.4s, v21.4s
  .long  0x4eb8fc38                          // frsqrts       v24.4s, v1.4s, v24.4s
  .long  0x6e36de31                          // fmul          v17.4s, v17.4s, v22.4s
  .long  0x4e040d17                          // dup           v23.4s, w8
  .long  0x4eb9fc59                          // frsqrts       v25.4s, v2.4s, v25.4s
  .long  0x6e38de94                          // fmul          v20.4s, v20.4s, v24.4s
  .long  0x4ea1da36                          // frecpe        v22.4s, v17.4s
  .long  0x6e32dc1a                          // fmul          v26.4s, v0.4s, v18.4s
  .long  0x6ea0e6e0                          // fcmgt         v0.4s, v23.4s, v0.4s
  .long  0x6e32dc3c                          // fmul          v28.4s, v1.4s, v18.4s
  .long  0x6ea1e6e1                          // fcmgt         v1.4s, v23.4s, v1.4s
  .long  0x6e32dc52                          // fmul          v18.4s, v2.4s, v18.4s
  .long  0x6ea2e6e2                          // fcmgt         v2.4s, v23.4s, v2.4s
  .long  0x6e39deb5                          // fmul          v21.4s, v21.4s, v25.4s
  .long  0x4ea1da97                          // frecpe        v23.4s, v20.4s
  .long  0x4e36fe39                          // frecps        v25.4s, v17.4s, v22.4s
  .long  0x4ea1dab8                          // frecpe        v24.4s, v21.4s
  .long  0x6e39ded6                          // fmul          v22.4s, v22.4s, v25.4s
  .long  0x4e37fe99                          // frecps        v25.4s, v20.4s, v23.4s
  .long  0x4eb01e1b                          // mov           v27.16b, v16.16b
  .long  0x6e39def7                          // fmul          v23.4s, v23.4s, v25.4s
  .long  0x4e38feb9                          // frecps        v25.4s, v21.4s, v24.4s
  .long  0x6e39df18                          // fmul          v24.4s, v24.4s, v25.4s
  .long  0x4eb01e19                          // mov           v25.16b, v16.16b
  .long  0x4e36ce7b                          // fmla          v27.4s, v19.4s, v22.4s
  .long  0x6ea1da36                          // frsqrte       v22.4s, v17.4s
  .long  0x4e37ce79                          // fmla          v25.4s, v19.4s, v23.4s
  .long  0x6ea1da97                          // frsqrte       v23.4s, v20.4s
  .long  0x4e38ce70                          // fmla          v16.4s, v19.4s, v24.4s
  .long  0x6e36ded8                          // fmul          v24.4s, v22.4s, v22.4s
  .long  0x6ea1dab3                          // frsqrte       v19.4s, v21.4s
  .long  0x4eb8fe31                          // frsqrts       v17.4s, v17.4s, v24.4s
  .long  0x6e37def8                          // fmul          v24.4s, v23.4s, v23.4s
  .long  0x4eb8fe94                          // frsqrts       v20.4s, v20.4s, v24.4s
  .long  0x6e33de78                          // fmul          v24.4s, v19.4s, v19.4s
  .long  0x52a7da48                          // mov           w8, #0x3ed20000
  .long  0x4eb8feb5                          // frsqrts       v21.4s, v21.4s, v24.4s
  .long  0x7290f848                          // movk          w8, #0x87c2
  .long  0x6e31ded1                          // fmul          v17.4s, v22.4s, v17.4s
  .long  0x6e34def4                          // fmul          v20.4s, v23.4s, v20.4s
  .long  0x6e35de73                          // fmul          v19.4s, v19.4s, v21.4s
  .long  0x4e040d15                          // dup           v21.4s, w8
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e31cebb                          // fmla          v27.4s, v21.4s, v17.4s
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x4e34ceb9                          // fmla          v25.4s, v21.4s, v20.4s
  .long  0x4e33ceb0                          // fmla          v16.4s, v21.4s, v19.4s
  .long  0x4ebbf633                          // fmin          v19.4s, v17.4s, v27.4s
  .long  0x4eb9f634                          // fmin          v20.4s, v17.4s, v25.4s
  .long  0x4eb0f630                          // fmin          v16.4s, v17.4s, v16.4s
  .long  0x6e731f40                          // bsl           v0.16b, v26.16b, v19.16b
  .long  0x6e741f81                          // bsl           v1.16b, v28.16b, v20.16b
  .long  0x6e701e42                          // bsl           v2.16b, v18.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_from_2dot2_aarch64
.globl _sk_from_2dot2_aarch64
_sk_from_2dot2_aarch64:
  .long  0x6ea1d810                          // frsqrte       v16.4s, v0.4s
  .long  0x6ea1d832                          // frsqrte       v18.4s, v1.4s
  .long  0x6e30de15                          // fmul          v21.4s, v16.4s, v16.4s
  .long  0x6e20dc11                          // fmul          v17.4s, v0.4s, v0.4s
  .long  0x6ea1d854                          // frsqrte       v20.4s, v2.4s
  .long  0x6e32de56                          // fmul          v22.4s, v18.4s, v18.4s
  .long  0x4eb5fc00                          // frsqrts       v0.4s, v0.4s, v21.4s
  .long  0x6e21dc33                          // fmul          v19.4s, v1.4s, v1.4s
  .long  0x6e34de97                          // fmul          v23.4s, v20.4s, v20.4s
  .long  0x4eb6fc21                          // frsqrts       v1.4s, v1.4s, v22.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x4eb7fc55                          // frsqrts       v21.4s, v2.4s, v23.4s
  .long  0x6e21de41                          // fmul          v1.4s, v18.4s, v1.4s
  .long  0x6ea1d812                          // frsqrte       v18.4s, v0.4s
  .long  0x6e35de90                          // fmul          v16.4s, v20.4s, v21.4s
  .long  0x6ea1d834                          // frsqrte       v20.4s, v1.4s
  .long  0x6e32de56                          // fmul          v22.4s, v18.4s, v18.4s
  .long  0x6ea1da15                          // frsqrte       v21.4s, v16.4s
  .long  0x6e34de97                          // fmul          v23.4s, v20.4s, v20.4s
  .long  0x4eb6fc00                          // frsqrts       v0.4s, v0.4s, v22.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x4eb7fc21                          // frsqrts       v1.4s, v1.4s, v23.4s
  .long  0x6e20de40                          // fmul          v0.4s, v18.4s, v0.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6e21de81                          // fmul          v1.4s, v20.4s, v1.4s
  .long  0x6ea1d812                          // frsqrte       v18.4s, v0.4s
  .long  0x6e30deb0                          // fmul          v16.4s, v21.4s, v16.4s
  .long  0x6ea1d834                          // frsqrte       v20.4s, v1.4s
  .long  0x6e32de56                          // fmul          v22.4s, v18.4s, v18.4s
  .long  0x6ea1da15                          // frsqrte       v21.4s, v16.4s
  .long  0x6e34de97                          // fmul          v23.4s, v20.4s, v20.4s
  .long  0x4eb6fc00                          // frsqrts       v0.4s, v0.4s, v22.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x4eb7fc21                          // frsqrts       v1.4s, v1.4s, v23.4s
  .long  0x6e20de40                          // fmul          v0.4s, v18.4s, v0.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6e21de81                          // fmul          v1.4s, v20.4s, v1.4s
  .long  0x6ea1d812                          // frsqrte       v18.4s, v0.4s
  .long  0x6e30deb0                          // fmul          v16.4s, v21.4s, v16.4s
  .long  0x6ea1d834                          // frsqrte       v20.4s, v1.4s
  .long  0x6e32de56                          // fmul          v22.4s, v18.4s, v18.4s
  .long  0x6ea1da15                          // frsqrte       v21.4s, v16.4s
  .long  0x6e34de97                          // fmul          v23.4s, v20.4s, v20.4s
  .long  0x4eb6fc00                          // frsqrts       v0.4s, v0.4s, v22.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x4eb7fc21                          // frsqrts       v1.4s, v1.4s, v23.4s
  .long  0x6e20de40                          // fmul          v0.4s, v18.4s, v0.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6e21de81                          // fmul          v1.4s, v20.4s, v1.4s
  .long  0x6ea1d812                          // frsqrte       v18.4s, v0.4s
  .long  0x6e20dc14                          // fmul          v20.4s, v0.4s, v0.4s
  .long  0x6e30deb0                          // fmul          v16.4s, v21.4s, v16.4s
  .long  0x6ea1d835                          // frsqrte       v21.4s, v1.4s
  .long  0x6e21dc36                          // fmul          v22.4s, v1.4s, v1.4s
  .long  0x6e32de57                          // fmul          v23.4s, v18.4s, v18.4s
  .long  0x6e34dc14                          // fmul          v20.4s, v0.4s, v20.4s
  .long  0x4eb7fc00                          // frsqrts       v0.4s, v0.4s, v23.4s
  .long  0x6ea1da17                          // frsqrte       v23.4s, v16.4s
  .long  0x6e34de31                          // fmul          v17.4s, v17.4s, v20.4s
  .long  0x6e35deb4                          // fmul          v20.4s, v21.4s, v21.4s
  .long  0x6e36dc36                          // fmul          v22.4s, v1.4s, v22.4s
  .long  0x4eb4fc21                          // frsqrts       v1.4s, v1.4s, v20.4s
  .long  0x6e30de14                          // fmul          v20.4s, v16.4s, v16.4s
  .long  0x6e36de73                          // fmul          v19.4s, v19.4s, v22.4s
  .long  0x6e37def6                          // fmul          v22.4s, v23.4s, v23.4s
  .long  0x6e20de40                          // fmul          v0.4s, v18.4s, v0.4s
  .long  0x6e34de14                          // fmul          v20.4s, v16.4s, v20.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6e22dc42                          // fmul          v2.4s, v2.4s, v2.4s
  .long  0x6e21dea1                          // fmul          v1.4s, v21.4s, v1.4s
  .long  0x6ea1d812                          // frsqrte       v18.4s, v0.4s
  .long  0x6e34dc42                          // fmul          v2.4s, v2.4s, v20.4s
  .long  0x6e30def0                          // fmul          v16.4s, v23.4s, v16.4s
  .long  0x6ea1d834                          // frsqrte       v20.4s, v1.4s
  .long  0x6e32de56                          // fmul          v22.4s, v18.4s, v18.4s
  .long  0x6ea1da15                          // frsqrte       v21.4s, v16.4s
  .long  0x4eb6fc00                          // frsqrts       v0.4s, v0.4s, v22.4s
  .long  0x6e34de96                          // fmul          v22.4s, v20.4s, v20.4s
  .long  0x4eb6fc21                          // frsqrts       v1.4s, v1.4s, v22.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e20de40                          // fmul          v0.4s, v18.4s, v0.4s
  .long  0x6e21de81                          // fmul          v1.4s, v20.4s, v1.4s
  .long  0x6e30deb0                          // fmul          v16.4s, v21.4s, v16.4s
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x6e20de20                          // fmul          v0.4s, v17.4s, v0.4s
  .long  0x6e21de61                          // fmul          v1.4s, v19.4s, v1.4s
  .long  0x6e30dc42                          // fmul          v2.4s, v2.4s, v16.4s
  .long  0x4e32f400                          // fmax          v0.4s, v0.4s, v18.4s
  .long  0x4e32f421                          // fmax          v1.4s, v1.4s, v18.4s
  .long  0x4e32f442                          // fmax          v2.4s, v2.4s, v18.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_to_2dot2_aarch64
.globl _sk_to_2dot2_aarch64
_sk_to_2dot2_aarch64:
  .long  0x6ea1d810                          // frsqrte       v16.4s, v0.4s
  .long  0x6e30de13                          // fmul          v19.4s, v16.4s, v16.4s
  .long  0x6ea1d831                          // frsqrte       v17.4s, v1.4s
  .long  0x4eb3fc00                          // frsqrts       v0.4s, v0.4s, v19.4s
  .long  0x6ea1d852                          // frsqrte       v18.4s, v2.4s
  .long  0x6e31de34                          // fmul          v20.4s, v17.4s, v17.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e32de55                          // fmul          v21.4s, v18.4s, v18.4s
  .long  0x4eb4fc21                          // frsqrts       v1.4s, v1.4s, v20.4s
  .long  0x6ea1d810                          // frsqrte       v16.4s, v0.4s
  .long  0x4eb5fc42                          // frsqrts       v2.4s, v2.4s, v21.4s
  .long  0x6e21de21                          // fmul          v1.4s, v17.4s, v1.4s
  .long  0x4ea1d811                          // frecpe        v17.4s, v0.4s
  .long  0x6e30de16                          // fmul          v22.4s, v16.4s, v16.4s
  .long  0x6e22de42                          // fmul          v2.4s, v18.4s, v2.4s
  .long  0x6ea1d832                          // frsqrte       v18.4s, v1.4s
  .long  0x4eb6fc16                          // frsqrts       v22.4s, v0.4s, v22.4s
  .long  0x4e31fc00                          // frecps        v0.4s, v0.4s, v17.4s
  .long  0x4ea1d833                          // frecpe        v19.4s, v1.4s
  .long  0x6e20de20                          // fmul          v0.4s, v17.4s, v0.4s
  .long  0x6e32de51                          // fmul          v17.4s, v18.4s, v18.4s
  .long  0x6ea1d854                          // frsqrte       v20.4s, v2.4s
  .long  0x4eb1fc31                          // frsqrts       v17.4s, v1.4s, v17.4s
  .long  0x4e33fc21                          // frecps        v1.4s, v1.4s, v19.4s
  .long  0x6e21de61                          // fmul          v1.4s, v19.4s, v1.4s
  .long  0x6e34de93                          // fmul          v19.4s, v20.4s, v20.4s
  .long  0x4eb3fc53                          // frsqrts       v19.4s, v2.4s, v19.4s
  .long  0x6e36de10                          // fmul          v16.4s, v16.4s, v22.4s
  .long  0x6e31de51                          // fmul          v17.4s, v18.4s, v17.4s
  .long  0x6e33de92                          // fmul          v18.4s, v20.4s, v19.4s
  .long  0x6ea1da13                          // frsqrte       v19.4s, v16.4s
  .long  0x4ea1d855                          // frecpe        v21.4s, v2.4s
  .long  0x6e33de76                          // fmul          v22.4s, v19.4s, v19.4s
  .long  0x4e35fc42                          // frecps        v2.4s, v2.4s, v21.4s
  .long  0x6ea1da34                          // frsqrte       v20.4s, v17.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6e22dea2                          // fmul          v2.4s, v21.4s, v2.4s
  .long  0x6ea1da55                          // frsqrte       v21.4s, v18.4s
  .long  0x6e34de96                          // fmul          v22.4s, v20.4s, v20.4s
  .long  0x6e30de70                          // fmul          v16.4s, v19.4s, v16.4s
  .long  0x4eb6fe31                          // frsqrts       v17.4s, v17.4s, v22.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x6ea1da13                          // frsqrte       v19.4s, v16.4s
  .long  0x4eb6fe52                          // frsqrts       v18.4s, v18.4s, v22.4s
  .long  0x6e31de91                          // fmul          v17.4s, v20.4s, v17.4s
  .long  0x6e33de76                          // fmul          v22.4s, v19.4s, v19.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x6ea1da34                          // frsqrte       v20.4s, v17.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6ea1da55                          // frsqrte       v21.4s, v18.4s
  .long  0x6e34de96                          // fmul          v22.4s, v20.4s, v20.4s
  .long  0x6e30de70                          // fmul          v16.4s, v19.4s, v16.4s
  .long  0x4eb6fe31                          // frsqrts       v17.4s, v17.4s, v22.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x6ea1da13                          // frsqrte       v19.4s, v16.4s
  .long  0x4eb6fe52                          // frsqrts       v18.4s, v18.4s, v22.4s
  .long  0x6e31de91                          // fmul          v17.4s, v20.4s, v17.4s
  .long  0x6e33de76                          // fmul          v22.4s, v19.4s, v19.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x6ea1da34                          // frsqrte       v20.4s, v17.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6ea1da55                          // frsqrte       v21.4s, v18.4s
  .long  0x6e34de96                          // fmul          v22.4s, v20.4s, v20.4s
  .long  0x6e30de70                          // fmul          v16.4s, v19.4s, v16.4s
  .long  0x4eb6fe31                          // frsqrts       v17.4s, v17.4s, v22.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x6ea1da13                          // frsqrte       v19.4s, v16.4s
  .long  0x4eb6fe52                          // frsqrts       v18.4s, v18.4s, v22.4s
  .long  0x6e31de91                          // fmul          v17.4s, v20.4s, v17.4s
  .long  0x6e33de76                          // fmul          v22.4s, v19.4s, v19.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6ea1da34                          // frsqrte       v20.4s, v17.4s
  .long  0x4eb6fe10                          // frsqrts       v16.4s, v16.4s, v22.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x6e34de96                          // fmul          v22.4s, v20.4s, v20.4s
  .long  0x6e30de70                          // fmul          v16.4s, v19.4s, v16.4s
  .long  0x6e21de21                          // fmul          v1.4s, v17.4s, v1.4s
  .long  0x6ea1da55                          // frsqrte       v21.4s, v18.4s
  .long  0x4eb6fe31                          // frsqrts       v17.4s, v17.4s, v22.4s
  .long  0x4ea1da13                          // frecpe        v19.4s, v16.4s
  .long  0x6e35deb6                          // fmul          v22.4s, v21.4s, v21.4s
  .long  0x6e31de91                          // fmul          v17.4s, v20.4s, v17.4s
  .long  0x4e33fe10                          // frecps        v16.4s, v16.4s, v19.4s
  .long  0x6e22de42                          // fmul          v2.4s, v18.4s, v2.4s
  .long  0x4eb6fe52                          // frsqrts       v18.4s, v18.4s, v22.4s
  .long  0x6e30de70                          // fmul          v16.4s, v19.4s, v16.4s
  .long  0x4ea1da33                          // frecpe        v19.4s, v17.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x4e33fe31                          // frecps        v17.4s, v17.4s, v19.4s
  .long  0x6e31de71                          // fmul          v17.4s, v19.4s, v17.4s
  .long  0x4ea1da53                          // frecpe        v19.4s, v18.4s
  .long  0x4e33fe52                          // frecps        v18.4s, v18.4s, v19.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e32de72                          // fmul          v18.4s, v19.4s, v18.4s
  .long  0x6f00e413                          // movi          v19.2d, #0x0
  .long  0x6e30dc00                          // fmul          v0.4s, v0.4s, v16.4s
  .long  0x6e31dc21                          // fmul          v1.4s, v1.4s, v17.4s
  .long  0x6e32dc42                          // fmul          v2.4s, v2.4s, v18.4s
  .long  0x4e33f400                          // fmax          v0.4s, v0.4s, v19.4s
  .long  0x4e33f421                          // fmax          v1.4s, v1.4s, v19.4s
  .long  0x4e33f442                          // fmax          v2.4s, v2.4s, v19.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_rgb_to_hsl_aarch64
.globl _sk_rgb_to_hsl_aarch64
_sk_rgb_to_hsl_aarch64:
  .long  0x4e21f410                          // fmax          v16.4s, v0.4s, v1.4s
  .long  0x4ea1f411                          // fmin          v17.4s, v0.4s, v1.4s
  .long  0x6ea1e454                          // fcmgt         v20.4s, v2.4s, v1.4s
  .long  0x4f00f715                          // fmov          v21.4s, #6.000000000000000000e+00
  .long  0x4e22f610                          // fmax          v16.4s, v16.4s, v2.4s
  .long  0x4ea2f631                          // fmin          v17.4s, v17.4s, v2.4s
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x4e341eb4                          // and           v20.16b, v21.16b, v20.16b
  .long  0x4eb1d615                          // fsub          v21.4s, v16.4s, v17.4s
  .long  0x4ea2d433                          // fsub          v19.4s, v1.4s, v2.4s
  .long  0x4ea0d456                          // fsub          v22.4s, v2.4s, v0.4s
  .long  0x4f026417                          // movi          v23.4s, #0x40, lsl #24
  .long  0x6e35fe42                          // fdiv          v2.4s, v18.4s, v21.4s
  .long  0x4ea1d418                          // fsub          v24.4s, v0.4s, v1.4s
  .long  0x4f00f619                          // fmov          v25.4s, #4.000000000000000000e+00
  .long  0x4f0167fa                          // movi          v26.4s, #0x3f, lsl #24
  .long  0x4eb0d6f2                          // fsub          v18.4s, v23.4s, v16.4s
  .long  0x4e36cc57                          // fmla          v23.4s, v2.4s, v22.4s
  .long  0x4e31e616                          // fcmeq         v22.4s, v16.4s, v17.4s
  .long  0x4e20e600                          // fcmeq         v0.4s, v16.4s, v0.4s
  .long  0x4e21e601                          // fcmeq         v1.4s, v16.4s, v1.4s
  .long  0x4e31d610                          // fadd          v16.4s, v16.4s, v17.4s
  .long  0x52a7c548                          // mov           w8, #0x3e2a0000
  .long  0x4e33cc54                          // fmla          v20.4s, v2.4s, v19.4s
  .long  0x4e38cc59                          // fmla          v25.4s, v2.4s, v24.4s
  .long  0x6e3ade02                          // fmul          v2.4s, v16.4s, v26.4s
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4eb1d651                          // fsub          v17.4s, v18.4s, v17.4s
  .long  0x6ebae452                          // fcmgt         v18.4s, v2.4s, v26.4s
  .long  0x6e791ee1                          // bsl           v1.16b, v23.16b, v25.16b
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x6e701e32                          // bsl           v18.16b, v17.16b, v16.16b
  .long  0x6e611e80                          // bsl           v0.16b, v20.16b, v1.16b
  .long  0x6e32fea1                          // fdiv          v1.4s, v21.4s, v18.4s
  .long  0x6e33dc00                          // fmul          v0.4s, v0.4s, v19.4s
  .long  0x4e761c00                          // bic           v0.16b, v0.16b, v22.16b
  .long  0x4e761c21                          // bic           v1.16b, v1.16b, v22.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_hsl_to_rgb_aarch64
.globl _sk_hsl_to_rgb_aarch64
_sk_hsl_to_rgb_aarch64:
  .long  0x52a7d548                          // mov           w8, #0x3eaa0000
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e040d17                          // dup           v23.4s, w8
  .long  0x52a7c548                          // mov           w8, #0x3e2a0000
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x52a7e548                          // mov           w8, #0x3f2a0000
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x4f07f616                          // fmov          v22.4s, #-1.000000000000000000e+00
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e22d435                          // fadd          v21.4s, v1.4s, v2.4s
  .long  0x4e040d1a                          // dup           v26.4s, w8
  .long  0x52b7d548                          // mov           w8, #0xbeaa0000
  .long  0x6eb2e41d                          // fcmgt         v29.4s, v0.4s, v18.4s
  .long  0x4e36d41e                          // fadd          v30.4s, v0.4s, v22.4s
  .long  0x4f0167f1                          // movi          v17.4s, #0x3f, lsl #24
  .long  0x4ea0d830                          // fcmeq         v16.4s, v1.4s, #0.0
  .long  0x4ea0e819                          // fcmlt         v25.4s, v0.4s, #0.0
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e32d43c                          // fadd          v28.4s, v1.4s, v18.4s
  .long  0x4ea2cc35                          // fmls          v21.4s, v1.4s, v2.4s
  .long  0x4e32d401                          // fadd          v1.4s, v0.4s, v18.4s
  .long  0x6e601fdd                          // bsl           v29.16b, v30.16b, v0.16b
  .long  0x4e37d417                          // fadd          v23.4s, v0.4s, v23.4s
  .long  0x6ea2e63b                          // fcmgt         v27.4s, v17.4s, v2.4s
  .long  0x4e040d1e                          // dup           v30.4s, w8
  .long  0x6e22df9c                          // fmul          v28.4s, v28.4s, v2.4s
  .long  0x6e7d1c39                          // bsl           v25.16b, v1.16b, v29.16b
  .long  0x6eb2e6e1                          // fcmgt         v1.4s, v23.4s, v18.4s
  .long  0x4e36d6fd                          // fadd          v29.4s, v23.4s, v22.4s
  .long  0x4e3ed41e                          // fadd          v30.4s, v0.4s, v30.4s
  .long  0x6e751f9b                          // bsl           v27.16b, v28.16b, v21.16b
  .long  0x4ea0eaf5                          // fcmlt         v21.4s, v23.4s, #0.0
  .long  0x4e32d6fc                          // fadd          v28.4s, v23.4s, v18.4s
  .long  0x6e771fa1                          // bsl           v1.16b, v29.16b, v23.16b
  .long  0x4f026414                          // movi          v20.4s, #0x40, lsl #24
  .long  0x6e611f95                          // bsl           v21.16b, v28.16b, v1.16b
  .long  0x4e32d7c1                          // fadd          v1.4s, v30.4s, v18.4s
  .long  0x6eb2e7d2                          // fcmgt         v18.4s, v30.4s, v18.4s
  .long  0x4e36d7d6                          // fadd          v22.4s, v30.4s, v22.4s
  .long  0x6ea0fb7c                          // fneg          v28.4s, v27.4s
  .long  0x4ea0ebdd                          // fcmlt         v29.4s, v30.4s, #0.0
  .long  0x6e7e1ed2                          // bsl           v18.16b, v22.16b, v30.16b
  .long  0x4e22ce9c                          // fmla          v28.4s, v20.4s, v2.4s
  .long  0x4f00f718                          // fmov          v24.4s, #6.000000000000000000e+00
  .long  0x6e721c3d                          // bsl           v29.16b, v1.16b, v18.16b
  .long  0x4ebcd761                          // fsub          v1.4s, v27.4s, v28.4s
  .long  0x4eb5d752                          // fsub          v18.4s, v26.4s, v21.4s
  .long  0x4ebc1f94                          // mov           v20.16b, v28.16b
  .long  0x6e38dc38                          // fmul          v24.4s, v1.4s, v24.4s
  .long  0x4eb9d756                          // fsub          v22.4s, v26.4s, v25.4s
  .long  0x4ebc1f9f                          // mov           v31.16b, v28.16b
  .long  0x4e32cf14                          // fmla          v20.4s, v24.4s, v18.4s
  .long  0x4ebc1f81                          // mov           v1.16b, v28.16b
  .long  0x4ebc1f92                          // mov           v18.16b, v28.16b
  .long  0x4e38cc1f                          // fmla          v31.4s, v0.4s, v24.4s
  .long  0x4e36cf01                          // fmla          v1.4s, v24.4s, v22.4s
  .long  0x4ebdd740                          // fsub          v0.4s, v26.4s, v29.4s
  .long  0x4e3ecf12                          // fmla          v18.4s, v24.4s, v30.4s
  .long  0x4ebc1f96                          // mov           v22.16b, v28.16b
  .long  0x6eb5e75e                          // fcmgt         v30.4s, v26.4s, v21.4s
  .long  0x4e20cf16                          // fmla          v22.4s, v24.4s, v0.4s
  .long  0x6e7c1e9e                          // bsl           v30.16b, v20.16b, v28.16b
  .long  0x6eb9e754                          // fcmgt         v20.4s, v26.4s, v25.4s
  .long  0x6ebde75a                          // fcmgt         v26.4s, v26.4s, v29.4s
  .long  0x6e7c1c34                          // bsl           v20.16b, v1.16b, v28.16b
  .long  0x6e7c1eda                          // bsl           v26.16b, v22.16b, v28.16b
  .long  0x4e37cf1c                          // fmla          v28.4s, v24.4s, v23.4s
  .long  0x6eb9e637                          // fcmgt         v23.4s, v17.4s, v25.4s
  .long  0x6eb5e678                          // fcmgt         v24.4s, v19.4s, v21.4s
  .long  0x6eb5e635                          // fcmgt         v21.4s, v17.4s, v21.4s
  .long  0x6ebde631                          // fcmgt         v17.4s, v17.4s, v29.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6eb9e676                          // fcmgt         v22.4s, v19.4s, v25.4s
  .long  0x6ebde673                          // fcmgt         v19.4s, v19.4s, v29.4s
  .long  0x6e7a1f71                          // bsl           v17.16b, v27.16b, v26.16b
  .long  0x6e7e1f75                          // bsl           v21.16b, v27.16b, v30.16b
  .long  0x6e741f77                          // bsl           v23.16b, v27.16b, v20.16b
  .long  0x6e711e53                          // bsl           v19.16b, v18.16b, v17.16b
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb01e01                          // mov           v1.16b, v16.16b
  .long  0x6e751f98                          // bsl           v24.16b, v28.16b, v21.16b
  .long  0x6e771ff6                          // bsl           v22.16b, v31.16b, v23.16b
  .long  0x6e731c50                          // bsl           v16.16b, v2.16b, v19.16b
  .long  0x6e781c40                          // bsl           v0.16b, v2.16b, v24.16b
  .long  0x6e761c41                          // bsl           v1.16b, v2.16b, v22.16b
  .long  0x4eb01e02                          // mov           v2.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_scale_1_float_aarch64
.globl _sk_scale_1_float_aarch64
_sk_scale_1_float_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4f909000                          // fmul          v0.4s, v0.4s, v16.s[0]
  .long  0x4f909021                          // fmul          v1.4s, v1.4s, v16.s[0]
  .long  0x4f909042                          // fmul          v2.4s, v2.4s, v16.s[0]
  .long  0x4f909063                          // fmul          v3.4s, v3.4s, v16.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_scale_u8_aarch64
.globl _sk_scale_u8_aarch64
_sk_scale_u8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x39400109                          // ldrb          w9, [x8]
  .long  0x3940050a                          // ldrb          w10, [x8, #1]
  .long  0x3940090b                          // ldrb          w11, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d31                          // mov           v17.h[0], w9
  .long  0x4e061d51                          // mov           v17.h[1], w10
  .long  0x4e0a1d71                          // mov           v17.h[2], w11
  .long  0x4e0e1d11                          // mov           v17.h[3], w8
  .long  0x2f10a631                          // uxtl          v17.4s, v17.4h
  .long  0x6e21da31                          // ucvtf         v17.4s, v17.4s
  .long  0x6e30de30                          // fmul          v16.4s, v17.4s, v16.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lerp_1_float_aarch64
.globl _sk_lerp_1_float_aarch64
_sk_lerp_1_float_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea4d411                          // fsub          v17.4s, v0.4s, v4.4s
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea5d432                          // fsub          v18.4s, v1.4s, v5.4s
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4f901220                          // fmla          v0.4s, v17.4s, v16.s[0]
  .long  0x4ea6d451                          // fsub          v17.4s, v2.4s, v6.4s
  .long  0x4f901241                          // fmla          v1.4s, v18.4s, v16.s[0]
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea7d472                          // fsub          v18.4s, v3.4s, v7.4s
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0x4f901222                          // fmla          v2.4s, v17.4s, v16.s[0]
  .long  0x4f901243                          // fmla          v3.4s, v18.4s, v16.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lerp_u8_aarch64
.globl _sk_lerp_u8_aarch64
_sk_lerp_u8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4ea4d412                          // fsub          v18.4s, v0.4s, v4.4s
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x3940010a                          // ldrb          w10, [x8]
  .long  0x39400509                          // ldrb          w9, [x8, #1]
  .long  0x3940090b                          // ldrb          w11, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d51                          // mov           v17.h[0], w10
  .long  0x4e061d31                          // mov           v17.h[1], w9
  .long  0x4e0a1d71                          // mov           v17.h[2], w11
  .long  0x4e0e1d11                          // mov           v17.h[3], w8
  .long  0x2f10a620                          // uxtl          v0.4s, v17.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e30dc10                          // fmul          v16.4s, v0.4s, v16.4s
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea5d431                          // fsub          v17.4s, v1.4s, v5.4s
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4e32ce00                          // fmla          v0.4s, v16.4s, v18.4s
  .long  0x4ea6d452                          // fsub          v18.4s, v2.4s, v6.4s
  .long  0x4e31ce01                          // fmla          v1.4s, v16.4s, v17.4s
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea7d471                          // fsub          v17.4s, v3.4s, v7.4s
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0x4e32ce02                          // fmla          v2.4s, v16.4s, v18.4s
  .long  0x4e31ce03                          // fmla          v3.4s, v16.4s, v17.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lerp_565_aarch64
.globl _sk_lerp_565_aarch64
_sk_lerp_565_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x4f072710                          // movi          v16.4s, #0xf8, lsl #8
  .long  0x4ea4d413                          // fsub          v19.4s, v0.4s, v4.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0xfc696903                          // ldr           d3, [x8, x9]
  .long  0x52a6f088                          // mov           w8, #0x37840000
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x2f10a463                          // uxtl          v3.4s, v3.4h
  .long  0x321b17e8                          // orr           w8, wzr, #0x7e0
  .long  0x4e301c60                          // and           v0.16b, v3.16b, v16.16b
  .long  0x4e040d12                          // dup           v18.4s, w8
  .long  0x52a74048                          // mov           w8, #0x3a020000
  .long  0x4e21d800                          // scvtf         v0.4s, v0.4s
  .long  0x72810428                          // movk          w8, #0x821
  .long  0x6e31dc10                          // fmul          v16.4s, v0.4s, v17.4s
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4e33ce00                          // fmla          v0.4s, v16.4s, v19.4s
  .long  0x4f0007f0                          // movi          v16.4s, #0x1f
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a7a088                          // mov           w8, #0x3d040000
  .long  0x4e321c72                          // and           v18.16b, v3.16b, v18.16b
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x4e301c63                          // and           v3.16b, v3.16b, v16.16b
  .long  0x4ea6d450                          // fsub          v16.4s, v2.4s, v6.4s
  .long  0x4e21da42                          // scvtf         v2.4s, v18.4s
  .long  0x6e31dc51                          // fmul          v17.4s, v2.4s, v17.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x4ea5d433                          // fsub          v19.4s, v1.4s, v5.4s
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x6e22dc63                          // fmul          v3.4s, v3.4s, v2.4s
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4e33ce21                          // fmla          v1.4s, v17.4s, v19.4s
  .long  0x4e30cc62                          // fmla          v2.4s, v3.4s, v16.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_tables_aarch64
.globl _sk_load_tables_aarch64
_sk_load_tables_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ef409                          // lsl           x9, x0, #2
  .long  0x6f00e620                          // movi          v0.2d, #0xff000000ff
  .long  0x52a7700b                          // mov           w11, #0x3b800000
  .long  0xa940310a                          // ldp           x10, x12, [x8]
  .long  0x7290102b                          // movk          w11, #0x8081
  .long  0x4e040d63                          // dup           v3.4s, w11
  .long  0x3ce96942                          // ldr           q2, [x10, x9]
  .long  0xa9412109                          // ldp           x9, x8, [x8, #16]
  .long  0x4e201c41                          // and           v1.16b, v2.16b, v0.16b
  .long  0x1e26002e                          // fmov          w14, s1
  .long  0x6f380450                          // ushr          v16.4s, v2.4s, #8
  .long  0x6f300451                          // ushr          v17.4s, v2.4s, #16
  .long  0x8b2e498e                          // add           x14, x12, w14, uxtw #2
  .long  0x0e0c3c2a                          // mov           w10, v1.s[1]
  .long  0x0e143c2b                          // mov           w11, v1.s[2]
  .long  0x0e1c3c2d                          // mov           w13, v1.s[3]
  .long  0x4e201e01                          // and           v1.16b, v16.16b, v0.16b
  .long  0x4e201e30                          // and           v16.16b, v17.16b, v0.16b
  .long  0x0d4081c0                          // ld1           {v0.s}[0], [x14]
  .long  0x8b2a498a                          // add           x10, x12, w10, uxtw #2
  .long  0xbc6b5991                          // ldr           s17, [x12, w11, uxtw #2]
  .long  0xbc6d5992                          // ldr           s18, [x12, w13, uxtw #2]
  .long  0x0e0c3c2b                          // mov           w11, v1.s[1]
  .long  0x0e143c2c                          // mov           w12, v1.s[2]
  .long  0x0e1c3c2d                          // mov           w13, v1.s[3]
  .long  0x1e26002e                          // fmov          w14, s1
  .long  0x8b2e492e                          // add           x14, x9, w14, uxtw #2
  .long  0xbc6c5933                          // ldr           s19, [x9, w12, uxtw #2]
  .long  0xbc6d5934                          // ldr           s20, [x9, w13, uxtw #2]
  .long  0x8b2b4929                          // add           x9, x9, w11, uxtw #2
  .long  0x1e26020b                          // fmov          w11, s16
  .long  0x6f280442                          // ushr          v2.4s, v2.4s, #24
  .long  0x0d409140                          // ld1           {v0.s}[1], [x10]
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x8b2b490a                          // add           x10, x8, w11, uxtw #2
  .long  0x0d4081c1                          // ld1           {v1.s}[0], [x14]
  .long  0x6e23dc43                          // fmul          v3.4s, v2.4s, v3.4s
  .long  0x0d408142                          // ld1           {v2.s}[0], [x10]
  .long  0x0e0c3e0f                          // mov           w15, v16.s[1]
  .long  0x0e143e0c                          // mov           w12, v16.s[2]
  .long  0x8b2f490a                          // add           x10, x8, w15, uxtw #2
  .long  0x0e1c3e0d                          // mov           w13, v16.s[3]
  .long  0xbc6c5910                          // ldr           s16, [x8, w12, uxtw #2]
  .long  0x0d409121                          // ld1           {v1.s}[1], [x9]
  .long  0x0d409142                          // ld1           {v2.s}[1], [x10]
  .long  0x6e140620                          // mov           v0.s[2], v17.s[0]
  .long  0xbc6d5911                          // ldr           s17, [x8, w13, uxtw #2]
  .long  0x6e140661                          // mov           v1.s[2], v19.s[0]
  .long  0x6e140602                          // mov           v2.s[2], v16.s[0]
  .long  0x6e1c0640                          // mov           v0.s[3], v18.s[0]
  .long  0x6e1c0681                          // mov           v1.s[3], v20.s[0]
  .long  0x6e1c0622                          // mov           v2.s[3], v17.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_byte_tables_aarch64
.globl _sk_byte_tables_aarch64
_sk_byte_tables_aarch64:
  .long  0xd10083ff                          // sub           sp, sp, #0x20
  .long  0xaa0103e8                          // mov           x8, x1
  .long  0x91002109                          // add           x9, x8, #0x8
  .long  0xa9014ff4                          // stp           x20, x19, [sp, #16]
  .long  0xf90007e9                          // str           x9, [sp, #8]
  .long  0xf8410429                          // ldr           x9, [x1], #16
  .long  0x52a86fea                          // mov           w10, #0x437f0000
  .long  0x4e040d51                          // dup           v17.4s, w10
  .long  0x52a7700b                          // mov           w11, #0x3b800000
  .long  0xa9405126                          // ldp           x6, x20, [x9]
  .long  0x6e31dc00                          // fmul          v0.4s, v0.4s, v17.4s
  .long  0x7290102b                          // movk          w11, #0x8081
  .long  0x6e21a800                          // fcvtnu        v0.4s, v0.4s
  .long  0x4e040d70                          // dup           v16.4s, w11
  .long  0x0e0c3c0a                          // mov           w10, v0.s[1]
  .long  0x0e143c0b                          // mov           w11, v0.s[2]
  .long  0x0e1c3c0c                          // mov           w12, v0.s[3]
  .long  0x1e26000d                          // fmov          w13, s0
  .long  0x386d48cd                          // ldrb          w13, [x6, w13, uxtw]
  .long  0x386a48ca                          // ldrb          w10, [x6, w10, uxtw]
  .long  0x386b48cb                          // ldrb          w11, [x6, w11, uxtw]
  .long  0x386c48cc                          // ldrb          w12, [x6, w12, uxtw]
  .long  0xa9412526                          // ldp           x6, x9, [x9, #16]
  .long  0x6e31dc42                          // fmul          v2.4s, v2.4s, v17.4s
  .long  0x6e31dc21                          // fmul          v1.4s, v1.4s, v17.4s
  .long  0x6e31dc63                          // fmul          v3.4s, v3.4s, v17.4s
  .long  0x6e21a842                          // fcvtnu        v2.4s, v2.4s
  .long  0x6e21a821                          // fcvtnu        v1.4s, v1.4s
  .long  0x6e21a863                          // fcvtnu        v3.4s, v3.4s
  .long  0x0e0c3c52                          // mov           w18, v2.s[1]
  .long  0x0e143c43                          // mov           w3, v2.s[2]
  .long  0x0e1c3c44                          // mov           w4, v2.s[3]
  .long  0x1e260045                          // fmov          w5, s2
  .long  0x1e260031                          // fmov          w17, s1
  .long  0x386548c5                          // ldrb          w5, [x6, w5, uxtw]
  .long  0x387248d2                          // ldrb          w18, [x6, w18, uxtw]
  .long  0x386348c3                          // ldrb          w3, [x6, w3, uxtw]
  .long  0x386448c4                          // ldrb          w4, [x6, w4, uxtw]
  .long  0x1e260066                          // fmov          w6, s3
  .long  0x0e0c3c2e                          // mov           w14, v1.s[1]
  .long  0x0e0c3c67                          // mov           w7, v3.s[1]
  .long  0x38714a91                          // ldrb          w17, [x20, w17, uxtw]
  .long  0x38664926                          // ldrb          w6, [x9, w6, uxtw]
  .long  0x0e143c2f                          // mov           w15, v1.s[2]
  .long  0x0e1c3c30                          // mov           w16, v1.s[3]
  .long  0x0e143c73                          // mov           w19, v3.s[2]
  .long  0x386e4a8e                          // ldrb          w14, [x20, w14, uxtw]
  .long  0x38674927                          // ldrb          w7, [x9, w7, uxtw]
  .long  0x386f4a8f                          // ldrb          w15, [x20, w15, uxtw]
  .long  0x38704a90                          // ldrb          w16, [x20, w16, uxtw]
  .long  0x0e1c3c74                          // mov           w20, v3.s[3]
  .long  0x38734933                          // ldrb          w19, [x9, w19, uxtw]
  .long  0x38744929                          // ldrb          w9, [x9, w20, uxtw]
  .long  0x4e021da0                          // mov           v0.h[0], w13
  .long  0x4e021e21                          // mov           v1.h[0], w17
  .long  0x4e021ca2                          // mov           v2.h[0], w5
  .long  0x4e021cc3                          // mov           v3.h[0], w6
  .long  0x4e061d40                          // mov           v0.h[1], w10
  .long  0x4e061dc1                          // mov           v1.h[1], w14
  .long  0x4e061e42                          // mov           v2.h[1], w18
  .long  0x4e061ce3                          // mov           v3.h[1], w7
  .long  0x4e0a1d60                          // mov           v0.h[2], w11
  .long  0x4e0a1de1                          // mov           v1.h[2], w15
  .long  0x4e0a1c62                          // mov           v2.h[2], w3
  .long  0x4e0a1e63                          // mov           v3.h[2], w19
  .long  0x4e0e1d80                          // mov           v0.h[3], w12
  .long  0x4e0e1e01                          // mov           v1.h[3], w16
  .long  0x4e0e1c82                          // mov           v2.h[3], w4
  .long  0x4e0e1d23                          // mov           v3.h[3], w9
  .long  0xf9400505                          // ldr           x5, [x8, #8]
  .long  0x2f07b7e0                          // bic           v0.4h, #0xff, lsl #8
  .long  0x2f07b7e1                          // bic           v1.4h, #0xff, lsl #8
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x2f07b7e3                          // bic           v3.4h, #0xff, lsl #8
  .long  0xa9414ff4                          // ldp           x20, x19, [sp, #16]
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x2f10a463                          // uxtl          v3.4s, v3.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6e21d863                          // ucvtf         v3.4s, v3.4s
  .long  0x6e30dc00                          // fmul          v0.4s, v0.4s, v16.4s
  .long  0x6e30dc21                          // fmul          v1.4s, v1.4s, v16.4s
  .long  0x6e30dc42                          // fmul          v2.4s, v2.4s, v16.4s
  .long  0x6e30dc63                          // fmul          v3.4s, v3.4s, v16.4s
  .long  0x910083ff                          // add           sp, sp, #0x20
  .long  0xd61f00a0                          // br            x5

HIDDEN _sk_byte_tables_rgb_aarch64
.globl _sk_byte_tables_rgb_aarch64
_sk_byte_tables_rgb_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0xb9401909                          // ldr           w9, [x8, #24]
  .long  0xa9402d0a                          // ldp           x10, x11, [x8]
  .long  0xf9400908                          // ldr           x8, [x8, #16]
  .long  0x51000529                          // sub           w9, w9, #0x1
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e21da31                          // scvtf         v17.4s, v17.4s
  .long  0x6e21de21                          // fmul          v1.4s, v17.4s, v1.4s
  .long  0x6e20de20                          // fmul          v0.4s, v17.4s, v0.4s
  .long  0x6e22de22                          // fmul          v2.4s, v17.4s, v2.4s
  .long  0x6e21a821                          // fcvtnu        v1.4s, v1.4s
  .long  0x6e21a800                          // fcvtnu        v0.4s, v0.4s
  .long  0x6e21a842                          // fcvtnu        v2.4s, v2.4s
  .long  0x0e0c3c2f                          // mov           w15, v1.s[1]
  .long  0x0e143c30                          // mov           w16, v1.s[2]
  .long  0x0e1c3c31                          // mov           w17, v1.s[3]
  .long  0x1e260032                          // fmov          w18, s1
  .long  0x1e26000e                          // fmov          w14, s0
  .long  0x38724972                          // ldrb          w18, [x11, w18, uxtw]
  .long  0x386f496f                          // ldrb          w15, [x11, w15, uxtw]
  .long  0x38704970                          // ldrb          w16, [x11, w16, uxtw]
  .long  0x3871496b                          // ldrb          w11, [x11, w17, uxtw]
  .long  0x1e260051                          // fmov          w17, s2
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x386e494e                          // ldrb          w14, [x10, w14, uxtw]
  .long  0x0e0c3c44                          // mov           w4, v2.s[1]
  .long  0x38714911                          // ldrb          w17, [x8, w17, uxtw]
  .long  0x0e143c0c                          // mov           w12, v0.s[2]
  .long  0x0e1c3c0d                          // mov           w13, v0.s[3]
  .long  0x0e143c45                          // mov           w5, v2.s[2]
  .long  0x38694949                          // ldrb          w9, [x10, w9, uxtw]
  .long  0x38644904                          // ldrb          w4, [x8, w4, uxtw]
  .long  0x386c494c                          // ldrb          w12, [x10, w12, uxtw]
  .long  0x386d494a                          // ldrb          w10, [x10, w13, uxtw]
  .long  0x0e1c3c4d                          // mov           w13, v2.s[3]
  .long  0x38654905                          // ldrb          w5, [x8, w5, uxtw]
  .long  0x386d4908                          // ldrb          w8, [x8, w13, uxtw]
  .long  0x4e021dc0                          // mov           v0.h[0], w14
  .long  0x4e021e41                          // mov           v1.h[0], w18
  .long  0x4e021e22                          // mov           v2.h[0], w17
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e061de1                          // mov           v1.h[1], w15
  .long  0x4e061c82                          // mov           v2.h[1], w4
  .long  0x4e0a1d80                          // mov           v0.h[2], w12
  .long  0x4e0a1e01                          // mov           v1.h[2], w16
  .long  0x4e0a1ca2                          // mov           v2.h[2], w5
  .long  0x4e0e1d40                          // mov           v0.h[3], w10
  .long  0x4e0e1d61                          // mov           v1.h[3], w11
  .long  0x4e0e1d02                          // mov           v2.h[3], w8
  .long  0x2f07b7e0                          // bic           v0.4h, #0xff, lsl #8
  .long  0x2f07b7e1                          // bic           v1.4h, #0xff, lsl #8
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6e30dc00                          // fmul          v0.4s, v0.4s, v16.4s
  .long  0x6e30dc21                          // fmul          v1.4s, v1.4s, v16.4s
  .long  0x6e30dc42                          // fmul          v2.4s, v2.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_a8_aarch64
.globl _sk_load_a8_aarch64
_sk_load_a8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d22                          // dup           v2.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x3940010a                          // ldrb          w10, [x8]
  .long  0x3940050b                          // ldrb          w11, [x8, #1]
  .long  0x3940090c                          // ldrb          w12, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d43                          // mov           v3.h[0], w10
  .long  0x4e061d63                          // mov           v3.h[1], w11
  .long  0x4e0a1d83                          // mov           v3.h[2], w12
  .long  0x4e0e1d03                          // mov           v3.h[3], w8
  .long  0x2f10a463                          // uxtl          v3.4s, v3.4h
  .long  0x6e21d863                          // ucvtf         v3.4s, v3.4s
  .long  0x6e22dc63                          // fmul          v3.4s, v3.4s, v2.4s
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_a8_aarch64
.globl _sk_gather_a8_aarch64
_sk_gather_a8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x4e040d23                          // dup           v3.4s, w9
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x386c490c                          // ldrb          w12, [x8, w12, uxtw]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x38694909                          // ldrb          w9, [x8, w9, uxtw]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x386a490a                          // ldrb          w10, [x8, w10, uxtw]
  .long  0x386b4908                          // ldrb          w8, [x8, w11, uxtw]
  .long  0x4e021d82                          // mov           v2.h[0], w12
  .long  0x4e061d22                          // mov           v2.h[1], w9
  .long  0x4e0a1d42                          // mov           v2.h[2], w10
  .long  0x4e0e1d02                          // mov           v2.h[3], w8
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x6e23dc43                          // fmul          v3.4s, v2.4s, v3.4s
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_a8_aarch64
.globl _sk_store_a8_aarch64
_sk_store_a8_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a86fe9                          // mov           w9, #0x437f0000
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0x0e0e3e09                          // umov          w9, v16.h[3]
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x39000d09                          // strb          w9, [x8, #3]
  .long  0x0e0a3e09                          // umov          w9, v16.h[2]
  .long  0x39000909                          // strb          w9, [x8, #2]
  .long  0x0e063e09                          // umov          w9, v16.h[1]
  .long  0x39000509                          // strb          w9, [x8, #1]
  .long  0x0e023e09                          // umov          w9, v16.h[0]
  .long  0x39000109                          // strb          w9, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_g8_aarch64
.globl _sk_load_g8_aarch64
_sk_load_g8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d20                          // dup           v0.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x3940010a                          // ldrb          w10, [x8]
  .long  0x39400509                          // ldrb          w9, [x8, #1]
  .long  0x3940090b                          // ldrb          w11, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d41                          // mov           v1.h[0], w10
  .long  0x4e061d21                          // mov           v1.h[1], w9
  .long  0x4e0a1d61                          // mov           v1.h[2], w11
  .long  0x4e0e1d01                          // mov           v1.h[3], w8
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4ea01c01                          // mov           v1.16b, v0.16b
  .long  0x4ea01c02                          // mov           v2.16b, v0.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_g8_aarch64
.globl _sk_gather_g8_aarch64
_sk_gather_g8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x4e040d23                          // dup           v3.4s, w9
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x386c490c                          // ldrb          w12, [x8, w12, uxtw]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x38694909                          // ldrb          w9, [x8, w9, uxtw]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x386a490a                          // ldrb          w10, [x8, w10, uxtw]
  .long  0x386b4908                          // ldrb          w8, [x8, w11, uxtw]
  .long  0x4e021d80                          // mov           v0.h[0], w12
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e0a1d40                          // mov           v0.h[2], w10
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x2f07b7e0                          // bic           v0.4h, #0xff, lsl #8
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e23dc00                          // fmul          v0.4s, v0.4s, v3.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0x4ea01c01                          // mov           v1.16b, v0.16b
  .long  0x4ea01c02                          // mov           v2.16b, v0.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_i8_aarch64
.globl _sk_gather_i8_aarch64
_sk_gather_i8_aarch64:
  .long  0xaa0103e8                          // mov           x8, x1
  .long  0xf8408429                          // ldr           x9, [x1], #8
  .long  0xb4000069                          // cbz           x9, 17e4 <sk_gather_i8_aarch64+0x14>
  .long  0xaa0903ea                          // mov           x10, x9
  .long  0x14000003                          // b             17ec <sk_gather_i8_aarch64+0x1c>
  .long  0xf940050a                          // ldr           x10, [x8, #8]
  .long  0x91004101                          // add           x1, x8, #0x10
  .long  0xf8410548                          // ldr           x8, [x10], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0xf9400529                          // ldr           x9, [x9, #8]
  .long  0x4d40c942                          // ld1r          {v2.4s}, [x10]
  .long  0x6f00e623                          // movi          v3.2d, #0xff000000ff
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000d                          // fmov          w13, s0
  .long  0x0e0c3c0a                          // mov           w10, v0.s[1]
  .long  0x386d490d                          // ldrb          w13, [x8, w13, uxtw]
  .long  0x0e143c0b                          // mov           w11, v0.s[2]
  .long  0x386a490a                          // ldrb          w10, [x8, w10, uxtw]
  .long  0x0e1c3c0c                          // mov           w12, v0.s[3]
  .long  0x386b490b                          // ldrb          w11, [x8, w11, uxtw]
  .long  0x386c4908                          // ldrb          w8, [x8, w12, uxtw]
  .long  0x4e021da0                          // mov           v0.h[0], w13
  .long  0x4e061d40                          // mov           v0.h[1], w10
  .long  0x4e0a1d60                          // mov           v0.h[2], w11
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e231c00                          // and           v0.16b, v0.16b, v3.16b
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x8b2c492c                          // add           x12, x9, w12, uxtw #2
  .long  0x0e0c3c08                          // mov           w8, v0.s[1]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d408180                          // ld1           {v0.s}[0], [x12]
  .long  0x8b284928                          // add           x8, x9, w8, uxtw #2
  .long  0xb86a592a                          // ldr           w10, [x9, w10, uxtw #2]
  .long  0x52a7700c                          // mov           w12, #0x3b800000
  .long  0x0d409100                          // ld1           {v0.s}[1], [x8]
  .long  0xb86b5928                          // ldr           w8, [x9, w11, uxtw #2]
  .long  0x7290102c                          // movk          w12, #0x8081
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e141d40                          // mov           v0.s[2], w10
  .long  0x4e1c1d00                          // mov           v0.s[3], w8
  .long  0x4e231c01                          // and           v1.16b, v0.16b, v3.16b
  .long  0x6f380402                          // ushr          v2.4s, v0.4s, #8
  .long  0x6f300411                          // ushr          v17.4s, v0.4s, #16
  .long  0x4e040d90                          // dup           v16.4s, w12
  .long  0x6f280400                          // ushr          v0.4s, v0.4s, #24
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x4e231c42                          // and           v2.16b, v2.16b, v3.16b
  .long  0x4e231e23                          // and           v3.16b, v17.16b, v3.16b
  .long  0x4e21d811                          // scvtf         v17.4s, v0.4s
  .long  0x6e30dc20                          // fmul          v0.4s, v1.4s, v16.4s
  .long  0x4e21d841                          // scvtf         v1.4s, v2.4s
  .long  0x4e21d862                          // scvtf         v2.4s, v3.4s
  .long  0x6e30dc21                          // fmul          v1.4s, v1.4s, v16.4s
  .long  0x6e30dc42                          // fmul          v2.4s, v2.4s, v16.4s
  .long  0x6e30de23                          // fmul          v3.4s, v17.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_565_aarch64
.globl _sk_load_565_aarch64
_sk_load_565_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x4f072701                          // movi          v1.4s, #0xf8, lsl #8
  .long  0x4f0007e3                          // movi          v3.4s, #0x1f
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0xfc696900                          // ldr           d0, [x8, x9]
  .long  0x321b17e8                          // orr           w8, wzr, #0x7e0
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x52a6f088                          // mov           w8, #0x37840000
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e040d00                          // dup           v0.4s, w8
  .long  0x52a74048                          // mov           w8, #0x3a020000
  .long  0x72810428                          // movk          w8, #0x821
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d01                          // dup           v1.4s, w8
  .long  0x52a7a088                          // mov           w8, #0x3d040000
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x6e21dc41                          // fmul          v1.4s, v2.4s, v1.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e22dc62                          // fmul          v2.4s, v3.4s, v2.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_565_aarch64
.globl _sk_gather_565_aarch64
_sk_gather_565_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x321b17e9                          // orr           w9, wzr, #0x7e0
  .long  0x4e040d23                          // dup           v3.4s, w9
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x8b2c450c                          // add           x12, x8, w12, uxtw #1
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d404180                          // ld1           {v0.h}[0], [x12]
  .long  0x78695909                          // ldrh          w9, [x8, w9, uxtw #1]
  .long  0x786a590a                          // ldrh          w10, [x8, w10, uxtw #1]
  .long  0x786b5908                          // ldrh          w8, [x8, w11, uxtw #1]
  .long  0x4f072701                          // movi          v1.4s, #0xf8, lsl #8
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e0a1d40                          // mov           v0.h[2], w10
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x52a6f08b                          // mov           w11, #0x37840000
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x7284210b                          // movk          w11, #0x2108
  .long  0x52a74049                          // mov           w9, #0x3a020000
  .long  0x4f0007e2                          // movi          v2.4s, #0x1f
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x72810429                          // movk          w9, #0x821
  .long  0x52a7a08a                          // mov           w10, #0x3d040000
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e040d60                          // dup           v0.4s, w11
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x7284210a                          // movk          w10, #0x2108
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d21                          // dup           v1.4s, w9
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e21dc61                          // fmul          v1.4s, v3.4s, v1.4s
  .long  0x4e040d43                          // dup           v3.4s, w10
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x6e23dc42                          // fmul          v2.4s, v2.4s, v3.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_565_aarch64
.globl _sk_store_565_aarch64
_sk_store_565_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a84f8a                          // mov           w10, #0x427c0000
  .long  0x4f01f7f0                          // fmov          v16.4s, #3.100000000000000000e+01
  .long  0x4e040d52                          // dup           v18.4s, w10
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0x6e32dc32                          // fmul          v18.4s, v1.4s, v18.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x6e30dc50                          // fmul          v16.4s, v2.4s, v16.4s
  .long  0x4f2b5631                          // shl           v17.4s, v17.4s, #11
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f255652                          // shl           v18.4s, v18.4s, #5
  .long  0x4eb11e51                          // orr           v17.16b, v18.16b, v17.16b
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x4eb01e30                          // orr           v16.16b, v17.16b, v16.16b
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0xfc296910                          // str           d16, [x8, x9]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_4444_aarch64
.globl _sk_load_4444_aarch64
_sk_load_4444_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x4f072601                          // movi          v1.4s, #0xf0, lsl #8
  .long  0x4f0025e2                          // movi          v2.4s, #0xf, lsl #8
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f070603                          // movi          v3.4s, #0xf0
  .long  0x4f0005f0                          // movi          v16.4s, #0xf
  .long  0xfc696900                          // ldr           d0, [x8, x9]
  .long  0x52a6f108                          // mov           w8, #0x37880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e301c10                          // and           v16.16b, v0.16b, v16.16b
  .long  0x4e040d00                          // dup           v0.4s, w8
  .long  0x52a73108                          // mov           w8, #0x39880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d01                          // dup           v1.4s, w8
  .long  0x52a77108                          // mov           w8, #0x3b880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x6e21dc41                          // fmul          v1.4s, v2.4s, v1.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x52a7b108                          // mov           w8, #0x3d880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e22dc62                          // fmul          v2.4s, v3.4s, v2.4s
  .long  0x4e040d03                          // dup           v3.4s, w8
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_4444_aarch64
.globl _sk_gather_4444_aarch64
_sk_gather_4444_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x4f070603                          // movi          v3.4s, #0xf0
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f0005f0                          // movi          v16.4s, #0xf
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x8b2c450c                          // add           x12, x8, w12, uxtw #1
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d404180                          // ld1           {v0.h}[0], [x12]
  .long  0x78695909                          // ldrh          w9, [x8, w9, uxtw #1]
  .long  0x786a590a                          // ldrh          w10, [x8, w10, uxtw #1]
  .long  0x786b5908                          // ldrh          w8, [x8, w11, uxtw #1]
  .long  0x4f072601                          // movi          v1.4s, #0xf0, lsl #8
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e0a1d40                          // mov           v0.h[2], w10
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x52a6f10b                          // mov           w11, #0x37880000
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x7291112b                          // movk          w11, #0x8889
  .long  0x4f0025e2                          // movi          v2.4s, #0xf, lsl #8
  .long  0x52a73109                          // mov           w9, #0x39880000
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x72911129                          // movk          w9, #0x8889
  .long  0x52a7710a                          // mov           w10, #0x3b880000
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e301c10                          // and           v16.16b, v0.16b, v16.16b
  .long  0x4e040d60                          // dup           v0.4s, w11
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x7291112a                          // movk          w10, #0x8889
  .long  0x52a7b108                          // mov           w8, #0x3d880000
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d21                          // dup           v1.4s, w9
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x6e21dc41                          // fmul          v1.4s, v2.4s, v1.4s
  .long  0x4e040d42                          // dup           v2.4s, w10
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e22dc62                          // fmul          v2.4s, v3.4s, v2.4s
  .long  0x4e040d03                          // dup           v3.4s, w8
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_4444_aarch64
.globl _sk_store_4444_aarch64
_sk_store_4444_aarch64:
  .long  0x4f01f5d0                          // fmov          v16.4s, #1.500000000000000000e+01
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0x6e30dc32                          // fmul          v18.4s, v1.4s, v16.4s
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x4f2c5631                          // shl           v17.4s, v17.4s, #12
  .long  0x4f285652                          // shl           v18.4s, v18.4s, #8
  .long  0x4eb11e51                          // orr           v17.16b, v18.16b, v17.16b
  .long  0x6e30dc52                          // fmul          v18.4s, v2.4s, v16.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0x4f245652                          // shl           v18.4s, v18.4s, #4
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4eb21e31                          // orr           v17.16b, v17.16b, v18.16b
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x4eb01e30                          // orr           v16.16b, v17.16b, v16.16b
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0xfc296910                          // str           d16, [x8, x9]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_8888_aarch64
.globl _sk_load_8888_aarch64
_sk_load_8888_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ef409                          // lsl           x9, x0, #2
  .long  0x6f00e621                          // movi          v1.2d, #0xff000000ff
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x3ce96900                          // ldr           q0, [x8, x9]
  .long  0x52a77008                          // mov           w8, #0x3b800000
  .long  0x72901028                          // movk          w8, #0x8081
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x6f380410                          // ushr          v16.4s, v0.4s, #8
  .long  0x6f300411                          // ushr          v17.4s, v0.4s, #16
  .long  0x4e211c03                          // and           v3.16b, v0.16b, v1.16b
  .long  0x6f280400                          // ushr          v0.4s, v0.4s, #24
  .long  0x4e211e10                          // and           v16.16b, v16.16b, v1.16b
  .long  0x4e211e21                          // and           v1.16b, v17.16b, v1.16b
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x4e21d811                          // scvtf         v17.4s, v0.4s
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x4e21d832                          // scvtf         v18.4s, v1.4s
  .long  0x6e22dc60                          // fmul          v0.4s, v3.4s, v2.4s
  .long  0x6e22de23                          // fmul          v3.4s, v17.4s, v2.4s
  .long  0x6e22de01                          // fmul          v1.4s, v16.4s, v2.4s
  .long  0x6e22de42                          // fmul          v2.4s, v18.4s, v2.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_8888_aarch64
.globl _sk_gather_8888_aarch64
_sk_gather_8888_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x8b2c490c                          // add           x12, x8, w12, uxtw #2
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d408180                          // ld1           {v0.s}[0], [x12]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0xb86a590a                          // ldr           w10, [x8, w10, uxtw #2]
  .long  0xb86b5908                          // ldr           w8, [x8, w11, uxtw #2]
  .long  0x0d409120                          // ld1           {v0.s}[1], [x9]
  .long  0x6f00e621                          // movi          v1.2d, #0xff000000ff
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e141d40                          // mov           v0.s[2], w10
  .long  0x4e1c1d00                          // mov           v0.s[3], w8
  .long  0x6f380410                          // ushr          v16.4s, v0.4s, #8
  .long  0x6f300411                          // ushr          v17.4s, v0.4s, #16
  .long  0x4e211c03                          // and           v3.16b, v0.16b, v1.16b
  .long  0x6f280400                          // ushr          v0.4s, v0.4s, #24
  .long  0x4e211e10                          // and           v16.16b, v16.16b, v1.16b
  .long  0x4e211e21                          // and           v1.16b, v17.16b, v1.16b
  .long  0x4e040d22                          // dup           v2.4s, w9
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x4e21d811                          // scvtf         v17.4s, v0.4s
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x4e21d832                          // scvtf         v18.4s, v1.4s
  .long  0x6e22dc60                          // fmul          v0.4s, v3.4s, v2.4s
  .long  0x6e22de23                          // fmul          v3.4s, v17.4s, v2.4s
  .long  0x6e22de01                          // fmul          v1.4s, v16.4s, v2.4s
  .long  0x6e22de42                          // fmul          v2.4s, v18.4s, v2.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_8888_aarch64
.globl _sk_store_8888_aarch64
_sk_store_8888_aarch64:
  .long  0x52a86fea                          // mov           w10, #0x437f0000
  .long  0x4e040d50                          // dup           v16.4s, w10
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x6e30dc32                          // fmul          v18.4s, v1.4s, v16.4s
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x4f285652                          // shl           v18.4s, v18.4s, #8
  .long  0x4eb11e51                          // orr           v17.16b, v18.16b, v17.16b
  .long  0x6e30dc52                          // fmul          v18.4s, v2.4s, v16.4s
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x4f305652                          // shl           v18.4s, v18.4s, #16
  .long  0x4eb21e31                          // orr           v17.16b, v17.16b, v18.16b
  .long  0x4f385610                          // shl           v16.4s, v16.4s, #24
  .long  0xd37ef409                          // lsl           x9, x0, #2
  .long  0x4eb01e30                          // orr           v16.16b, v17.16b, v16.16b
  .long  0x3ca96910                          // str           q16, [x8, x9]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_f16_aarch64
.globl _sk_load_f16_aarch64
_sk_load_f16_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0c400510                          // ld4           {v16.4h-v19.4h}, [x8]
  .long  0x0e217a00                          // fcvtl         v0.4s, v16.4h
  .long  0x0e217a21                          // fcvtl         v1.4s, v17.4h
  .long  0x0e217a42                          // fcvtl         v2.4s, v18.4h
  .long  0x0e217a63                          // fcvtl         v3.4s, v19.4h
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_f16_aarch64
.globl _sk_gather_f16_aarch64
_sk_gather_f16_aarch64:
  .long  0xa9bf7bfd                          // stp           x29, x30, [sp, #-16]!
  .long  0xd100c3e9                          // sub           x9, sp, #0x30
  .long  0x910003fd                          // mov           x29, sp
  .long  0x927be93f                          // and           sp, x9, #0xffffffffffffffe0
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x8b2c4d0c                          // add           x12, x8, w12, uxtw #3
  .long  0x8b2a4d0a                          // add           x10, x8, w10, uxtw #3
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d408540                          // ld1           {v0.d}[0], [x10]
  .long  0x0d408581                          // ld1           {v1.d}[0], [x12]
  .long  0x8b294d09                          // add           x9, x8, w9, uxtw #3
  .long  0x8b2b4d08                          // add           x8, x8, w11, uxtw #3
  .long  0x4d408500                          // ld1           {v0.d}[1], [x8]
  .long  0x4d408521                          // ld1           {v1.d}[1], [x9]
  .long  0x910003e8                          // mov           x8, sp
  .long  0xad0003e1                          // stp           q1, q0, [sp]
  .long  0x0c400510                          // ld4           {v16.4h-v19.4h}, [x8]
  .long  0xf9400428                          // ldr           x8, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0x0e217a00                          // fcvtl         v0.4s, v16.4h
  .long  0x0e217a21                          // fcvtl         v1.4s, v17.4h
  .long  0x0e217a42                          // fcvtl         v2.4s, v18.4h
  .long  0x0e217a63                          // fcvtl         v3.4s, v19.4h
  .long  0xd63f0100                          // blr           x8
  .long  0x910003bf                          // mov           sp, x29
  .long  0xa8c17bfd                          // ldp           x29, x30, [sp], #16
  .long  0xd65f03c0                          // ret

HIDDEN _sk_store_f16_aarch64
.globl _sk_store_f16_aarch64
_sk_store_f16_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x0e216810                          // fcvtn         v16.4h, v0.4s
  .long  0x0e216831                          // fcvtn         v17.4h, v1.4s
  .long  0x0e216852                          // fcvtn         v18.4h, v2.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x0e216873                          // fcvtn         v19.4h, v3.4s
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0c000510                          // st4           {v16.4h-v19.4h}, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_u16_be_aarch64
.globl _sk_load_u16_be_aarch64
_sk_load_u16_be_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0c400500                          // ld4           {v0.4h-v3.4h}, [x8]
  .long  0x52a6f008                          // mov           w8, #0x37800000
  .long  0x72801008                          // movk          w8, #0x80
  .long  0x0f185410                          // shl           v16.4h, v0.4h, #8
  .long  0x2f180411                          // ushr          v17.4h, v0.4h, #8
  .long  0x0f185432                          // shl           v18.4h, v1.4h, #8
  .long  0x2f180433                          // ushr          v19.4h, v1.4h, #8
  .long  0x0f185454                          // shl           v20.4h, v2.4h, #8
  .long  0x2f180455                          // ushr          v21.4h, v2.4h, #8
  .long  0x0f185476                          // shl           v22.4h, v3.4h, #8
  .long  0x2f180460                          // ushr          v0.4h, v3.4h, #8
  .long  0x0eb11e01                          // orr           v1.8b, v16.8b, v17.8b
  .long  0x0eb31e42                          // orr           v2.8b, v18.8b, v19.8b
  .long  0x0eb51e90                          // orr           v16.8b, v20.8b, v21.8b
  .long  0x0ea01ec0                          // orr           v0.8b, v22.8b, v0.8b
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x2f10a610                          // uxtl          v16.4s, v16.4h
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e040d03                          // dup           v3.4s, w8
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6e21da10                          // ucvtf         v16.4s, v16.4s
  .long  0x6e21d811                          // ucvtf         v17.4s, v0.4s
  .long  0x6e23dc20                          // fmul          v0.4s, v1.4s, v3.4s
  .long  0x6e23dc41                          // fmul          v1.4s, v2.4s, v3.4s
  .long  0x6e23de02                          // fmul          v2.4s, v16.4s, v3.4s
  .long  0x6e23de23                          // fmul          v3.4s, v17.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_u16_be_aarch64
.globl _sk_store_u16_be_aarch64
_sk_store_u16_be_aarch64:
  .long  0x52a8efe9                          // mov           w9, #0x477f0000
  .long  0x729fe009                          // movk          w9, #0xff00
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x0e612a31                          // xtn           v17.4h, v17.4s
  .long  0x6e30dc32                          // fmul          v18.4s, v1.4s, v16.4s
  .long  0x0f185633                          // shl           v19.4h, v17.4h, #8
  .long  0x2f180631                          // ushr          v17.4h, v17.4h, #8
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x0eb11e75                          // orr           v21.8b, v19.8b, v17.8b
  .long  0x6e30dc51                          // fmul          v17.4s, v2.4s, v16.4s
  .long  0x0e612a52                          // xtn           v18.4h, v18.4s
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x0f185654                          // shl           v20.4h, v18.4h, #8
  .long  0x2f180652                          // ushr          v18.4h, v18.4h, #8
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x0e612a31                          // xtn           v17.4h, v17.4s
  .long  0x0eb21e96                          // orr           v22.8b, v20.8b, v18.8b
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0x0f185632                          // shl           v18.4h, v17.4h, #8
  .long  0x2f180631                          // ushr          v17.4h, v17.4h, #8
  .long  0x0eb11e57                          // orr           v23.8b, v18.8b, v17.8b
  .long  0x0f185611                          // shl           v17.4h, v16.4h, #8
  .long  0x2f180610                          // ushr          v16.4h, v16.4h, #8
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0eb01e38                          // orr           v24.8b, v17.8b, v16.8b
  .long  0x0c000515                          // st4           {v21.4h-v24.4h}, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_f32_aarch64
.globl _sk_load_f32_aarch64
_sk_load_f32_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b001108                          // add           x8, x8, x0, lsl #4
  .long  0x4c400900                          // ld4           {v0.4s-v3.4s}, [x8]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_f32_aarch64
.globl _sk_store_f32_aarch64
_sk_store_f32_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b001108                          // add           x8, x8, x0, lsl #4
  .long  0x4c000900                          // st4           {v0.4s-v3.4s}, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_x_aarch64
.globl _sk_clamp_x_aarch64
_sk_clamp_x_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x4e20f620                          // fmax          v0.4s, v17.4s, v0.4s
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0x4d40c910                          // ld1r          {v16.4s}, [x8]
  .long  0x4eb18610                          // add           v16.4s, v16.4s, v17.4s
  .long  0x4eb0f400                          // fmin          v0.4s, v0.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_y_aarch64
.globl _sk_clamp_y_aarch64
_sk_clamp_y_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x4e21f621                          // fmax          v1.4s, v17.4s, v1.4s
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0x4d40c910                          // ld1r          {v16.4s}, [x8]
  .long  0x4eb18610                          // add           v16.4s, v16.4s, v17.4s
  .long  0x4eb0f421                          // fmin          v1.4s, v1.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_repeat_x_aarch64
.globl _sk_repeat_x_aarch64
_sk_repeat_x_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x4eb18651                          // add           v17.4s, v18.4s, v17.4s
  .long  0x6e32fc12                          // fdiv          v18.4s, v0.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905240                          // fmls          v0.4s, v18.4s, v16.s[0]
  .long  0x4eb1f400                          // fmin          v0.4s, v0.4s, v17.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_repeat_y_aarch64
.globl _sk_repeat_y_aarch64
_sk_repeat_y_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x4eb18651                          // add           v17.4s, v18.4s, v17.4s
  .long  0x6e32fc32                          // fdiv          v18.4s, v1.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905241                          // fmls          v1.4s, v18.4s, v16.s[0]
  .long  0x4eb1f421                          // fmin          v1.4s, v1.4s, v17.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_mirror_x_aarch64
.globl _sk_mirror_x_aarch64
_sk_mirror_x_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040611                          // dup           v17.4s, v16.s[0]
  .long  0x1e302a10                          // fadd          s16, s16, s16
  .long  0x4eb1d400                          // fsub          v0.4s, v0.4s, v17.4s
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x6e32fc12                          // fdiv          v18.4s, v0.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905240                          // fmls          v0.4s, v18.4s, v16.s[0]
  .long  0x6f07e7f0                          // movi          v16.2d, #0xffffffffffffffff
  .long  0x4eb1d400                          // fsub          v0.4s, v0.4s, v17.4s
  .long  0x4eb08630                          // add           v16.4s, v17.4s, v16.4s
  .long  0x4ea0f800                          // fabs          v0.4s, v0.4s
  .long  0x4eb0f400                          // fmin          v0.4s, v0.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_mirror_y_aarch64
.globl _sk_mirror_y_aarch64
_sk_mirror_y_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040611                          // dup           v17.4s, v16.s[0]
  .long  0x1e302a10                          // fadd          s16, s16, s16
  .long  0x4eb1d421                          // fsub          v1.4s, v1.4s, v17.4s
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x6e32fc32                          // fdiv          v18.4s, v1.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905241                          // fmls          v1.4s, v18.4s, v16.s[0]
  .long  0x6f07e7f0                          // movi          v16.2d, #0xffffffffffffffff
  .long  0x4eb1d421                          // fsub          v1.4s, v1.4s, v17.4s
  .long  0x4eb08630                          // add           v16.4s, v17.4s, v16.4s
  .long  0x4ea0f821                          // fabs          v1.4s, v1.4s
  .long  0x4eb0f421                          // fmin          v1.4s, v1.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_luminance_to_alpha_aarch64
.globl _sk_luminance_to_alpha_aarch64
_sk_luminance_to_alpha_aarch64:
  .long  0x52a7cb28                          // mov           w8, #0x3e590000
  .long  0x72967a08                          // movk          w8, #0xb3d0
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a7e6e8                          // mov           w8, #0x3f370000
  .long  0x7282eb28                          // movk          w8, #0x1759
  .long  0x4ea01c10                          // mov           v16.16b, v0.16b
  .long  0x4e040d00                          // dup           v0.4s, w8
  .long  0x52a7b268                          // mov           w8, #0x3d930000
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x729bb308                          // movk          w8, #0xdd98
  .long  0x6e20dc23                          // fmul          v3.4s, v1.4s, v0.4s
  .long  0x4e30ce23                          // fmla          v3.4s, v17.4s, v16.4s
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x4e22ce03                          // fmla          v3.4s, v16.4s, v2.4s
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_2x3_aarch64
.globl _sk_matrix_2x3_aarch64
_sk_matrix_2x3_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100410a                          // add           x10, x8, #0x10
  .long  0x4ddfc932                          // ld1r          {v18.4s}, [x9], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x2d415113                          // ldp           s19, s20, [x8, #8]
  .long  0x9100510a                          // add           x10, x8, #0x14
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x4f931030                          // fmla          v16.4s, v1.4s, v19.s[0]
  .long  0xbd400133                          // ldr           s19, [x9]
  .long  0x4f941031                          // fmla          v17.4s, v1.4s, v20.s[0]
  .long  0x4e20ce50                          // fmla          v16.4s, v18.4s, v0.4s
  .long  0x4f931011                          // fmla          v17.4s, v0.4s, v19.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_3x4_aarch64
.globl _sk_matrix_3x4_aarch64
_sk_matrix_3x4_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100910a                          // add           x10, x8, #0x24
  .long  0x4ddfc933                          // ld1r          {v19.4s}, [x9], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x9100a10a                          // add           x10, x8, #0x28
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x9100b10a                          // add           x10, x8, #0x2c
  .long  0x2d435514                          // ldp           s20, s21, [x8, #24]
  .long  0xbd402116                          // ldr           s22, [x8, #32]
  .long  0x4d40c952                          // ld1r          {v18.4s}, [x10]
  .long  0x4f941050                          // fmla          v16.4s, v2.4s, v20.s[0]
  .long  0x4f951051                          // fmla          v17.4s, v2.4s, v21.s[0]
  .long  0x4f961052                          // fmla          v18.4s, v2.4s, v22.s[0]
  .long  0x2d425502                          // ldp           s2, s21, [x8, #16]
  .long  0x2d415d14                          // ldp           s20, s23, [x8, #8]
  .long  0x4f821031                          // fmla          v17.4s, v1.4s, v2.s[0]
  .long  0xbd400122                          // ldr           s2, [x9]
  .long  0x4f971030                          // fmla          v16.4s, v1.4s, v23.s[0]
  .long  0x4f951032                          // fmla          v18.4s, v1.4s, v21.s[0]
  .long  0x4e20ce70                          // fmla          v16.4s, v19.4s, v0.4s
  .long  0x4f941012                          // fmla          v18.4s, v0.4s, v20.s[0]
  .long  0x4f821011                          // fmla          v17.4s, v0.4s, v2.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_4x5_aarch64
.globl _sk_matrix_4x5_aarch64
_sk_matrix_4x5_aarch64:
  .long  0xf9400029                          // ldr           x9, [x1]
  .long  0xaa0903e8                          // mov           x8, x9
  .long  0x9101012a                          // add           x10, x9, #0x40
  .long  0x4ddfc914                          // ld1r          {v20.4s}, [x8], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x9101112a                          // add           x10, x9, #0x44
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x9101212a                          // add           x10, x9, #0x48
  .long  0x4d40c952                          // ld1r          {v18.4s}, [x10]
  .long  0x2d465533                          // ldp           s19, s21, [x9, #48]
  .long  0x2d475d36                          // ldp           s22, s23, [x9, #56]
  .long  0x9101312a                          // add           x10, x9, #0x4c
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f931070                          // fmla          v16.4s, v3.4s, v19.s[0]
  .long  0x4d40c953                          // ld1r          {v19.4s}, [x10]
  .long  0x4f951071                          // fmla          v17.4s, v3.4s, v21.s[0]
  .long  0x4f961072                          // fmla          v18.4s, v3.4s, v22.s[0]
  .long  0x2d445935                          // ldp           s21, s22, [x9, #32]
  .long  0x4f971073                          // fmla          v19.4s, v3.4s, v23.s[0]
  .long  0x2d455d23                          // ldp           s3, s23, [x9, #40]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0x4f951050                          // fmla          v16.4s, v2.4s, v21.s[0]
  .long  0x4f961051                          // fmla          v17.4s, v2.4s, v22.s[0]
  .long  0x2d425935                          // ldp           s21, s22, [x9, #16]
  .long  0x4f971053                          // fmla          v19.4s, v2.4s, v23.s[0]
  .long  0x4f831052                          // fmla          v18.4s, v2.4s, v3.s[0]
  .long  0x2d410d22                          // ldp           s2, s3, [x9, #8]
  .long  0x4f951030                          // fmla          v16.4s, v1.4s, v21.s[0]
  .long  0x2d435d35                          // ldp           s21, s23, [x9, #24]
  .long  0x4f961031                          // fmla          v17.4s, v1.4s, v22.s[0]
  .long  0xbd400116                          // ldr           s22, [x8]
  .long  0x4e20ce90                          // fmla          v16.4s, v20.4s, v0.4s
  .long  0x4f951032                          // fmla          v18.4s, v1.4s, v21.s[0]
  .long  0x4f971033                          // fmla          v19.4s, v1.4s, v23.s[0]
  .long  0x4f821012                          // fmla          v18.4s, v0.4s, v2.s[0]
  .long  0x4f831013                          // fmla          v19.4s, v0.4s, v3.s[0]
  .long  0x4f961011                          // fmla          v17.4s, v0.4s, v22.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_perspective_aarch64
.globl _sk_matrix_perspective_aarch64
_sk_matrix_perspective_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100510a                          // add           x10, x8, #0x14
  .long  0x4ddfc930                          // ld1r          {v16.4s}, [x9], #4
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x9100810a                          // add           x10, x8, #0x20
  .long  0x4d40c952                          // ld1r          {v18.4s}, [x10]
  .long  0x2d41d113                          // ldp           s19, s20, [x8, #12]
  .long  0x2d435915                          // ldp           s21, s22, [x8, #24]
  .long  0x91002108                          // add           x8, x8, #0x8
  .long  0x4f941031                          // fmla          v17.4s, v1.4s, v20.s[0]
  .long  0x4d40c914                          // ld1r          {v20.4s}, [x8]
  .long  0x4f961032                          // fmla          v18.4s, v1.4s, v22.s[0]
  .long  0xbd400136                          // ldr           s22, [x9]
  .long  0x4f951012                          // fmla          v18.4s, v0.4s, v21.s[0]
  .long  0x4f931011                          // fmla          v17.4s, v0.4s, v19.s[0]
  .long  0x4f961034                          // fmla          v20.4s, v1.4s, v22.s[0]
  .long  0x4ea1da41                          // frecpe        v1.4s, v18.4s
  .long  0x4e21fe52                          // frecps        v18.4s, v18.4s, v1.4s
  .long  0x6e32dc32                          // fmul          v18.4s, v1.4s, v18.4s
  .long  0x4e20ce14                          // fmla          v20.4s, v16.4s, v0.4s
  .long  0x6e32de21                          // fmul          v1.4s, v17.4s, v18.4s
  .long  0x6e32de80                          // fmul          v0.4s, v20.4s, v18.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_linear_gradient_aarch64
.globl _sk_linear_gradient_aarch64
_sk_linear_gradient_aarch64:
  .long  0xf9400029                          // ldr           x9, [x1]
  .long  0x91004128                          // add           x8, x9, #0x10
  .long  0x9100512a                          // add           x10, x9, #0x14
  .long  0x4d40c910                          // ld1r          {v16.4s}, [x8]
  .long  0x91006128                          // add           x8, x9, #0x18
  .long  0x4d40c941                          // ld1r          {v1.4s}, [x10]
  .long  0x9100712a                          // add           x10, x9, #0x1c
  .long  0x4d40c902                          // ld1r          {v2.4s}, [x8]
  .long  0xf9400128                          // ldr           x8, [x9]
  .long  0x4d40c943                          // ld1r          {v3.4s}, [x10]
  .long  0xb40006c8                          // cbz           x8, 2348 <sk_linear_gradient_aarch64+0x100>
  .long  0x6dbf23e9                          // stp           d9, d8, [sp, #-16]!
  .long  0xf9400529                          // ldr           x9, [x9, #8]
  .long  0x6f00e413                          // movi          v19.2d, #0x0
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x91004129                          // add           x9, x9, #0x10
  .long  0x6f00e414                          // movi          v20.2d, #0x0
  .long  0xd100412a                          // sub           x10, x9, #0x10
  .long  0x4d40c955                          // ld1r          {v21.4s}, [x10]
  .long  0xd100312b                          // sub           x11, x9, #0xc
  .long  0xd100212a                          // sub           x10, x9, #0x8
  .long  0x4d40c976                          // ld1r          {v22.4s}, [x11]
  .long  0xd100112b                          // sub           x11, x9, #0x4
  .long  0x4d40c957                          // ld1r          {v23.4s}, [x10]
  .long  0xaa0903ea                          // mov           x10, x9
  .long  0x4d40c978                          // ld1r          {v24.4s}, [x11]
  .long  0x4ddfc959                          // ld1r          {v25.4s}, [x10], #4
  .long  0x9100412b                          // add           x11, x9, #0x10
  .long  0x4ea31c7b                          // mov           v27.16b, v3.16b
  .long  0x6ea0e6a3                          // fcmgt         v3.4s, v21.4s, v0.4s
  .long  0x4d40c97a                          // ld1r          {v26.4s}, [x11]
  .long  0x4eb41e95                          // mov           v21.16b, v20.16b
  .long  0x4ea31c74                          // mov           v20.16b, v3.16b
  .long  0x9100212b                          // add           x11, x9, #0x8
  .long  0x4eb31e69                          // mov           v9.16b, v19.16b
  .long  0x4ea31c73                          // mov           v19.16b, v3.16b
  .long  0x6e771eb4                          // bsl           v20.16b, v21.16b, v23.16b
  .long  0x4d40c975                          // ld1r          {v21.4s}, [x11]
  .long  0x9100312b                          // add           x11, x9, #0xc
  .long  0x6e761d33                          // bsl           v19.16b, v9.16b, v22.16b
  .long  0x4d40c976                          // ld1r          {v22.4s}, [x11]
  .long  0x4d40c957                          // ld1r          {v23.4s}, [x10]
  .long  0x4eb21e5c                          // mov           v28.16b, v18.16b
  .long  0x4eb11e3d                          // mov           v29.16b, v17.16b
  .long  0x4eb01e1e                          // mov           v30.16b, v16.16b
  .long  0x4ea11c3f                          // mov           v31.16b, v1.16b
  .long  0x4ea21c48                          // mov           v8.16b, v2.16b
  .long  0x4ea31c72                          // mov           v18.16b, v3.16b
  .long  0x4ea31c71                          // mov           v17.16b, v3.16b
  .long  0x4ea31c70                          // mov           v16.16b, v3.16b
  .long  0x4ea31c61                          // mov           v1.16b, v3.16b
  .long  0x4ea31c62                          // mov           v2.16b, v3.16b
  .long  0x6e7a1f63                          // bsl           v3.16b, v27.16b, v26.16b
  .long  0x6e781f92                          // bsl           v18.16b, v28.16b, v24.16b
  .long  0x6e791fb1                          // bsl           v17.16b, v29.16b, v25.16b
  .long  0x6e751fe1                          // bsl           v1.16b, v31.16b, v21.16b
  .long  0x6e761d02                          // bsl           v2.16b, v8.16b, v22.16b
  .long  0xd1000508                          // sub           x8, x8, #0x1
  .long  0x6e771fd0                          // bsl           v16.16b, v30.16b, v23.16b
  .long  0x91009129                          // add           x9, x9, #0x24
  .long  0xb5fffaa8                          // cbnz          x8, 2290 <sk_linear_gradient_aarch64+0x48>
  .long  0x6cc123e9                          // ldp           d9, d8, [sp], #16
  .long  0x14000005                          // b             2358 <sk_linear_gradient_aarch64+0x110>
  .long  0x6f00e414                          // movi          v20.2d, #0x0
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x6f00e413                          // movi          v19.2d, #0x0
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4e20ce70                          // fmla          v16.4s, v19.4s, v0.4s
  .long  0x4e20ce81                          // fmla          v1.4s, v20.4s, v0.4s
  .long  0x4e20ce42                          // fmla          v2.4s, v18.4s, v0.4s
  .long  0x4e20ce23                          // fmla          v3.4s, v17.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_linear_gradient_2stops_aarch64
.globl _sk_linear_gradient_2stops_aarch64
_sk_linear_gradient_2stops_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100410a                          // add           x10, x8, #0x10
  .long  0x4ddfc931                          // ld1r          {v17.4s}, [x9], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x9100510a                          // add           x10, x8, #0x14
  .long  0x4d40c941                          // ld1r          {v1.4s}, [x10]
  .long  0x9100610a                          // add           x10, x8, #0x18
  .long  0x4d40c942                          // ld1r          {v2.4s}, [x10]
  .long  0x9100710a                          // add           x10, x8, #0x1c
  .long  0x2d414d12                          // ldp           s18, s19, [x8, #8]
  .long  0x4d40c943                          // ld1r          {v3.4s}, [x10]
  .long  0x4e20ce30                          // fmla          v16.4s, v17.4s, v0.4s
  .long  0xbd400131                          // ldr           s17, [x9]
  .long  0x4f921002                          // fmla          v2.4s, v0.4s, v18.s[0]
  .long  0x4f931003                          // fmla          v3.4s, v0.4s, v19.s[0]
  .long  0x4f911001                          // fmla          v1.4s, v0.4s, v17.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_save_xy_aarch64
.globl _sk_save_xy_aarch64
_sk_save_xy_aarch64:
  .long  0x4f0167f0                          // movi          v16.4s, #0x3f, lsl #24
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4e30d411                          // fadd          v17.4s, v0.4s, v16.4s
  .long  0x4e30d430                          // fadd          v16.4s, v1.4s, v16.4s
  .long  0x4e219a32                          // frintm        v18.4s, v17.4s
  .long  0x4eb2d631                          // fsub          v17.4s, v17.4s, v18.4s
  .long  0x4e219a12                          // frintm        v18.4s, v16.4s
  .long  0x4eb2d610                          // fsub          v16.4s, v16.4s, v18.4s
  .long  0x3d800100                          // str           q0, [x8]
  .long  0x3d800901                          // str           q1, [x8, #32]
  .long  0x3d801111                          // str           q17, [x8, #64]
  .long  0x3d801910                          // str           q16, [x8, #96]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_accumulate_aarch64
.globl _sk_accumulate_aarch64
_sk_accumulate_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x3dc02110                          // ldr           q16, [x8, #128]
  .long  0x3dc02911                          // ldr           q17, [x8, #160]
  .long  0x6e31de10                          // fmul          v16.4s, v16.4s, v17.4s
  .long  0x4e30cc04                          // fmla          v4.4s, v0.4s, v16.4s
  .long  0x4e30cc25                          // fmla          v5.4s, v1.4s, v16.4s
  .long  0x4e30cc46                          // fmla          v6.4s, v2.4s, v16.4s
  .long  0x4e30cc67                          // fmla          v7.4s, v3.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_nx_aarch64
.globl _sk_bilinear_nx_aarch64
_sk_bilinear_nx_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x3dc01100                          // ldr           q0, [x8, #64]
  .long  0x3dc00110                          // ldr           q16, [x8]
  .long  0x4ea0d620                          // fsub          v0.4s, v17.4s, v0.4s
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e0                          // movi          v0.4s, #0xbf, lsl #24
  .long  0x4e20d600                          // fadd          v0.4s, v16.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_px_aarch64
.globl _sk_bilinear_px_aarch64
_sk_bilinear_px_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x3dc01100                          // ldr           q0, [x8, #64]
  .long  0x3dc00110                          // ldr           q16, [x8]
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0167e0                          // movi          v0.4s, #0x3f, lsl #24
  .long  0x4e20d600                          // fadd          v0.4s, v16.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_ny_aarch64
.globl _sk_bilinear_ny_aarch64
_sk_bilinear_ny_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x3dc01901                          // ldr           q1, [x8, #96]
  .long  0x3dc00910                          // ldr           q16, [x8, #32]
  .long  0x4ea1d621                          // fsub          v1.4s, v17.4s, v1.4s
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e1                          // movi          v1.4s, #0xbf, lsl #24
  .long  0x4e21d601                          // fadd          v1.4s, v16.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_py_aarch64
.globl _sk_bilinear_py_aarch64
_sk_bilinear_py_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x3dc01901                          // ldr           q1, [x8, #96]
  .long  0x3dc00910                          // ldr           q16, [x8, #32]
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0167e1                          // movi          v1.4s, #0x3f, lsl #24
  .long  0x4e21d601                          // fadd          v1.4s, v16.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n3x_aarch64
.globl _sk_bicubic_n3x_aarch64
_sk_bicubic_n3x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x3dc01111                          // ldr           q17, [x8, #64]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x4f03f600                          // fmov          v0.4s, #1.000000000000000000e+00
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x4eb1d400                          // fsub          v0.4s, v0.4s, v17.4s
  .long  0x6e20dc11                          // fmul          v17.4s, v0.4s, v0.4s
  .long  0x4e20ce12                          // fmla          v18.4s, v16.4s, v0.4s
  .long  0x6e32de20                          // fmul          v0.4s, v17.4s, v18.4s
  .long  0x3dc00113                          // ldr           q19, [x8]
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f07f700                          // fmov          v0.4s, #-1.500000000000000000e+00
  .long  0x4e20d660                          // fadd          v0.4s, v19.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n1x_aarch64
.globl _sk_bicubic_n1x_aarch64
_sk_bicubic_n1x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x4f03f600                          // fmov          v0.4s, #1.000000000000000000e+00
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x3dc01110                          // ldr           q16, [x8, #64]
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x4f0167f2                          // movi          v18.4s, #0x3f, lsl #24
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e20ce11                          // fmla          v17.4s, v16.4s, v0.4s
  .long  0x4e20ce32                          // fmla          v18.4s, v17.4s, v0.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e20ce51                          // fmla          v17.4s, v18.4s, v0.4s
  .long  0x3dc00110                          // ldr           q16, [x8]
  .long  0x3d802111                          // str           q17, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e0                          // movi          v0.4s, #0xbf, lsl #24
  .long  0x4e20d600                          // fadd          v0.4s, v16.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p1x_aarch64
.globl _sk_bicubic_p1x_aarch64
_sk_bicubic_p1x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x3dc01112                          // ldr           q18, [x8, #64]
  .long  0x3dc00100                          // ldr           q0, [x8]
  .long  0x4e040d33                          // dup           v19.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x4f0167f0                          // movi          v16.4s, #0x3f, lsl #24
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e32ce71                          // fmla          v17.4s, v19.4s, v18.4s
  .long  0x4e30d400                          // fadd          v0.4s, v0.4s, v16.4s
  .long  0x4e32ce30                          // fmla          v16.4s, v17.4s, v18.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e32ce11                          // fmla          v17.4s, v16.4s, v18.4s
  .long  0x3d802111                          // str           q17, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p3x_aarch64
.globl _sk_bicubic_p3x_aarch64
_sk_bicubic_p3x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d20                          // dup           v0.4s, w9
  .long  0x3dc01110                          // ldr           q16, [x8, #64]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x6e30de13                          // fmul          v19.4s, v16.4s, v16.4s
  .long  0x4e30cc11                          // fmla          v17.4s, v0.4s, v16.4s
  .long  0x6e31de60                          // fmul          v0.4s, v19.4s, v17.4s
  .long  0x3dc00112                          // ldr           q18, [x8]
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f03f700                          // fmov          v0.4s, #1.500000000000000000e+00
  .long  0x4e20d640                          // fadd          v0.4s, v18.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n3y_aarch64
.globl _sk_bicubic_n3y_aarch64
_sk_bicubic_n3y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x3dc01911                          // ldr           q17, [x8, #96]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x4f03f601                          // fmov          v1.4s, #1.000000000000000000e+00
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x4eb1d421                          // fsub          v1.4s, v1.4s, v17.4s
  .long  0x6e21dc31                          // fmul          v17.4s, v1.4s, v1.4s
  .long  0x4e21ce12                          // fmla          v18.4s, v16.4s, v1.4s
  .long  0x6e32de21                          // fmul          v1.4s, v17.4s, v18.4s
  .long  0x3dc00913                          // ldr           q19, [x8, #32]
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f07f701                          // fmov          v1.4s, #-1.500000000000000000e+00
  .long  0x4e21d661                          // fadd          v1.4s, v19.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n1y_aarch64
.globl _sk_bicubic_n1y_aarch64
_sk_bicubic_n1y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x4f03f601                          // fmov          v1.4s, #1.000000000000000000e+00
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x3dc01910                          // ldr           q16, [x8, #96]
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x4f0167f2                          // movi          v18.4s, #0x3f, lsl #24
  .long  0x4eb0d421                          // fsub          v1.4s, v1.4s, v16.4s
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e21ce11                          // fmla          v17.4s, v16.4s, v1.4s
  .long  0x4e21ce32                          // fmla          v18.4s, v17.4s, v1.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e21ce51                          // fmla          v17.4s, v18.4s, v1.4s
  .long  0x3dc00910                          // ldr           q16, [x8, #32]
  .long  0x3d802911                          // str           q17, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e1                          // movi          v1.4s, #0xbf, lsl #24
  .long  0x4e21d601                          // fadd          v1.4s, v16.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p1y_aarch64
.globl _sk_bicubic_p1y_aarch64
_sk_bicubic_p1y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x3dc01912                          // ldr           q18, [x8, #96]
  .long  0x3dc00901                          // ldr           q1, [x8, #32]
  .long  0x4e040d33                          // dup           v19.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x4f0167f0                          // movi          v16.4s, #0x3f, lsl #24
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e32ce71                          // fmla          v17.4s, v19.4s, v18.4s
  .long  0x4e30d421                          // fadd          v1.4s, v1.4s, v16.4s
  .long  0x4e32ce30                          // fmla          v16.4s, v17.4s, v18.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e32ce11                          // fmla          v17.4s, v16.4s, v18.4s
  .long  0x3d802911                          // str           q17, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p3y_aarch64
.globl _sk_bicubic_p3y_aarch64
_sk_bicubic_p3y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d21                          // dup           v1.4s, w9
  .long  0x3dc01910                          // ldr           q16, [x8, #96]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x6e30de13                          // fmul          v19.4s, v16.4s, v16.4s
  .long  0x4e30cc31                          // fmla          v17.4s, v1.4s, v16.4s
  .long  0x6e31de61                          // fmul          v1.4s, v19.4s, v17.4s
  .long  0x3dc00912                          // ldr           q18, [x8, #32]
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f03f701                          // fmov          v1.4s, #1.500000000000000000e+00
  .long  0x4e21d641                          // fadd          v1.4s, v18.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3
#elif defined(__arm__)
.balign 4

HIDDEN _sk_start_pipeline_vfp4
.globl _sk_start_pipeline_vfp4
_sk_start_pipeline_vfp4:
  .long  0xe92d41f0                          // push          {r4, r5, r6, r7, r8, lr}
  .long  0xe1a04000                          // mov           r4, r0
  .long  0xe2840002                          // add           r0, r4, #2
  .long  0xe1a05003                          // mov           r5, r3
  .long  0xe1a08002                          // mov           r8, r2
  .long  0xe1a07001                          // mov           r7, r1
  .long  0xe1500005                          // cmp           r0, r5
  .long  0x8a000010                          // bhi           64 <sk_start_pipeline_vfp4+0x64>
  .long  0xe4976004                          // ldr           r6, [r7], #4
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xe1a00004                          // mov           r0, r4
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xe1a01007                          // mov           r1, r7
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xe1a02008                          // mov           r2, r8
  .long  0xf2803010                          // vmov.i32      d3, #0
  .long  0xf2804010                          // vmov.i32      d4, #0
  .long  0xf2805010                          // vmov.i32      d5, #0
  .long  0xf2806010                          // vmov.i32      d6, #0
  .long  0xf2807010                          // vmov.i32      d7, #0
  .long  0xe12fff36                          // blx           r6
  .long  0xe2840004                          // add           r0, r4, #4
  .long  0xe2844002                          // add           r4, r4, #2
  .long  0xe1500005                          // cmp           r0, r5
  .long  0x9affffef                          // bls           24 <sk_start_pipeline_vfp4+0x24>
  .long  0xe1a00004                          // mov           r0, r4
  .long  0xe8bd81f0                          // pop           {r4, r5, r6, r7, r8, pc}

HIDDEN _sk_just_return_vfp4
.globl _sk_just_return_vfp4
_sk_just_return_vfp4:
  .long  0xe12fff1e                          // bx            lr

HIDDEN _sk_seed_shader_vfp4
.globl _sk_seed_shader_vfp4
_sk_seed_shader_vfp4:
  .long  0xee800b90                          // vdup.32       d16, r0
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xedd23b00                          // vldr          d19, [r2]
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf2872f10                          // vmov.f32      d2, #1
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2400da1                          // vadd.f32      d16, d16, d17
  .long  0xf2803010                          // vmov.i32      d3, #0
  .long  0xf2804010                          // vmov.i32      d4, #0
  .long  0xf2021da1                          // vadd.f32      d1, d18, d17
  .long  0xf2000da3                          // vadd.f32      d0, d16, d19
  .long  0xf2805010                          // vmov.i32      d5, #0
  .long  0xf2806010                          // vmov.i32      d6, #0
  .long  0xf2807010                          // vmov.i32      d7, #0
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_constant_color_vfp4
.globl _sk_constant_color_vfp4
_sk_constant_color_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe283400c                          // add           r4, r3, #12
  .long  0xe1a0e003                          // mov           lr, r3
  .long  0xe2833008                          // add           r3, r3, #8
  .long  0xf4ae0c9d                          // vld1.32       {d0[]}, [lr :32]!
  .long  0xf4a43c9f                          // vld1.32       {d3[]}, [r4 :32]
  .long  0xf4a32c9f                          // vld1.32       {d2[]}, [r3 :32]
  .long  0xf4ae1c9f                          // vld1.32       {d1[]}, [lr :32]
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_clear_vfp4
.globl _sk_clear_vfp4
_sk_clear_vfp4:
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xf2803010                          // vmov.i32      d3, #0
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcatop_vfp4
.globl _sk_srcatop_vfp4
_sk_srcatop_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2603d83                          // vsub.f32      d19, d16, d3
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xf3430d94                          // vmul.f32      d16, d19, d4
  .long  0xf3431d95                          // vmul.f32      d17, d19, d5
  .long  0xf3432d96                          // vmul.f32      d18, d19, d6
  .long  0xf2400c17                          // vfma.f32      d16, d0, d7
  .long  0xf2411c17                          // vfma.f32      d17, d1, d7
  .long  0xf2422c17                          // vfma.f32      d18, d2, d7
  .long  0xf2033c97                          // vfma.f32      d3, d19, d7
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstatop_vfp4
.globl _sk_dstatop_vfp4
_sk_dstatop_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3431d15                          // vmul.f32      d17, d3, d5
  .long  0xf2604d87                          // vsub.f32      d20, d16, d7
  .long  0xf3430d14                          // vmul.f32      d16, d3, d4
  .long  0xf3432d16                          // vmul.f32      d18, d3, d6
  .long  0xf3433d17                          // vmul.f32      d19, d3, d7
  .long  0xf2440c90                          // vfma.f32      d16, d20, d0
  .long  0xf2441c91                          // vfma.f32      d17, d20, d1
  .long  0xf2442c92                          // vfma.f32      d18, d20, d2
  .long  0xf2443c93                          // vfma.f32      d19, d20, d3
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcin_vfp4
.globl _sk_srcin_vfp4
_sk_srcin_vfp4:
  .long  0xf3000d17                          // vmul.f32      d0, d0, d7
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3011d17                          // vmul.f32      d1, d1, d7
  .long  0xf3022d17                          // vmul.f32      d2, d2, d7
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstin_vfp4
.globl _sk_dstin_vfp4
_sk_dstin_vfp4:
  .long  0xf3030d14                          // vmul.f32      d0, d3, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3031d15                          // vmul.f32      d1, d3, d5
  .long  0xf3032d16                          // vmul.f32      d2, d3, d6
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcout_vfp4
.globl _sk_srcout_vfp4
_sk_srcout_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2600d87                          // vsub.f32      d16, d16, d7
  .long  0xf3000d90                          // vmul.f32      d0, d16, d0
  .long  0xf3001d91                          // vmul.f32      d1, d16, d1
  .long  0xf3002d92                          // vmul.f32      d2, d16, d2
  .long  0xf3003d93                          // vmul.f32      d3, d16, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstout_vfp4
.globl _sk_dstout_vfp4
_sk_dstout_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3000d94                          // vmul.f32      d0, d16, d4
  .long  0xf3001d95                          // vmul.f32      d1, d16, d5
  .long  0xf3002d96                          // vmul.f32      d2, d16, d6
  .long  0xf3003d97                          // vmul.f32      d3, d16, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcover_vfp4
.globl _sk_srcover_vfp4
_sk_srcover_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf2040c30                          // vfma.f32      d0, d4, d16
  .long  0xf2051c30                          // vfma.f32      d1, d5, d16
  .long  0xf2062c30                          // vfma.f32      d2, d6, d16
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstover_vfp4
.globl _sk_dstover_vfp4
_sk_dstover_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2651115                          // vorr          d17, d5, d5
  .long  0xf2604d87                          // vsub.f32      d20, d16, d7
  .long  0xf2640114                          // vorr          d16, d4, d4
  .long  0xf2662116                          // vorr          d18, d6, d6
  .long  0xf2673117                          // vorr          d19, d7, d7
  .long  0xf2400c34                          // vfma.f32      d16, d0, d20
  .long  0xf2411c34                          // vfma.f32      d17, d1, d20
  .long  0xf2422c34                          // vfma.f32      d18, d2, d20
  .long  0xf2433c34                          // vfma.f32      d19, d3, d20
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_modulate_vfp4
.globl _sk_modulate_vfp4
_sk_modulate_vfp4:
  .long  0xf3000d14                          // vmul.f32      d0, d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3011d15                          // vmul.f32      d1, d1, d5
  .long  0xf3022d16                          // vmul.f32      d2, d2, d6
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_multiply_vfp4
.globl _sk_multiply_vfp4
_sk_multiply_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2601d87                          // vsub.f32      d17, d16, d7
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3412d90                          // vmul.f32      d18, d17, d0
  .long  0xf3403d94                          // vmul.f32      d19, d16, d4
  .long  0xf3414d91                          // vmul.f32      d20, d17, d1
  .long  0xf3405d95                          // vmul.f32      d21, d16, d5
  .long  0xf3416d92                          // vmul.f32      d22, d17, d2
  .long  0xf3418d93                          // vmul.f32      d24, d17, d3
  .long  0xf3407d96                          // vmul.f32      d23, d16, d6
  .long  0xf3409d97                          // vmul.f32      d25, d16, d7
  .long  0xf2430da2                          // vadd.f32      d16, d19, d18
  .long  0xf2451da4                          // vadd.f32      d17, d21, d20
  .long  0xf2472da6                          // vadd.f32      d18, d23, d22
  .long  0xf2493da8                          // vadd.f32      d19, d25, d24
  .long  0xf2400c14                          // vfma.f32      d16, d0, d4
  .long  0xf2411c15                          // vfma.f32      d17, d1, d5
  .long  0xf2422c16                          // vfma.f32      d18, d2, d6
  .long  0xf2433c17                          // vfma.f32      d19, d3, d7
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_plus__vfp4
.globl _sk_plus__vfp4
_sk_plus__vfp4:
  .long  0xf2000d04                          // vadd.f32      d0, d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2011d05                          // vadd.f32      d1, d1, d5
  .long  0xf2022d06                          // vadd.f32      d2, d2, d6
  .long  0xf2033d07                          // vadd.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_screen_vfp4
.globl _sk_screen_vfp4
_sk_screen_vfp4:
  .long  0xf2400d04                          // vadd.f32      d16, d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2411d05                          // vadd.f32      d17, d1, d5
  .long  0xf2422d06                          // vadd.f32      d18, d2, d6
  .long  0xf2433d07                          // vadd.f32      d19, d3, d7
  .long  0xf2600c14                          // vfms.f32      d16, d0, d4
  .long  0xf2611c15                          // vfms.f32      d17, d1, d5
  .long  0xf2622c16                          // vfms.f32      d18, d2, d6
  .long  0xf2633c17                          // vfms.f32      d19, d3, d7
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_xor__vfp4
.globl _sk_xor__vfp4
_sk_xor__vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2603d83                          // vsub.f32      d19, d16, d3
  .long  0xf2604d87                          // vsub.f32      d20, d16, d7
  .long  0xf3430d94                          // vmul.f32      d16, d19, d4
  .long  0xf3431d95                          // vmul.f32      d17, d19, d5
  .long  0xf3432d96                          // vmul.f32      d18, d19, d6
  .long  0xf3433d97                          // vmul.f32      d19, d19, d7
  .long  0xf2440c90                          // vfma.f32      d16, d20, d0
  .long  0xf2441c91                          // vfma.f32      d17, d20, d1
  .long  0xf2442c92                          // vfma.f32      d18, d20, d2
  .long  0xf2443c93                          // vfma.f32      d19, d20, d3
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_darken_vfp4
.globl _sk_darken_vfp4
_sk_darken_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3431d14                          // vmul.f32      d17, d3, d4
  .long  0xf3402d17                          // vmul.f32      d18, d0, d7
  .long  0xf3433d15                          // vmul.f32      d19, d3, d5
  .long  0xf3414d17                          // vmul.f32      d20, d1, d7
  .long  0xf3435d16                          // vmul.f32      d21, d3, d6
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3426d17                          // vmul.f32      d22, d2, d7
  .long  0xf2421fa1                          // vmax.f32      d17, d18, d17
  .long  0xf2407d04                          // vadd.f32      d23, d0, d4
  .long  0xf2443fa3                          // vmax.f32      d19, d20, d19
  .long  0xf2412d05                          // vadd.f32      d18, d1, d5
  .long  0xf2424d06                          // vadd.f32      d20, d2, d6
  .long  0xf2465fa5                          // vmax.f32      d21, d22, d21
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2270da1                          // vsub.f32      d0, d23, d17
  .long  0xf2221da3                          // vsub.f32      d1, d18, d19
  .long  0xf2242da5                          // vsub.f32      d2, d20, d21
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_lighten_vfp4
.globl _sk_lighten_vfp4
_sk_lighten_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3431d14                          // vmul.f32      d17, d3, d4
  .long  0xf3402d17                          // vmul.f32      d18, d0, d7
  .long  0xf3433d15                          // vmul.f32      d19, d3, d5
  .long  0xf3414d17                          // vmul.f32      d20, d1, d7
  .long  0xf3435d16                          // vmul.f32      d21, d3, d6
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3426d17                          // vmul.f32      d22, d2, d7
  .long  0xf2621fa1                          // vmin.f32      d17, d18, d17
  .long  0xf2407d04                          // vadd.f32      d23, d0, d4
  .long  0xf2643fa3                          // vmin.f32      d19, d20, d19
  .long  0xf2412d05                          // vadd.f32      d18, d1, d5
  .long  0xf2424d06                          // vadd.f32      d20, d2, d6
  .long  0xf2665fa5                          // vmin.f32      d21, d22, d21
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2270da1                          // vsub.f32      d0, d23, d17
  .long  0xf2221da3                          // vsub.f32      d1, d18, d19
  .long  0xf2242da5                          // vsub.f32      d2, d20, d21
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_difference_vfp4
.globl _sk_difference_vfp4
_sk_difference_vfp4:
  .long  0xf3430d14                          // vmul.f32      d16, d3, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3401d17                          // vmul.f32      d17, d0, d7
  .long  0xf3432d15                          // vmul.f32      d18, d3, d5
  .long  0xf3413d17                          // vmul.f32      d19, d1, d7
  .long  0xf3434d16                          // vmul.f32      d20, d3, d6
  .long  0xf3425d17                          // vmul.f32      d21, d2, d7
  .long  0xf2c76f10                          // vmov.f32      d22, #1
  .long  0xf2610fa0                          // vmin.f32      d16, d17, d16
  .long  0xf2631fa2                          // vmin.f32      d17, d19, d18
  .long  0xf2662d83                          // vsub.f32      d18, d22, d3
  .long  0xf2653fa4                          // vmin.f32      d19, d21, d20
  .long  0xf2404d04                          // vadd.f32      d20, d0, d4
  .long  0xf2400da0                          // vadd.f32      d16, d16, d16
  .long  0xf2073c32                          // vfma.f32      d3, d7, d18
  .long  0xf2415d05                          // vadd.f32      d21, d1, d5
  .long  0xf2411da1                          // vadd.f32      d17, d17, d17
  .long  0xf2426d06                          // vadd.f32      d22, d2, d6
  .long  0xf2432da3                          // vadd.f32      d18, d19, d19
  .long  0xf2240da0                          // vsub.f32      d0, d20, d16
  .long  0xf2251da1                          // vsub.f32      d1, d21, d17
  .long  0xf2262da2                          // vsub.f32      d2, d22, d18
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_exclusion_vfp4
.globl _sk_exclusion_vfp4
_sk_exclusion_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3401d14                          // vmul.f32      d17, d0, d4
  .long  0xf3412d15                          // vmul.f32      d18, d1, d5
  .long  0xf3423d16                          // vmul.f32      d19, d2, d6
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf2404d04                          // vadd.f32      d20, d0, d4
  .long  0xf2411da1                          // vadd.f32      d17, d17, d17
  .long  0xf2415d05                          // vadd.f32      d21, d1, d5
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf2426d06                          // vadd.f32      d22, d2, d6
  .long  0xf2433da3                          // vadd.f32      d19, d19, d19
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2240da1                          // vsub.f32      d0, d20, d17
  .long  0xf2251da2                          // vsub.f32      d1, d21, d18
  .long  0xf2262da3                          // vsub.f32      d2, d22, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_colorburn_vfp4
.globl _sk_colorburn_vfp4
_sk_colorburn_vfp4:
  .long  0xed2d8b08                          // vpush         {d8-d11}
  .long  0xf2670d04                          // vsub.f32      d16, d7, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2671d06                          // vsub.f32      d17, d7, d6
  .long  0xf2672d05                          // vsub.f32      d18, d7, d5
  .long  0xf3008d93                          // vmul.f32      d8, d16, d3
  .long  0xf3019d93                          // vmul.f32      d9, d17, d3
  .long  0xf302ad93                          // vmul.f32      d10, d18, d3
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xeec8baa0                          // vdiv.f32      s23, s17, s1
  .long  0xee88ba00                          // vdiv.f32      s22, s16, s0
  .long  0xeec98aa2                          // vdiv.f32      s17, s19, s5
  .long  0xee898a02                          // vdiv.f32      s16, s18, s4
  .long  0xeeca9aa1                          // vdiv.f32      s19, s21, s3
  .long  0xee8a9a01                          // vdiv.f32      s18, s20, s2
  .long  0xf2672f08                          // vmin.f32      d18, d7, d8
  .long  0xf2673f09                          // vmin.f32      d19, d7, d9
  .long  0xf2670f0b                          // vmin.f32      d16, d7, d11
  .long  0xf2614d87                          // vsub.f32      d20, d17, d7
  .long  0xf2672d22                          // vsub.f32      d18, d7, d18
  .long  0xf2673d23                          // vsub.f32      d19, d7, d19
  .long  0xf2611d83                          // vsub.f32      d17, d17, d3
  .long  0xf2670d20                          // vsub.f32      d16, d7, d16
  .long  0xf3445d90                          // vmul.f32      d21, d20, d0
  .long  0xf3446d92                          // vmul.f32      d22, d20, d2
  .long  0xf3422d93                          // vmul.f32      d18, d18, d3
  .long  0xf3444d91                          // vmul.f32      d20, d20, d1
  .long  0xf3433d93                          // vmul.f32      d19, d19, d3
  .long  0xf3400d93                          // vmul.f32      d16, d16, d3
  .long  0xf3417d95                          // vmul.f32      d23, d17, d5
  .long  0xf3418d94                          // vmul.f32      d24, d17, d4
  .long  0xf3419d96                          // vmul.f32      d25, d17, d6
  .long  0xf2443da3                          // vadd.f32      d19, d20, d19
  .long  0xf2462da2                          // vadd.f32      d18, d22, d18
  .long  0xf245ada0                          // vadd.f32      d26, d21, d16
  .long  0xf247bd81                          // vadd.f32      d27, d23, d1
  .long  0xf248cd80                          // vadd.f32      d28, d24, d0
  .long  0xf249dd82                          // vadd.f32      d29, d25, d2
  .long  0xf2073c31                          // vfma.f32      d3, d7, d17
  .long  0xf2499da2                          // vadd.f32      d25, d25, d18
  .long  0xf2473da3                          // vadd.f32      d19, d23, d19
  .long  0xf3f97501                          // vceq.f32      d23, d1, #0
  .long  0xf2455d84                          // vadd.f32      d21, d21, d4
  .long  0xf2444d85                          // vadd.f32      d20, d20, d5
  .long  0xf2440e07                          // vceq.f32      d16, d4, d7
  .long  0xf2466d86                          // vadd.f32      d22, d22, d6
  .long  0xf2451e07                          // vceq.f32      d17, d5, d7
  .long  0xf2462e07                          // vceq.f32      d18, d6, d7
  .long  0xf35b71b3                          // vbsl          d23, d27, d19
  .long  0xf3f93500                          // vceq.f32      d19, d0, #0
  .long  0xf2488daa                          // vadd.f32      d24, d24, d26
  .long  0xf35c31b8                          // vbsl          d19, d28, d24
  .long  0xf3f98502                          // vceq.f32      d24, d2, #0
  .long  0xf35d81b9                          // vbsl          d24, d29, d25
  .long  0xf35501b3                          // vbsl          d16, d21, d19
  .long  0xf35411b7                          // vbsl          d17, d20, d23
  .long  0xf35621b8                          // vbsl          d18, d22, d24
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xecbd8b08                          // vpop          {d8-d11}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_colordodge_vfp4
.globl _sk_colordodge_vfp4
_sk_colordodge_vfp4:
  .long  0xed2d8b0e                          // vpush         {d8-d14}
  .long  0xf2238d02                          // vsub.f32      d8, d3, d2
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3039d16                          // vmul.f32      d9, d3, d6
  .long  0xf223ad01                          // vsub.f32      d10, d3, d1
  .long  0xf303bd15                          // vmul.f32      d11, d3, d5
  .long  0xf223cd00                          // vsub.f32      d12, d3, d0
  .long  0xf303dd14                          // vmul.f32      d13, d3, d4
  .long  0xeec9eaa8                          // vdiv.f32      s29, s19, s17
  .long  0xee89ea08                          // vdiv.f32      s28, s18, s16
  .long  0xeecb8aaa                          // vdiv.f32      s17, s23, s21
  .long  0xeecd9aac                          // vdiv.f32      s19, s27, s25
  .long  0xee8b8a0a                          // vdiv.f32      s16, s22, s20
  .long  0xee8d9a0c                          // vdiv.f32      s18, s26, s24
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xf2672f0e                          // vmin.f32      d18, d7, d14
  .long  0xf2601d87                          // vsub.f32      d17, d16, d7
  .long  0xf2673f08                          // vmin.f32      d19, d7, d8
  .long  0xf2674f09                          // vmin.f32      d20, d7, d9
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3415d92                          // vmul.f32      d21, d17, d2
  .long  0xf3422d93                          // vmul.f32      d18, d18, d3
  .long  0xf3416d91                          // vmul.f32      d22, d17, d1
  .long  0xf3433d93                          // vmul.f32      d19, d19, d3
  .long  0xf3411d90                          // vmul.f32      d17, d17, d0
  .long  0xf3444d93                          // vmul.f32      d20, d20, d3
  .long  0xf3407d95                          // vmul.f32      d23, d16, d5
  .long  0xf3408d94                          // vmul.f32      d24, d16, d4
  .long  0xf3409d96                          // vmul.f32      d25, d16, d6
  .long  0xf2452da2                          // vadd.f32      d18, d21, d18
  .long  0xf2463da3                          // vadd.f32      d19, d22, d19
  .long  0xf2414da4                          // vadd.f32      d20, d17, d20
  .long  0xf241ae03                          // vceq.f32      d26, d1, d3
  .long  0xf247bd81                          // vadd.f32      d27, d23, d1
  .long  0xf3b91505                          // vceq.f32      d1, d5, #0
  .long  0xf240ce03                          // vceq.f32      d28, d0, d3
  .long  0xf248dd80                          // vadd.f32      d29, d24, d0
  .long  0xf3b90504                          // vceq.f32      d0, d4, #0
  .long  0xf242ee03                          // vceq.f32      d30, d2, d3
  .long  0xf249fd82                          // vadd.f32      d31, d25, d2
  .long  0xf3b92506                          // vceq.f32      d2, d6, #0
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2410d84                          // vadd.f32      d16, d17, d4
  .long  0xf2491da2                          // vadd.f32      d17, d25, d18
  .long  0xf2462d85                          // vadd.f32      d18, d22, d5
  .long  0xf2455d86                          // vadd.f32      d21, d21, d6
  .long  0xf2473da3                          // vadd.f32      d19, d23, d19
  .long  0xf2484da4                          // vadd.f32      d20, d24, d20
  .long  0xf35fe1b1                          // vbsl          d30, d31, d17
  .long  0xf35ba1b3                          // vbsl          d26, d27, d19
  .long  0xf35dc1b4                          // vbsl          d28, d29, d20
  .long  0xf31001bc                          // vbsl          d0, d16, d28
  .long  0xf31211ba                          // vbsl          d1, d18, d26
  .long  0xf31521be                          // vbsl          d2, d21, d30
  .long  0xecbd8b0e                          // vpop          {d8-d14}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_hardlight_vfp4
.globl _sk_hardlight_vfp4
_sk_hardlight_vfp4:
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2670d04                          // vsub.f32      d16, d7, d4
  .long  0xf2617d87                          // vsub.f32      d23, d17, d7
  .long  0xf2611d83                          // vsub.f32      d17, d17, d3
  .long  0xf2672d05                          // vsub.f32      d18, d7, d5
  .long  0xf2674d06                          // vsub.f32      d20, d7, d6
  .long  0xf2633d00                          // vsub.f32      d19, d3, d0
  .long  0xf2635d01                          // vsub.f32      d21, d3, d1
  .long  0xf2636d02                          // vsub.f32      d22, d3, d2
  .long  0xf347bd90                          // vmul.f32      d27, d23, d0
  .long  0xf341cd94                          // vmul.f32      d28, d17, d4
  .long  0xf3430db0                          // vmul.f32      d16, d19, d16
  .long  0xf3463db4                          // vmul.f32      d19, d22, d20
  .long  0xf3452db2                          // vmul.f32      d18, d21, d18
  .long  0xf2404d00                          // vadd.f32      d20, d0, d0
  .long  0xf3405d14                          // vmul.f32      d21, d0, d4
  .long  0xf2416d01                          // vadd.f32      d22, d1, d1
  .long  0xf3418d15                          // vmul.f32      d24, d1, d5
  .long  0xf2429d02                          // vadd.f32      d25, d2, d2
  .long  0xf342ad16                          // vmul.f32      d26, d2, d6
  .long  0xf347dd91                          // vmul.f32      d29, d23, d1
  .long  0xf341fd95                          // vmul.f32      d31, d17, d5
  .long  0xf24cbdab                          // vadd.f32      d27, d28, d27
  .long  0xf3477d92                          // vmul.f32      d23, d23, d2
  .long  0xf341cd96                          // vmul.f32      d28, d17, d6
  .long  0xf2400da0                          // vadd.f32      d16, d16, d16
  .long  0xf343ed17                          // vmul.f32      d30, d3, d7
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf2433da3                          // vadd.f32      d19, d19, d19
  .long  0xf3434e24                          // vcge.f32      d20, d3, d20
  .long  0xf2455da5                          // vadd.f32      d21, d21, d21
  .long  0xf3436e26                          // vcge.f32      d22, d3, d22
  .long  0xf3439e29                          // vcge.f32      d25, d3, d25
  .long  0xf2488da8                          // vadd.f32      d24, d24, d24
  .long  0xf24aadaa                          // vadd.f32      d26, d26, d26
  .long  0xf2073c31                          // vfma.f32      d3, d7, d17
  .long  0xf24fddad                          // vadd.f32      d29, d31, d29
  .long  0xf24c1da7                          // vadd.f32      d17, d28, d23
  .long  0xf26e0da0                          // vsub.f32      d16, d30, d16
  .long  0xf26e2da2                          // vsub.f32      d18, d30, d18
  .long  0xf26e3da3                          // vsub.f32      d19, d30, d19
  .long  0xf35541b0                          // vbsl          d20, d21, d16
  .long  0xf35861b2                          // vbsl          d22, d24, d18
  .long  0xf35a91b3                          // vbsl          d25, d26, d19
  .long  0xf20b0da4                          // vadd.f32      d0, d27, d20
  .long  0xf20d1da6                          // vadd.f32      d1, d29, d22
  .long  0xf2012da9                          // vadd.f32      d2, d17, d25
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_overlay_vfp4
.globl _sk_overlay_vfp4
_sk_overlay_vfp4:
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2670d04                          // vsub.f32      d16, d7, d4
  .long  0xf2617d87                          // vsub.f32      d23, d17, d7
  .long  0xf2611d83                          // vsub.f32      d17, d17, d3
  .long  0xf2672d05                          // vsub.f32      d18, d7, d5
  .long  0xf2674d06                          // vsub.f32      d20, d7, d6
  .long  0xf2633d00                          // vsub.f32      d19, d3, d0
  .long  0xf2635d01                          // vsub.f32      d21, d3, d1
  .long  0xf2636d02                          // vsub.f32      d22, d3, d2
  .long  0xf347bd90                          // vmul.f32      d27, d23, d0
  .long  0xf341cd94                          // vmul.f32      d28, d17, d4
  .long  0xf3430db0                          // vmul.f32      d16, d19, d16
  .long  0xf3463db4                          // vmul.f32      d19, d22, d20
  .long  0xf3452db2                          // vmul.f32      d18, d21, d18
  .long  0xf2444d04                          // vadd.f32      d20, d4, d4
  .long  0xf3405d14                          // vmul.f32      d21, d0, d4
  .long  0xf2456d05                          // vadd.f32      d22, d5, d5
  .long  0xf3418d15                          // vmul.f32      d24, d1, d5
  .long  0xf2469d06                          // vadd.f32      d25, d6, d6
  .long  0xf342ad16                          // vmul.f32      d26, d2, d6
  .long  0xf347dd91                          // vmul.f32      d29, d23, d1
  .long  0xf341fd95                          // vmul.f32      d31, d17, d5
  .long  0xf24cbdab                          // vadd.f32      d27, d28, d27
  .long  0xf3477d92                          // vmul.f32      d23, d23, d2
  .long  0xf341cd96                          // vmul.f32      d28, d17, d6
  .long  0xf343ed17                          // vmul.f32      d30, d3, d7
  .long  0xf2400da0                          // vadd.f32      d16, d16, d16
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf2433da3                          // vadd.f32      d19, d19, d19
  .long  0xf3474e24                          // vcge.f32      d20, d7, d20
  .long  0xf2455da5                          // vadd.f32      d21, d21, d21
  .long  0xf3476e26                          // vcge.f32      d22, d7, d22
  .long  0xf2488da8                          // vadd.f32      d24, d24, d24
  .long  0xf3479e29                          // vcge.f32      d25, d7, d25
  .long  0xf24aadaa                          // vadd.f32      d26, d26, d26
  .long  0xf2073c31                          // vfma.f32      d3, d7, d17
  .long  0xf24fddad                          // vadd.f32      d29, d31, d29
  .long  0xf24c1da7                          // vadd.f32      d17, d28, d23
  .long  0xf26e0da0                          // vsub.f32      d16, d30, d16
  .long  0xf26e2da2                          // vsub.f32      d18, d30, d18
  .long  0xf26e3da3                          // vsub.f32      d19, d30, d19
  .long  0xf35541b0                          // vbsl          d20, d21, d16
  .long  0xf35861b2                          // vbsl          d22, d24, d18
  .long  0xf35a91b3                          // vbsl          d25, d26, d19
  .long  0xf20b0da4                          // vadd.f32      d0, d27, d20
  .long  0xf20d1da6                          // vadd.f32      d1, d29, d22
  .long  0xf2012da9                          // vadd.f32      d2, d17, d25
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_softlight_vfp4
.globl _sk_softlight_vfp4
_sk_softlight_vfp4:
  .long  0xed2d8b06                          // vpush         {d8-d10}
  .long  0xeec58aa7                          // vdiv.f32      s17, s11, s15
  .long  0xf3f90407                          // vcgt.f32      d16, d7, #0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeec49aa7                          // vdiv.f32      s19, s9, s15
  .long  0xeec6aaa7                          // vdiv.f32      s21, s13, s15
  .long  0xee858a07                          // vdiv.f32      s16, s10, s14
  .long  0xee849a07                          // vdiv.f32      s18, s8, s14
  .long  0xee86aa07                          // vdiv.f32      s20, s12, s14
  .long  0xf26021b0                          // vorr          d18, d16, d16
  .long  0xf2c01010                          // vmov.i32      d17, #0
  .long  0xf3582131                          // vbsl          d18, d8, d17
  .long  0xf26031b0                          // vorr          d19, d16, d16
  .long  0xf3fb45a2                          // vrsqrte.f32   d20, d18
  .long  0xf3593131                          // vbsl          d19, d9, d17
  .long  0xf35a0131                          // vbsl          d16, d10, d17
  .long  0xf3fb15a3                          // vrsqrte.f32   d17, d19
  .long  0xf3fb55a0                          // vrsqrte.f32   d21, d16
  .long  0xf3446db4                          // vmul.f32      d22, d20, d20
  .long  0xf243ada3                          // vadd.f32      d26, d19, d19
  .long  0xf240bda0                          // vadd.f32      d27, d16, d16
  .long  0xf3417db1                          // vmul.f32      d23, d17, d17
  .long  0xf3458db5                          // vmul.f32      d24, d21, d21
  .long  0xf2626fb6                          // vrsqrts.f32   d22, d18, d22
  .long  0xf2429da2                          // vadd.f32      d25, d18, d18
  .long  0xf2637fb7                          // vrsqrts.f32   d23, d19, d23
  .long  0xf2608fb8                          // vrsqrts.f32   d24, d16, d24
  .long  0xf2818f1c                          // vmov.f32      d8, #7
  .long  0xf2499da9                          // vadd.f32      d25, d25, d25
  .long  0xf3444db6                          // vmul.f32      d20, d20, d22
  .long  0xf24a6daa                          // vadd.f32      d22, d26, d26
  .long  0xf24badab                          // vadd.f32      d26, d27, d27
  .long  0xf3411db7                          // vmul.f32      d17, d17, d23
  .long  0xf3455db8                          // vmul.f32      d21, d21, d24
  .long  0xf3fb7524                          // vrecpe.f32    d23, d20
  .long  0xf3498db9                          // vmul.f32      d24, d25, d25
  .long  0xf3fbd521                          // vrecpe.f32    d29, d17
  .long  0xf34aedba                          // vmul.f32      d30, d26, d26
  .long  0xf3fbf525                          // vrecpe.f32    d31, d21
  .long  0xf2444fb7                          // vrecps.f32    d20, d20, d23
  .long  0xf346cdb6                          // vmul.f32      d28, d22, d22
  .long  0xf2411fbd                          // vrecps.f32    d17, d17, d29
  .long  0xf3c7bf10                          // vmov.f32      d27, #-1
  .long  0xf2455fbf                          // vrecps.f32    d21, d21, d31
  .long  0xf24aadae                          // vadd.f32      d26, d26, d30
  .long  0xf2498da8                          // vadd.f32      d24, d25, d24
  .long  0xf2429dab                          // vadd.f32      d25, d18, d27
  .long  0xf2466dac                          // vadd.f32      d22, d22, d28
  .long  0xf243cdab                          // vadd.f32      d28, d19, d27
  .long  0xf240bdab                          // vadd.f32      d27, d16, d27
  .long  0xf3474db4                          // vmul.f32      d20, d23, d20
  .long  0xf2c7ef10                          // vmov.f32      d30, #1
  .long  0xf34d1db1                          // vmul.f32      d17, d29, d17
  .long  0xf34badba                          // vmul.f32      d26, d27, d26
  .long  0xf242bd02                          // vadd.f32      d27, d2, d2
  .long  0xf26edda0                          // vsub.f32      d29, d30, d16
  .long  0xf3498db8                          // vmul.f32      d24, d25, d24
  .long  0xf3429d98                          // vmul.f32      d25, d18, d8
  .long  0xf34f5db5                          // vmul.f32      d21, d31, d21
  .long  0xf26efda2                          // vsub.f32      d31, d30, d18
  .long  0xf2642da2                          // vsub.f32      d18, d20, d18
  .long  0xf26b4d83                          // vsub.f32      d20, d27, d3
  .long  0xf2498da8                          // vadd.f32      d24, d25, d24
  .long  0xf34c6db6                          // vmul.f32      d22, d28, d22
  .long  0xf3437d98                          // vmul.f32      d23, d19, d8
  .long  0xf3449dbd                          // vmul.f32      d25, d20, d29
  .long  0xf245dd05                          // vadd.f32      d29, d5, d5
  .long  0xf340cd98                          // vmul.f32      d28, d16, d8
  .long  0xf2476da6                          // vadd.f32      d22, d23, d22
  .long  0xf2611da3                          // vsub.f32      d17, d17, d19
  .long  0xf24dddad                          // vadd.f32      d29, d29, d29
  .long  0xf24c7daa                          // vadd.f32      d23, d28, d26
  .long  0xf2650da0                          // vsub.f32      d16, d21, d16
  .long  0xf26e3da3                          // vsub.f32      d19, d30, d19
  .long  0xf347de2d                          // vcge.f32      d29, d7, d29
  .long  0xf241ad01                          // vadd.f32      d26, d1, d1
  .long  0xf3444d97                          // vmul.f32      d20, d20, d7
  .long  0xf358d1b2                          // vbsl          d29, d24, d18
  .long  0xf2448d04                          // vadd.f32      d24, d4, d4
  .long  0xf2462d06                          // vadd.f32      d18, d6, d6
  .long  0xf26a5d83                          // vsub.f32      d21, d26, d3
  .long  0xf2488da8                          // vadd.f32      d24, d24, d24
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf345cdbf                          // vmul.f32      d28, d21, d31
  .long  0xf3455d97                          // vmul.f32      d21, d21, d7
  .long  0xf3478e28                          // vcge.f32      d24, d7, d24
  .long  0xf3472e22                          // vcge.f32      d18, d7, d18
  .long  0xf343fd14                          // vmul.f32      d31, d3, d4
  .long  0xf3455dbd                          // vmul.f32      d21, d21, d29
  .long  0xf35681b1                          // vbsl          d24, d22, d17
  .long  0xf2401d00                          // vadd.f32      d17, d0, d0
  .long  0xf35721b0                          // vbsl          d18, d23, d16
  .long  0xf24c0d83                          // vadd.f32      d16, d28, d3
  .long  0xf2496d83                          // vadd.f32      d22, d25, d3
  .long  0xf2617d83                          // vsub.f32      d23, d17, d3
  .long  0xf3442db2                          // vmul.f32      d18, d20, d18
  .long  0xf3434e2a                          // vcge.f32      d20, d3, d26
  .long  0xf343ae2b                          // vcge.f32      d26, d3, d27
  .long  0xf3473db3                          // vmul.f32      d19, d23, d19
  .long  0xf3477d97                          // vmul.f32      d23, d23, d7
  .long  0xf3431e21                          // vcge.f32      d17, d3, d17
  .long  0xf3400d95                          // vmul.f32      d16, d16, d5
  .long  0xf2433d83                          // vadd.f32      d19, d19, d3
  .long  0xf3477db8                          // vmul.f32      d23, d23, d24
  .long  0xf26e8d87                          // vsub.f32      d24, d30, d7
  .long  0xf26eed83                          // vsub.f32      d30, d30, d3
  .long  0xf3433d94                          // vmul.f32      d19, d19, d4
  .long  0xf24f7da7                          // vadd.f32      d23, d31, d23
  .long  0xf3489d91                          // vmul.f32      d25, d24, d1
  .long  0xf348cd90                          // vmul.f32      d28, d24, d0
  .long  0xf34edd94                          // vmul.f32      d29, d30, d4
  .long  0xf34ebd95                          // vmul.f32      d27, d30, d5
  .long  0xf3488d92                          // vmul.f32      d24, d24, d2
  .long  0xf34efd96                          // vmul.f32      d31, d30, d6
  .long  0xf24dcdac                          // vadd.f32      d28, d29, d28
  .long  0xf343dd15                          // vmul.f32      d29, d3, d5
  .long  0xf24b9da9                          // vadd.f32      d25, d27, d25
  .long  0xf343bd16                          // vmul.f32      d27, d3, d6
  .long  0xf3466d96                          // vmul.f32      d22, d22, d6
  .long  0xf24f8da8                          // vadd.f32      d24, d31, d24
  .long  0xf24d5da5                          // vadd.f32      d21, d29, d21
  .long  0xf24b2da2                          // vadd.f32      d18, d27, d18
  .long  0xf35311b7                          // vbsl          d17, d19, d23
  .long  0xf35041b5                          // vbsl          d20, d16, d21
  .long  0xf356a1b2                          // vbsl          d26, d22, d18
  .long  0xf2073c3e                          // vfma.f32      d3, d7, d30
  .long  0xf20c0da1                          // vadd.f32      d0, d28, d17
  .long  0xf2091da4                          // vadd.f32      d1, d25, d20
  .long  0xf2082daa                          // vadd.f32      d2, d24, d26
  .long  0xecbd8b06                          // vpop          {d8-d10}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_clamp_0_vfp4
.globl _sk_clamp_0_vfp4
_sk_clamp_0_vfp4:
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2000f20                          // vmax.f32      d0, d0, d16
  .long  0xf2011f20                          // vmax.f32      d1, d1, d16
  .long  0xf2022f20                          // vmax.f32      d2, d2, d16
  .long  0xf2033f20                          // vmax.f32      d3, d3, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_clamp_1_vfp4
.globl _sk_clamp_1_vfp4
_sk_clamp_1_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2200f20                          // vmin.f32      d0, d0, d16
  .long  0xf2211f20                          // vmin.f32      d1, d1, d16
  .long  0xf2222f20                          // vmin.f32      d2, d2, d16
  .long  0xf2233f20                          // vmin.f32      d3, d3, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_clamp_a_vfp4
.globl _sk_clamp_a_vfp4
_sk_clamp_a_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2233f20                          // vmin.f32      d3, d3, d16
  .long  0xf2200f03                          // vmin.f32      d0, d0, d3
  .long  0xf2211f03                          // vmin.f32      d1, d1, d3
  .long  0xf2222f03                          // vmin.f32      d2, d2, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_set_rgb_vfp4
.globl _sk_set_rgb_vfp4
_sk_set_rgb_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe283e008                          // add           lr, r3, #8
  .long  0xf4a30c9d                          // vld1.32       {d0[]}, [r3 :32]!
  .long  0xf4ae2c9f                          // vld1.32       {d2[]}, [lr :32]
  .long  0xf4a31c9f                          // vld1.32       {d1[]}, [r3 :32]
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_swap_rb_vfp4
.globl _sk_swap_rb_vfp4
_sk_swap_rb_vfp4:
  .long  0xeef00b40                          // vmov.f64      d16, d0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb00b42                          // vmov.f64      d0, d2
  .long  0xeeb02b60                          // vmov.f64      d2, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_swap_vfp4
.globl _sk_swap_vfp4
_sk_swap_vfp4:
  .long  0xeef00b43                          // vmov.f64      d16, d3
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeef01b42                          // vmov.f64      d17, d2
  .long  0xeef02b41                          // vmov.f64      d18, d1
  .long  0xeef03b40                          // vmov.f64      d19, d0
  .long  0xeeb00b44                          // vmov.f64      d0, d4
  .long  0xeeb01b45                          // vmov.f64      d1, d5
  .long  0xeeb02b46                          // vmov.f64      d2, d6
  .long  0xeeb03b47                          // vmov.f64      d3, d7
  .long  0xeeb04b63                          // vmov.f64      d4, d19
  .long  0xeeb05b62                          // vmov.f64      d5, d18
  .long  0xeeb06b61                          // vmov.f64      d6, d17
  .long  0xeeb07b60                          // vmov.f64      d7, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_move_src_dst_vfp4
.globl _sk_move_src_dst_vfp4
_sk_move_src_dst_vfp4:
  .long  0xeeb04b40                          // vmov.f64      d4, d0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb05b41                          // vmov.f64      d5, d1
  .long  0xeeb06b42                          // vmov.f64      d6, d2
  .long  0xeeb07b43                          // vmov.f64      d7, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_move_dst_src_vfp4
.globl _sk_move_dst_src_vfp4
_sk_move_dst_src_vfp4:
  .long  0xeeb00b44                          // vmov.f64      d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb01b45                          // vmov.f64      d1, d5
  .long  0xeeb02b46                          // vmov.f64      d2, d6
  .long  0xeeb03b47                          // vmov.f64      d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_premul_vfp4
.globl _sk_premul_vfp4
_sk_premul_vfp4:
  .long  0xf3000d13                          // vmul.f32      d0, d0, d3
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3011d13                          // vmul.f32      d1, d1, d3
  .long  0xf3022d13                          // vmul.f32      d2, d2, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_unpremul_vfp4
.globl _sk_unpremul_vfp4
_sk_unpremul_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xeeb78a00                          // vmov.f32      s16, #112
  .long  0xf3f91503                          // vceq.f32      d17, d3, #0
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeec89a23                          // vdiv.f32      s19, s16, s7
  .long  0xee889a03                          // vdiv.f32      s18, s16, s6
  .long  0xf3501199                          // vbsl          d17, d16, d9
  .long  0xf3010d90                          // vmul.f32      d0, d17, d0
  .long  0xf3011d91                          // vmul.f32      d1, d17, d1
  .long  0xf3012d92                          // vmul.f32      d2, d17, d2
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}

HIDDEN _sk_from_srgb_vfp4
.globl _sk_from_srgb_vfp4
_sk_from_srgb_vfp4:
  .long  0xeddf3b20                          // vldr          d19, [pc, #128]
  .long  0xf3408d10                          // vmul.f32      d24, d0, d0
  .long  0xeddf0b1c                          // vldr          d16, [pc, #112]
  .long  0xf26341b3                          // vorr          d20, d19, d19
  .long  0xf26351b3                          // vorr          d21, d19, d19
  .long  0xeddf9b1f                          // vldr          d25, [pc, #124]
  .long  0xf2404c30                          // vfma.f32      d20, d0, d16
  .long  0xeddf2b1b                          // vldr          d18, [pc, #108]
  .long  0xf2415c30                          // vfma.f32      d21, d1, d16
  .long  0xeddfcb1d                          // vldr          d28, [pc, #116]
  .long  0xf2423c30                          // vfma.f32      d19, d2, d16
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3426d12                          // vmul.f32      d22, d2, d2
  .long  0xf3417d11                          // vmul.f32      d23, d1, d1
  .long  0xf3620e80                          // vcgt.f32      d16, d18, d0
  .long  0xf3621e81                          // vcgt.f32      d17, d18, d1
  .long  0xf341ad39                          // vmul.f32      d26, d1, d25
  .long  0xf342bd39                          // vmul.f32      d27, d2, d25
  .long  0xf3622e82                          // vcgt.f32      d18, d18, d2
  .long  0xf3409d39                          // vmul.f32      d25, d0, d25
  .long  0xf26cd1bc                          // vorr          d29, d28, d28
  .long  0xf248dcb4                          // vfma.f32      d29, d24, d20
  .long  0xf26c41bc                          // vorr          d20, d28, d28
  .long  0xf2474cb5                          // vfma.f32      d20, d23, d21
  .long  0xf246ccb3                          // vfma.f32      d28, d22, d19
  .long  0xf35901bd                          // vbsl          d16, d25, d29
  .long  0xf35a11b4                          // vbsl          d17, d26, d20
  .long  0xf35b21bc                          // vbsl          d18, d27, d28
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xe12fff13                          // bx            r3
  .long  0x3e99999a                          // .word         0x3e99999a
  .long  0x3e99999a                          // .word         0x3e99999a
  .long  0x3f328f5c                          // .word         0x3f328f5c
  .long  0x3f328f5c                          // .word         0x3f328f5c
  .long  0x3d6147ae                          // .word         0x3d6147ae
  .long  0x3d6147ae                          // .word         0x3d6147ae
  .long  0x3d9e8391                          // .word         0x3d9e8391
  .long  0x3d9e8391                          // .word         0x3d9e8391
  .long  0x3b23d70a                          // .word         0x3b23d70a
  .long  0x3b23d70a                          // .word         0x3b23d70a

HIDDEN _sk_to_srgb_vfp4
.globl _sk_to_srgb_vfp4
_sk_to_srgb_vfp4:
  .long  0xf3fb0582                          // vrsqrte.f32   d16, d2
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3fb1581                          // vrsqrte.f32   d17, d1
  .long  0xf3fb2580                          // vrsqrte.f32   d18, d0
  .long  0xf3403db0                          // vmul.f32      d19, d16, d16
  .long  0xf3414db1                          // vmul.f32      d20, d17, d17
  .long  0xf3425db2                          // vmul.f32      d21, d18, d18
  .long  0xf2623f33                          // vrsqrts.f32   d19, d2, d19
  .long  0xf2614f34                          // vrsqrts.f32   d20, d1, d20
  .long  0xf2605f35                          // vrsqrts.f32   d21, d0, d21
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xf3411db4                          // vmul.f32      d17, d17, d20
  .long  0xf3422db5                          // vmul.f32      d18, d18, d21
  .long  0xf3fb3520                          // vrecpe.f32    d19, d16
  .long  0xf3fb4521                          // vrecpe.f32    d20, d17
  .long  0xf3fb6522                          // vrecpe.f32    d22, d18
  .long  0xf3fb55a0                          // vrsqrte.f32   d21, d16
  .long  0xf3fb75a1                          // vrsqrte.f32   d23, d17
  .long  0xf3fb85a2                          // vrsqrte.f32   d24, d18
  .long  0xf2409fb3                          // vrecps.f32    d25, d16, d19
  .long  0xf241afb4                          // vrecps.f32    d26, d17, d20
  .long  0xf242bfb6                          // vrecps.f32    d27, d18, d22
  .long  0xf345cdb5                          // vmul.f32      d28, d21, d21
  .long  0xf347ddb7                          // vmul.f32      d29, d23, d23
  .long  0xf348edb8                          // vmul.f32      d30, d24, d24
  .long  0xf2600fbc                          // vrsqrts.f32   d16, d16, d28
  .long  0xf2611fbd                          // vrsqrts.f32   d17, d17, d29
  .long  0xf2622fbe                          // vrsqrts.f32   d18, d18, d30
  .long  0xf3433db9                          // vmul.f32      d19, d19, d25
  .long  0xeddf9b21                          // vldr          d25, [pc, #132]
  .long  0xf3444dba                          // vmul.f32      d20, d20, d26
  .long  0xeddfab21                          // vldr          d26, [pc, #132]
  .long  0xf3466dbb                          // vmul.f32      d22, d22, d27
  .long  0xf26ab1ba                          // vorr          d27, d26, d26
  .long  0xf243bcb9                          // vfma.f32      d27, d19, d25
  .long  0xf26a31ba                          // vorr          d19, d26, d26
  .long  0xf2443cb9                          // vfma.f32      d19, d20, d25
  .long  0xeddf4b1d                          // vldr          d20, [pc, #116]
  .long  0xf246acb9                          // vfma.f32      d26, d22, d25
  .long  0xf3450db0                          // vmul.f32      d16, d21, d16
  .long  0xeddf5b1c                          // vldr          d21, [pc, #112]
  .long  0xf3471db1                          // vmul.f32      d17, d23, d17
  .long  0xf3482db2                          // vmul.f32      d18, d24, d18
  .long  0xf3406d35                          // vmul.f32      d22, d0, d21
  .long  0xf240bcb4                          // vfma.f32      d27, d16, d20
  .long  0xf2413cb4                          // vfma.f32      d19, d17, d20
  .long  0xf242acb4                          // vfma.f32      d26, d18, d20
  .long  0xeddf2b17                          // vldr          d18, [pc, #92]
  .long  0xf3417d35                          // vmul.f32      d23, d1, d21
  .long  0xf3620e80                          // vcgt.f32      d16, d18, d0
  .long  0xf3621e81                          // vcgt.f32      d17, d18, d1
  .long  0xf3622e82                          // vcgt.f32      d18, d18, d2
  .long  0xf3425d35                          // vmul.f32      d21, d2, d21
  .long  0xf2c74f10                          // vmov.f32      d20, #1
  .long  0xf2648faa                          // vmin.f32      d24, d20, d26
  .long  0xf2643fa3                          // vmin.f32      d19, d20, d19
  .long  0xf2644fab                          // vmin.f32      d20, d20, d27
  .long  0xf35601b8                          // vbsl          d16, d22, d24
  .long  0xf35711b3                          // vbsl          d17, d23, d19
  .long  0xf35521b4                          // vbsl          d18, d21, d20
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xe12fff13                          // bx            r3
  .long  0x3f306fce                          // .word         0x3f306fce
  .long  0x3f306fce                          // .word         0x3f306fce
  .long  0xbdca57a8                          // .word         0xbdca57a8
  .long  0xbdca57a8                          // .word         0xbdca57a8
  .long  0x3ed287c2                          // .word         0x3ed287c2
  .long  0x3ed287c2                          // .word         0x3ed287c2
  .long  0x41475c29                          // .word         0x41475c29
  .long  0x41475c29                          // .word         0x41475c29
  .long  0x3b8ce704                          // .word         0x3b8ce704
  .long  0x3b8ce704                          // .word         0x3b8ce704

HIDDEN _sk_from_2dot2_vfp4
.globl _sk_from_2dot2_vfp4
_sk_from_2dot2_vfp4:
  .long  0xf3fb0580                          // vrsqrte.f32   d16, d0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3fb1581                          // vrsqrte.f32   d17, d1
  .long  0xf3fb2582                          // vrsqrte.f32   d18, d2
  .long  0xf3403db0                          // vmul.f32      d19, d16, d16
  .long  0xf3414db1                          // vmul.f32      d20, d17, d17
  .long  0xf3425db2                          // vmul.f32      d21, d18, d18
  .long  0xf2603f33                          // vrsqrts.f32   d19, d0, d19
  .long  0xf2614f34                          // vrsqrts.f32   d20, d1, d20
  .long  0xf2625f35                          // vrsqrts.f32   d21, d2, d21
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xf3411db4                          // vmul.f32      d17, d17, d20
  .long  0xf3422db5                          // vmul.f32      d18, d18, d21
  .long  0xf3fb35a0                          // vrsqrte.f32   d19, d16
  .long  0xf3fb45a1                          // vrsqrte.f32   d20, d17
  .long  0xf3fb55a2                          // vrsqrte.f32   d21, d18
  .long  0xf3436db3                          // vmul.f32      d22, d19, d19
  .long  0xf3447db4                          // vmul.f32      d23, d20, d20
  .long  0xf3458db5                          // vmul.f32      d24, d21, d21
  .long  0xf2600fb6                          // vrsqrts.f32   d16, d16, d22
  .long  0xf2611fb7                          // vrsqrts.f32   d17, d17, d23
  .long  0xf2622fb8                          // vrsqrts.f32   d18, d18, d24
  .long  0xf3430db0                          // vmul.f32      d16, d19, d16
  .long  0xf3441db1                          // vmul.f32      d17, d20, d17
  .long  0xf3452db2                          // vmul.f32      d18, d21, d18
  .long  0xf3fb35a0                          // vrsqrte.f32   d19, d16
  .long  0xf3fb45a1                          // vrsqrte.f32   d20, d17
  .long  0xf3fb55a2                          // vrsqrte.f32   d21, d18
  .long  0xf3436db3                          // vmul.f32      d22, d19, d19
  .long  0xf3447db4                          // vmul.f32      d23, d20, d20
  .long  0xf3458db5                          // vmul.f32      d24, d21, d21
  .long  0xf2600fb6                          // vrsqrts.f32   d16, d16, d22
  .long  0xf2611fb7                          // vrsqrts.f32   d17, d17, d23
  .long  0xf2622fb8                          // vrsqrts.f32   d18, d18, d24
  .long  0xf3430db0                          // vmul.f32      d16, d19, d16
  .long  0xf3441db1                          // vmul.f32      d17, d20, d17
  .long  0xf3452db2                          // vmul.f32      d18, d21, d18
  .long  0xf3fb35a0                          // vrsqrte.f32   d19, d16
  .long  0xf3fb45a1                          // vrsqrte.f32   d20, d17
  .long  0xf3fb55a2                          // vrsqrte.f32   d21, d18
  .long  0xf3436db3                          // vmul.f32      d22, d19, d19
  .long  0xf3447db4                          // vmul.f32      d23, d20, d20
  .long  0xf3458db5                          // vmul.f32      d24, d21, d21
  .long  0xf2600fb6                          // vrsqrts.f32   d16, d16, d22
  .long  0xf2611fb7                          // vrsqrts.f32   d17, d17, d23
  .long  0xf2622fb8                          // vrsqrts.f32   d18, d18, d24
  .long  0xf3430db0                          // vmul.f32      d16, d19, d16
  .long  0xf3441db1                          // vmul.f32      d17, d20, d17
  .long  0xf3452db2                          // vmul.f32      d18, d21, d18
  .long  0xf3fb35a0                          // vrsqrte.f32   d19, d16
  .long  0xf3fb45a1                          // vrsqrte.f32   d20, d17
  .long  0xf3fb55a2                          // vrsqrte.f32   d21, d18
  .long  0xf340bdb0                          // vmul.f32      d27, d16, d16
  .long  0xf341ddb1                          // vmul.f32      d29, d17, d17
  .long  0xf3436db3                          // vmul.f32      d22, d19, d19
  .long  0xf3447db4                          // vmul.f32      d23, d20, d20
  .long  0xf3458db5                          // vmul.f32      d24, d21, d21
  .long  0xf2606fb6                          // vrsqrts.f32   d22, d16, d22
  .long  0xf2617fb7                          // vrsqrts.f32   d23, d17, d23
  .long  0xf2628fb8                          // vrsqrts.f32   d24, d18, d24
  .long  0xf3400dbb                          // vmul.f32      d16, d16, d27
  .long  0xf3411dbd                          // vmul.f32      d17, d17, d29
  .long  0xf341bd11                          // vmul.f32      d27, d1, d1
  .long  0xf3433db6                          // vmul.f32      d19, d19, d22
  .long  0xf3444db7                          // vmul.f32      d20, d20, d23
  .long  0xf3455db8                          // vmul.f32      d21, d21, d24
  .long  0xf34b1db1                          // vmul.f32      d17, d27, d17
  .long  0xf3fb65a3                          // vrsqrte.f32   d22, d19
  .long  0xf3fb75a4                          // vrsqrte.f32   d23, d20
  .long  0xf3fb85a5                          // vrsqrte.f32   d24, d21
  .long  0xf3469db6                          // vmul.f32      d25, d22, d22
  .long  0xf347adb7                          // vmul.f32      d26, d23, d23
  .long  0xf348cdb8                          // vmul.f32      d28, d24, d24
  .long  0xf2633fb9                          // vrsqrts.f32   d19, d19, d25
  .long  0xf2644fba                          // vrsqrts.f32   d20, d20, d26
  .long  0xf3429db2                          // vmul.f32      d25, d18, d18
  .long  0xf2655fbc                          // vrsqrts.f32   d21, d21, d28
  .long  0xf340ad10                          // vmul.f32      d26, d0, d0
  .long  0xf3422db9                          // vmul.f32      d18, d18, d25
  .long  0xf3429d12                          // vmul.f32      d25, d2, d2
  .long  0xf3463db3                          // vmul.f32      d19, d22, d19
  .long  0xf3474db4                          // vmul.f32      d20, d23, d20
  .long  0xf34a0db0                          // vmul.f32      d16, d26, d16
  .long  0xf3485db5                          // vmul.f32      d21, d24, d21
  .long  0xf3492db2                          // vmul.f32      d18, d25, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xf3411db4                          // vmul.f32      d17, d17, d20
  .long  0xf3422db5                          // vmul.f32      d18, d18, d21
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2000fa3                          // vmax.f32      d0, d16, d19
  .long  0xf2011fa3                          // vmax.f32      d1, d17, d19
  .long  0xf2022fa3                          // vmax.f32      d2, d18, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_to_2dot2_vfp4
.globl _sk_to_2dot2_vfp4
_sk_to_2dot2_vfp4:
  .long  0xf3fb0580                          // vrsqrte.f32   d16, d0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3fb1581                          // vrsqrte.f32   d17, d1
  .long  0xf3fb3582                          // vrsqrte.f32   d19, d2
  .long  0xf3402db0                          // vmul.f32      d18, d16, d16
  .long  0xf3414db1                          // vmul.f32      d20, d17, d17
  .long  0xf3435db3                          // vmul.f32      d21, d19, d19
  .long  0xf2602f32                          // vrsqrts.f32   d18, d0, d18
  .long  0xf2614f34                          // vrsqrts.f32   d20, d1, d20
  .long  0xf2625f35                          // vrsqrts.f32   d21, d2, d21
  .long  0xf3402db2                          // vmul.f32      d18, d16, d18
  .long  0xf3411db4                          // vmul.f32      d17, d17, d20
  .long  0xf3430db5                          // vmul.f32      d16, d19, d21
  .long  0xf3fb35a2                          // vrsqrte.f32   d19, d18
  .long  0xf3fb45a1                          // vrsqrte.f32   d20, d17
  .long  0xf3fb55a0                          // vrsqrte.f32   d21, d16
  .long  0xf3fbc522                          // vrecpe.f32    d28, d18
  .long  0xf3436db3                          // vmul.f32      d22, d19, d19
  .long  0xf3447db4                          // vmul.f32      d23, d20, d20
  .long  0xf3458db5                          // vmul.f32      d24, d21, d21
  .long  0xf2626fb6                          // vrsqrts.f32   d22, d18, d22
  .long  0xf2617fb7                          // vrsqrts.f32   d23, d17, d23
  .long  0xf2608fb8                          // vrsqrts.f32   d24, d16, d24
  .long  0xf2422fbc                          // vrecps.f32    d18, d18, d28
  .long  0xf3433db6                          // vmul.f32      d19, d19, d22
  .long  0xf3444db7                          // vmul.f32      d20, d20, d23
  .long  0xf3455db8                          // vmul.f32      d21, d21, d24
  .long  0xf34c2db2                          // vmul.f32      d18, d28, d18
  .long  0xf3fb65a3                          // vrsqrte.f32   d22, d19
  .long  0xf3fb75a4                          // vrsqrte.f32   d23, d20
  .long  0xf3fb85a5                          // vrsqrte.f32   d24, d21
  .long  0xf3469db6                          // vmul.f32      d25, d22, d22
  .long  0xf347adb7                          // vmul.f32      d26, d23, d23
  .long  0xf348bdb8                          // vmul.f32      d27, d24, d24
  .long  0xf2633fb9                          // vrsqrts.f32   d19, d19, d25
  .long  0xf2644fba                          // vrsqrts.f32   d20, d20, d26
  .long  0xf2655fbb                          // vrsqrts.f32   d21, d21, d27
  .long  0xf3463db3                          // vmul.f32      d19, d22, d19
  .long  0xf3474db4                          // vmul.f32      d20, d23, d20
  .long  0xf3485db5                          // vmul.f32      d21, d24, d21
  .long  0xf3fb65a3                          // vrsqrte.f32   d22, d19
  .long  0xf3fb75a4                          // vrsqrte.f32   d23, d20
  .long  0xf3fb85a5                          // vrsqrte.f32   d24, d21
  .long  0xf3469db6                          // vmul.f32      d25, d22, d22
  .long  0xf347adb7                          // vmul.f32      d26, d23, d23
  .long  0xf348bdb8                          // vmul.f32      d27, d24, d24
  .long  0xf2633fb9                          // vrsqrts.f32   d19, d19, d25
  .long  0xf2644fba                          // vrsqrts.f32   d20, d20, d26
  .long  0xf2655fbb                          // vrsqrts.f32   d21, d21, d27
  .long  0xf3463db3                          // vmul.f32      d19, d22, d19
  .long  0xf3474db4                          // vmul.f32      d20, d23, d20
  .long  0xf3485db5                          // vmul.f32      d21, d24, d21
  .long  0xf3fb65a3                          // vrsqrte.f32   d22, d19
  .long  0xf3fb75a4                          // vrsqrte.f32   d23, d20
  .long  0xf3fb85a5                          // vrsqrte.f32   d24, d21
  .long  0xf3469db6                          // vmul.f32      d25, d22, d22
  .long  0xf347adb7                          // vmul.f32      d26, d23, d23
  .long  0xf348bdb8                          // vmul.f32      d27, d24, d24
  .long  0xf2633fb9                          // vrsqrts.f32   d19, d19, d25
  .long  0xf2644fba                          // vrsqrts.f32   d20, d20, d26
  .long  0xf2655fbb                          // vrsqrts.f32   d21, d21, d27
  .long  0xf3463db3                          // vmul.f32      d19, d22, d19
  .long  0xf3474db4                          // vmul.f32      d20, d23, d20
  .long  0xf3485db5                          // vmul.f32      d21, d24, d21
  .long  0xf3fb65a3                          // vrsqrte.f32   d22, d19
  .long  0xf3fb75a4                          // vrsqrte.f32   d23, d20
  .long  0xf3fb85a5                          // vrsqrte.f32   d24, d21
  .long  0xf3432db2                          // vmul.f32      d18, d19, d18
  .long  0xf3469db6                          // vmul.f32      d25, d22, d22
  .long  0xf347adb7                          // vmul.f32      d26, d23, d23
  .long  0xf348bdb8                          // vmul.f32      d27, d24, d24
  .long  0xf2639fb9                          // vrsqrts.f32   d25, d19, d25
  .long  0xf264afba                          // vrsqrts.f32   d26, d20, d26
  .long  0xf265bfbb                          // vrsqrts.f32   d27, d21, d27
  .long  0xf3466db9                          // vmul.f32      d22, d22, d25
  .long  0xf3fb9521                          // vrecpe.f32    d25, d17
  .long  0xf3477dba                          // vmul.f32      d23, d23, d26
  .long  0xf3fba520                          // vrecpe.f32    d26, d16
  .long  0xf3488dbb                          // vmul.f32      d24, d24, d27
  .long  0xf2411fb9                          // vrecps.f32    d17, d17, d25
  .long  0xf3fbb526                          // vrecpe.f32    d27, d22
  .long  0xf3fbd527                          // vrecpe.f32    d29, d23
  .long  0xf2400fba                          // vrecps.f32    d16, d16, d26
  .long  0xf3fbe528                          // vrecpe.f32    d30, d24
  .long  0xf2466fbb                          // vrecps.f32    d22, d22, d27
  .long  0xf2477fbd                          // vrecps.f32    d23, d23, d29
  .long  0xf2488fbe                          // vrecps.f32    d24, d24, d30
  .long  0xf3491db1                          // vmul.f32      d17, d25, d17
  .long  0xf34a0db0                          // vmul.f32      d16, d26, d16
  .long  0xf34b6db6                          // vmul.f32      d22, d27, d22
  .long  0xf3441db1                          // vmul.f32      d17, d20, d17
  .long  0xf34d3db7                          // vmul.f32      d19, d29, d23
  .long  0xf34e4db8                          // vmul.f32      d20, d30, d24
  .long  0xf3450db0                          // vmul.f32      d16, d21, d16
  .long  0xf3422db6                          // vmul.f32      d18, d18, d22
  .long  0xf3411db3                          // vmul.f32      d17, d17, d19
  .long  0xf3400db4                          // vmul.f32      d16, d16, d20
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2020fa3                          // vmax.f32      d0, d18, d19
  .long  0xf2011fa3                          // vmax.f32      d1, d17, d19
  .long  0xf2002fa3                          // vmax.f32      d2, d16, d19
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}

HIDDEN _sk_rgb_to_hsl_vfp4
.globl _sk_rgb_to_hsl_vfp4
_sk_rgb_to_hsl_vfp4:
  .long  0xed2d8b08                          // vpush         {d8-d11}
  .long  0xf2401f01                          // vmax.f32      d17, d0, d1
  .long  0xeddf9b2c                          // vldr          d25, [pc, #176]
  .long  0xf2600f01                          // vmin.f32      d16, d0, d1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb78a00                          // vmov.f32      s16, #112
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xf2411f82                          // vmax.f32      d17, d17, d2
  .long  0xf2602f82                          // vmin.f32      d18, d16, d2
  .long  0xf2c45610                          // vmov.i32      d21, #1073741824
  .long  0xf2607d01                          // vsub.f32      d23, d0, d1
  .long  0xf2656da1                          // vsub.f32      d22, d21, d17
  .long  0xf221ada2                          // vsub.f32      d10, d17, d18
  .long  0xf2413da2                          // vadd.f32      d19, d17, d18
  .long  0xf2c08010                          // vmov.i32      d24, #0
  .long  0xf2666da2                          // vsub.f32      d22, d22, d18
  .long  0xf241ae80                          // vceq.f32      d26, d17, d0
  .long  0xeec8ba2a                          // vdiv.f32      s23, s16, s21
  .long  0xf3430db4                          // vmul.f32      d16, d19, d20
  .long  0xee88ba0a                          // vdiv.f32      s22, s16, s20
  .long  0xf3209ea4                          // vcgt.f32      d9, d16, d20
  .long  0xf2614d02                          // vsub.f32      d20, d1, d2
  .long  0xf3477d9b                          // vmul.f32      d23, d23, d11
  .long  0xf31691b3                          // vbsl          d9, d22, d19
  .long  0xf2623d00                          // vsub.f32      d19, d2, d0
  .long  0xf3626e01                          // vcgt.f32      d22, d2, d1
  .long  0xeeca8aa9                          // vdiv.f32      s17, s21, s19
  .long  0xee8a8a09                          // vdiv.f32      s16, s20, s18
  .long  0xf3433d9b                          // vmul.f32      d19, d19, d11
  .long  0xf3444d9b                          // vmul.f32      d20, d20, d11
  .long  0xf35961b8                          // vbsl          d22, d25, d24
  .long  0xf2419e81                          // vceq.f32      d25, d17, d1
  .long  0xf2011ea2                          // vceq.f32      d1, d17, d18
  .long  0xf2433da5                          // vadd.f32      d19, d19, d21
  .long  0xf2c15f10                          // vmov.f32      d21, #4
  .long  0xf2464da4                          // vadd.f32      d20, d22, d20
  .long  0xf2471da5                          // vadd.f32      d17, d23, d21
  .long  0xf35391b1                          // vbsl          d25, d19, d17
  .long  0xeddf1b0a                          // vldr          d17, [pc, #40]
  .long  0xf2612111                          // vorr          d18, d1, d1
  .long  0xf354a1b9                          // vbsl          d26, d20, d25
  .long  0xf35821ba                          // vbsl          d18, d24, d26
  .long  0xf3181198                          // vbsl          d1, d24, d8
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf22021b0                          // vorr          d2, d16, d16
  .long  0xecbd8b08                          // vpop          {d8-d11}
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}
  .long  0x40c00000                          // .word         0x40c00000
  .long  0x40c00000                          // .word         0x40c00000
  .long  0x3e2aaaab                          // .word         0x3e2aaaab
  .long  0x3e2aaaab                          // .word         0x3e2aaaab

HIDDEN _sk_hsl_to_rgb_vfp4
.globl _sk_hsl_to_rgb_vfp4
_sk_hsl_to_rgb_vfp4:
  .long  0xf2c72f10                          // vmov.f32      d18, #1
  .long  0xeddf0b4f                          // vldr          d16, [pc, #316]
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xeddf9b4f                          // vldr          d25, [pc, #316]
  .long  0xf2415d22                          // vadd.f32      d21, d1, d18
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3414d12                          // vmul.f32      d20, d1, d2
  .long  0xf2416d02                          // vadd.f32      d22, d1, d2
  .long  0xf2407d20                          // vadd.f32      d23, d0, d16
  .long  0xf3610e82                          // vcgt.f32      d16, d17, d2
  .long  0xf3455d92                          // vmul.f32      d21, d21, d2
  .long  0xf2664da4                          // vsub.f32      d20, d22, d20
  .long  0xf2426d02                          // vadd.f32      d22, d2, d2
  .long  0xf3c73f10                          // vmov.f32      d19, #-1
  .long  0xf35501b4                          // vbsl          d16, d21, d20
  .long  0xf2409d29                          // vadd.f32      d25, d0, d25
  .long  0xf2408d23                          // vadd.f32      d24, d0, d19
  .long  0xf3f9e629                          // vclt.f32      d30, d25, #0
  .long  0xf360ae22                          // vcgt.f32      d26, d0, d18
  .long  0xf247cda3                          // vadd.f32      d28, d23, d19
  .long  0xf367dea2                          // vcgt.f32      d29, d23, d18
  .long  0xf240bd22                          // vadd.f32      d27, d0, d18
  .long  0xf2666da0                          // vsub.f32      d22, d22, d16
  .long  0xf2474da2                          // vadd.f32      d20, d23, d18
  .long  0xf358a190                          // vbsl          d26, d24, d0
  .long  0xf3f98600                          // vclt.f32      d24, d0, #0
  .long  0xf3695ea2                          // vcgt.f32      d21, d25, d18
  .long  0xf2493da3                          // vadd.f32      d19, d25, d19
  .long  0xf35b81ba                          // vbsl          d24, d27, d26
  .long  0xf3f9a627                          // vclt.f32      d26, d23, #0
  .long  0xf35cd1b7                          // vbsl          d29, d28, d23
  .long  0xeddfcb35                          // vldr          d28, [pc, #212]
  .long  0xf2492da2                          // vadd.f32      d18, d25, d18
  .long  0xf260bda6                          // vsub.f32      d27, d16, d22
  .long  0xf354a1bd                          // vbsl          d26, d20, d29
  .long  0xf2c14f18                          // vmov.f32      d20, #6
  .long  0xf35351b9                          // vbsl          d21, d19, d25
  .long  0xf26cddaa                          // vsub.f32      d29, d28, d26
  .long  0xf352e1b5                          // vbsl          d30, d18, d21
  .long  0xf34b2db4                          // vmul.f32      d18, d27, d20
  .long  0xf26c3da8                          // vsub.f32      d19, d28, d24
  .long  0xf26c4dae                          // vsub.f32      d20, d28, d30
  .long  0xf36cbeaa                          // vcgt.f32      d27, d28, d26
  .long  0xf3425dbd                          // vmul.f32      d21, d18, d29
  .long  0xf3477db2                          // vmul.f32      d23, d23, d18
  .long  0xf3423db3                          // vmul.f32      d19, d18, d19
  .long  0xf3444db2                          // vmul.f32      d20, d20, d18
  .long  0xf2465da5                          // vadd.f32      d21, d22, d21
  .long  0xf342dd90                          // vmul.f32      d29, d18, d0
  .long  0xf3210eaa                          // vcgt.f32      d0, d17, d26
  .long  0xf3492db2                          // vmul.f32      d18, d25, d18
  .long  0xf355b1b6                          // vbsl          d27, d21, d22
  .long  0xeddf5b22                          // vldr          d21, [pc, #136]
  .long  0xf36cfea8                          // vcgt.f32      d31, d28, d24
  .long  0xf2463da3                          // vadd.f32      d19, d22, d19
  .long  0xf36cceae                          // vcgt.f32      d28, d28, d30
  .long  0xf2464da4                          // vadd.f32      d20, d22, d20
  .long  0xf365aeaa                          // vcgt.f32      d26, d21, d26
  .long  0xf2467da7                          // vadd.f32      d23, d22, d23
  .long  0xf3619ea8                          // vcgt.f32      d25, d17, d24
  .long  0xf3611eae                          // vcgt.f32      d17, d17, d30
  .long  0xf31001bb                          // vbsl          d0, d16, d27
  .long  0xf353f1b6                          // vbsl          d31, d19, d22
  .long  0xf354c1b6                          // vbsl          d28, d20, d22
  .long  0xf357a190                          // vbsl          d26, d23, d0
  .long  0xf3b90501                          // vceq.f32      d0, d1, #0
  .long  0xf3658ea8                          // vcgt.f32      d24, d21, d24
  .long  0xf246ddad                          // vadd.f32      d29, d22, d29
  .long  0xf3653eae                          // vcgt.f32      d19, d21, d30
  .long  0xf2462da2                          // vadd.f32      d18, d22, d18
  .long  0xf35091bf                          // vbsl          d25, d16, d31
  .long  0xf35011bc                          // vbsl          d17, d16, d28
  .long  0xf2600110                          // vorr          d16, d0, d0
  .long  0xf2201110                          // vorr          d1, d0, d0
  .long  0xf352013a                          // vbsl          d16, d2, d26
  .long  0xf35d81b9                          // vbsl          d24, d29, d25
  .long  0xf35231b1                          // vbsl          d19, d18, d17
  .long  0xf3121138                          // vbsl          d1, d2, d24
  .long  0xf3120133                          // vbsl          d0, d2, d19
  .long  0xf22021b0                          // vorr          d2, d16, d16
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0x3eaaaaab                          // .word         0x3eaaaaab
  .long  0x3eaaaaab                          // .word         0x3eaaaaab
  .long  0x3f2aaaab                          // .word         0x3f2aaaab
  .long  0x3f2aaaab                          // .word         0x3f2aaaab
  .long  0x3e2aaaab                          // .word         0x3e2aaaab
  .long  0x3e2aaaab                          // .word         0x3e2aaaab

HIDDEN _sk_scale_1_float_vfp4
.globl _sk_scale_1_float_vfp4
_sk_scale_1_float_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xf3000d90                          // vmul.f32      d0, d16, d0
  .long  0xf3001d91                          // vmul.f32      d1, d16, d1
  .long  0xf3002d92                          // vmul.f32      d2, d16, d2
  .long  0xf3003d93                          // vmul.f32      d3, d16, d3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_scale_u8_vfp4
.globl _sk_scale_u8_vfp4
_sk_scale_u8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b06                          // vldr          d17, [pc, #24]
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf3000d90                          // vmul.f32      d0, d16, d0
  .long  0xf3001d91                          // vmul.f32      d1, d16, d1
  .long  0xf3002d92                          // vmul.f32      d2, d16, d2
  .long  0xf3003d93                          // vmul.f32      d3, d16, d3
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_lerp_1_float_vfp4
.globl _sk_lerp_1_float_vfp4
_sk_lerp_1_float_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2600d04                          // vsub.f32      d16, d0, d4
  .long  0xf2611d05                          // vsub.f32      d17, d1, d5
  .long  0xf2622d06                          // vsub.f32      d18, d2, d6
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2633d07                          // vsub.f32      d19, d3, d7
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf2240114                          // vorr          d0, d4, d4
  .long  0xf2251115                          // vorr          d1, d5, d5
  .long  0xf2262116                          // vorr          d2, d6, d6
  .long  0xf2273117                          // vorr          d3, d7, d7
  .long  0xf2000cb4                          // vfma.f32      d0, d16, d20
  .long  0xf2011cb4                          // vfma.f32      d1, d17, d20
  .long  0xf2022cb4                          // vfma.f32      d2, d18, d20
  .long  0xf2033cb4                          // vfma.f32      d3, d19, d20
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_lerp_u8_vfp4
.globl _sk_lerp_u8_vfp4
_sk_lerp_u8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2602d04                          // vsub.f32      d18, d0, d4
  .long  0xf2623d06                          // vsub.f32      d19, d2, d6
  .long  0xf2634d07                          // vsub.f32      d20, d3, d7
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2240114                          // vorr          d0, d4, d4
  .long  0xf2262116                          // vorr          d2, d6, d6
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xf2273117                          // vorr          d3, d7, d7
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b08                          // vldr          d17, [pc, #32]
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf2611d05                          // vsub.f32      d17, d1, d5
  .long  0xf2251115                          // vorr          d1, d5, d5
  .long  0xf2020cb0                          // vfma.f32      d0, d18, d16
  .long  0xf2011cb0                          // vfma.f32      d1, d17, d16
  .long  0xf2032cb0                          // vfma.f32      d2, d19, d16
  .long  0xf2043cb0                          // vfma.f32      d3, d20, d16
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_lerp_565_vfp4
.globl _sk_lerp_565_vfp4
_sk_lerp_565_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c72218                          // vmov.i32      d18, #63488
  .long  0xf2c1101f                          // vmov.i32      d17, #31
  .long  0xf2603d04                          // vsub.f32      d19, d0, d4
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2616d05                          // vsub.f32      d22, d1, d5
  .long  0xf2240114                          // vorr          d0, d4, d4
  .long  0xf2251115                          // vorr          d1, d5, d5
  .long  0xe7933080                          // ldr           r3, [r3, r0, lsl #1]
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe58d3000                          // str           r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe3a03e7e                          // mov           r3, #2016
  .long  0xf3d04a30                          // vmovl.u16     q10, d16
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf24421b2                          // vand          d18, d20, d18
  .long  0xf24411b1                          // vand          d17, d20, d17
  .long  0xeddf5b12                          // vldr          d21, [pc, #72]
  .long  0xf24401b0                          // vand          d16, d20, d16
  .long  0xeddf4b0e                          // vldr          d20, [pc, #56]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3422db4                          // vmul.f32      d18, d18, d20
  .long  0xeddf4b0d                          // vldr          d20, [pc, #52]
  .long  0xf3400db5                          // vmul.f32      d16, d16, d21
  .long  0xf2625d06                          // vsub.f32      d21, d2, d6
  .long  0xf3411db4                          // vmul.f32      d17, d17, d20
  .long  0xf2262116                          // vorr          d2, d6, d6
  .long  0xf2030cb2                          // vfma.f32      d0, d19, d18
  .long  0xf2061cb0                          // vfma.f32      d1, d22, d16
  .long  0xf2052cb1                          // vfma.f32      d2, d21, d17
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37842108                          // .word         0x37842108
  .long  0x37842108                          // .word         0x37842108
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3d042108                          // .word         0x3d042108
  .long  0x3d042108                          // .word         0x3d042108

HIDDEN _sk_load_tables_vfp4
.globl _sk_load_tables_vfp4
_sk_load_tables_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c7001f                          // vmov.i32      d16, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe99300b0                          // ldmib         r3, {r4, r5, r7}
  .long  0xe08e3100                          // add           r3, lr, r0, lsl #2
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf24121b0                          // vand          d18, d17, d16
  .long  0xf3f83031                          // vshr.u32      d19, d17, #8
  .long  0xee323b90                          // vmov.32       r3, d18[1]
  .long  0xee126b90                          // vmov.32       r6, d18[0]
  .long  0xf3f02031                          // vshr.u32      d18, d17, #16
  .long  0xf24221b0                          // vand          d18, d18, d16
  .long  0xf24301b0                          // vand          d16, d19, d16
  .long  0xe0843103                          // add           r3, r4, r3, lsl #2
  .long  0xedd30a00                          // vldr          s1, [r3]
  .long  0xe0843106                          // add           r3, r4, r6, lsl #2
  .long  0xee326b90                          // vmov.32       r6, d18[1]
  .long  0xed930a00                          // vldr          s0, [r3]
  .long  0xee303b90                          // vmov.32       r3, d16[1]
  .long  0xee104b90                          // vmov.32       r4, d16[0]
  .long  0xf3e80031                          // vshr.u32      d16, d17, #24
  .long  0xeddf1b0d                          // vldr          d17, [pc, #52]
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe087e106                          // add           lr, r7, r6, lsl #2
  .long  0xee126b90                          // vmov.32       r6, d18[0]
  .long  0xe0853103                          // add           r3, r5, r3, lsl #2
  .long  0xedde2a00                          // vldr          s5, [lr]
  .long  0xedd31a00                          // vldr          s3, [r3]
  .long  0xe0853104                          // add           r3, r5, r4, lsl #2
  .long  0xed931a00                          // vldr          s2, [r3]
  .long  0xe0873106                          // add           r3, r7, r6, lsl #2
  .long  0xed932a00                          // vldr          s4, [r3]
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_byte_tables_vfp4
.globl _sk_byte_tables_vfp4
_sk_byte_tables_vfp4:
  .long  0xe92d4bf0                          // push          {r4, r5, r6, r7, r8, r9, fp, lr}
  .long  0xeddf0b37                          // vldr          d16, [pc, #220]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xe8911010                          // ldm           r1, {r4, ip}
  .long  0xf2422c30                          // vfma.f32      d18, d2, d16
  .long  0xf2413c30                          // vfma.f32      d19, d1, d16
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xe89402e0                          // ldm           r4, {r5, r6, r7, r9}
  .long  0xf2404c30                          // vfma.f32      d20, d0, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2431c30                          // vfma.f32      d17, d3, d16
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf3fb37a3                          // vcvt.u32.f32  d19, d19
  .long  0xf3fb47a4                          // vcvt.u32.f32  d20, d20
  .long  0xee123b90                          // vmov.32       r3, d18[0]
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee13eb90                          // vmov.32       lr, d19[0]
  .long  0xee144b90                          // vmov.32       r4, d20[0]
  .long  0xe7d78003                          // ldrb          r8, [r7, r3]
  .long  0xe7d6300e                          // ldrb          r3, [r6, lr]
  .long  0xee053b90                          // vmov.32       d21[0], r3
  .long  0xe7d53004                          // ldrb          r3, [r5, r4]
  .long  0xee344b90                          // vmov.32       r4, d20[1]
  .long  0xee013b90                          // vmov.32       d17[0], r3
  .long  0xee103b90                          // vmov.32       r3, d16[0]
  .long  0xee048b90                          // vmov.32       d20[0], r8
  .long  0xe7d5e004                          // ldrb          lr, [r5, r4]
  .long  0xee334b90                          // vmov.32       r4, d19[1]
  .long  0xee325b90                          // vmov.32       r5, d18[1]
  .long  0xf3c7201f                          // vmov.i32      d18, #255
  .long  0xe7d93003                          // ldrb          r3, [r9, r3]
  .long  0xee21eb90                          // vmov.32       d17[1], lr
  .long  0xf24111b2                          // vand          d17, d17, d18
  .long  0xf3fb16a1                          // vcvt.f32.u32  d17, d17
  .long  0xe7d64004                          // ldrb          r4, [r6, r4]
  .long  0xee306b90                          // vmov.32       r6, d16[1]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee254b90                          // vmov.32       d21[1], r4
  .long  0xe7d74005                          // ldrb          r4, [r7, r5]
  .long  0xf24531b2                          // vand          d19, d21, d18
  .long  0xee244b90                          // vmov.32       d20[1], r4
  .long  0xf24441b2                          // vand          d20, d20, d18
  .long  0xf3fb46a4                          // vcvt.f32.u32  d20, d20
  .long  0xe7d93006                          // ldrb          r3, [r9, r6]
  .long  0xee203b90                          // vmov.32       d16[1], r3
  .long  0xf24001b2                          // vand          d16, d16, d18
  .long  0xf3fb26a3                          // vcvt.f32.u32  d18, d19
  .long  0xeddf3b09                          // vldr          d19, [pc, #36]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3010db3                          // vmul.f32      d0, d17, d19
  .long  0xf3042db3                          // vmul.f32      d2, d20, d19
  .long  0xf3021db3                          // vmul.f32      d1, d18, d19
  .long  0xf3003db3                          // vmul.f32      d3, d16, d19
  .long  0xe8bd4bf0                          // pop           {r4, r5, r6, r7, r8, r9, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_byte_tables_rgb_vfp4
.globl _sk_byte_tables_rgb_vfp4
_sk_byte_tables_rgb_vfp4:
  .long  0xe92d41f0                          // push          {r4, r5, r6, r7, r8, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf3c7301f                          // vmov.i32      d19, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe9930110                          // ldmib         r3, {r4, r8}
  .long  0xe593300c                          // ldr           r3, [r3, #12]
  .long  0xe2433001                          // sub           r3, r3, #1
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2402c30                          // vfma.f32      d18, d0, d16
  .long  0xf2411c30                          // vfma.f32      d17, d1, d16
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xee123b90                          // vmov.32       r3, d18[0]
  .long  0xee326b90                          // vmov.32       r6, d18[1]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2422c30                          // vfma.f32      d18, d2, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xee107b90                          // vmov.32       r7, d16[0]
  .long  0xee305b90                          // vmov.32       r5, d16[1]
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7dee006                          // ldrb          lr, [lr, r6]
  .long  0xee116b90                          // vmov.32       r6, d17[0]
  .long  0xee023b90                          // vmov.32       d18[0], r3
  .long  0xee313b90                          // vmov.32       r3, d17[1]
  .long  0xee22eb90                          // vmov.32       d18[1], lr
  .long  0xf24221b3                          // vand          d18, d18, d19
  .long  0xf3fb26a2                          // vcvt.f32.u32  d18, d18
  .long  0xe7d87007                          // ldrb          r7, [r8, r7]
  .long  0xee017b90                          // vmov.32       d17[0], r7
  .long  0xe7d46006                          // ldrb          r6, [r4, r6]
  .long  0xe7d43003                          // ldrb          r3, [r4, r3]
  .long  0xee006b90                          // vmov.32       d16[0], r6
  .long  0xe7d84005                          // ldrb          r4, [r8, r5]
  .long  0xee203b90                          // vmov.32       d16[1], r3
  .long  0xee214b90                          // vmov.32       d17[1], r4
  .long  0xf24001b3                          // vand          d16, d16, d19
  .long  0xf24111b3                          // vand          d17, d17, d19
  .long  0xeddf3b07                          // vldr          d19, [pc, #28]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3fb16a1                          // vcvt.f32.u32  d17, d17
  .long  0xf3020db3                          // vmul.f32      d0, d18, d19
  .long  0xf3001db3                          // vmul.f32      d1, d16, d19
  .long  0xf3012db3                          // vmul.f32      d2, d17, d19
  .long  0xe8bd41f0                          // pop           {r4, r5, r6, r7, r8, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_load_a8_vfp4
.globl _sk_load_a8_vfp4
_sk_load_a8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b03                          // vldr          d17, [pc, #12]
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_a8_vfp4
.globl _sk_gather_a8_vfp4
_sk_gather_a8_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7de4004                          // ldrb          r4, [lr, r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b03                          // vldr          d17, [pc, #12]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_store_a8_vfp4
.globl _sk_store_a8_vfp4
_sk_store_a8_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xeddf0b0d                          // vldr          d16, [pc, #52]
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2431c30                          // vfma.f32      d17, d3, d16
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee10eb90                          // vmov.32       lr, d16[0]
  .long  0xee30cb90                          // vmov.32       ip, d16[1]
  .long  0xe7e3e000                          // strb          lr, [r3, r0]!
  .long  0xe5c3c001                          // strb          ip, [r3, #1]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x437f0000                          // .word         0x437f0000

HIDDEN _sk_load_g8_vfp4
.globl _sk_load_g8_vfp4
_sk_load_g8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b05                          // vldr          d17, [pc, #20]
  .long  0xf3000db1                          // vmul.f32      d0, d16, d17
  .long  0xf2201110                          // vorr          d1, d0, d0
  .long  0xf2202110                          // vorr          d2, d0, d0
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_g8_vfp4
.globl _sk_gather_g8_vfp4
_sk_gather_g8_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7de4004                          // ldrb          r4, [lr, r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b05                          // vldr          d17, [pc, #20]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3000db1                          // vmul.f32      d0, d16, d17
  .long  0xf2201110                          // vorr          d1, d0, d0
  .long  0xf2202110                          // vorr          d2, d0, d0
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_i8_vfp4
.globl _sk_gather_i8_vfp4
_sk_gather_i8_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe1a0e001                          // mov           lr, r1
  .long  0xe491c004                          // ldr           ip, [r1], #4
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xe35c0000                          // cmp           ip, #0
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe1a0300c                          // mov           r3, ip
  .long  0x028e1008                          // addeq         r1, lr, #8
  .long  0x059e3004                          // ldreq         r3, [lr, #4]
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7de4004                          // ldrb          r4, [lr, r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xe59c4004                          // ldr           r4, [ip, #4]
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xee103b90                          // vmov.32       r3, d16[0]
  .long  0xee30eb90                          // vmov.32       lr, d16[1]
  .long  0xe0843103                          // add           r3, r4, r3, lsl #2
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe084310e                          // add           r3, r4, lr, lsl #2
  .long  0xf4e308bf                          // vld1.32       {d16[1]}, [r3 :32]
  .long  0xf24021b1                          // vand          d18, d16, d17
  .long  0xf3f83030                          // vshr.u32      d19, d16, #8
  .long  0xf3e84030                          // vshr.u32      d20, d16, #24
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3f00030                          // vshr.u32      d16, d16, #16
  .long  0xf24331b1                          // vand          d19, d19, d17
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b0a                          // vldr          d17, [pc, #40]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf3043db1                          // vmul.f32      d3, d20, d17
  .long  0xf3031db1                          // vmul.f32      d1, d19, d17
  .long  0xf3002db1                          // vmul.f32      d2, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_load_565_vfp4
.globl _sk_load_565_vfp4
_sk_load_565_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c1101f                          // vmov.i32      d17, #31
  .long  0xf3c72218                          // vmov.i32      d18, #63488
  .long  0xeddf3b16                          // vldr          d19, [pc, #88]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe7933080                          // ldr           r3, [r3, r0, lsl #1]
  .long  0xe58d3000                          // str           r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe3a03e7e                          // mov           r3, #2016
  .long  0xf3d04a30                          // vmovl.u16     q10, d16
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf24411b1                          // vand          d17, d20, d17
  .long  0xeddf5b0e                          // vldr          d21, [pc, #56]
  .long  0xf24421b2                          // vand          d18, d20, d18
  .long  0xf24401b0                          // vand          d16, d20, d16
  .long  0xeddf4b09                          // vldr          d20, [pc, #36]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3020db3                          // vmul.f32      d0, d18, d19
  .long  0xf3001db4                          // vmul.f32      d1, d16, d20
  .long  0xf3012db5                          // vmul.f32      d2, d17, d21
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0x37842108                          // .word         0x37842108
  .long  0x37842108                          // .word         0x37842108
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3d042108                          // .word         0x3d042108
  .long  0x3d042108                          // .word         0x3d042108

HIDDEN _sk_gather_565_vfp4
.globl _sk_gather_565_vfp4
_sk_gather_565_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xeddf4b20                          // vldr          d20, [pc, #128]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xeddf5b1e                          // vldr          d21, [pc, #120]
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xf2c1201f                          // vmov.i32      d18, #31
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c71218                          // vmov.i32      d17, #63488
  .long  0xe08e3083                          // add           r3, lr, r3, lsl #1
  .long  0xe08e4084                          // add           r4, lr, r4, lsl #1
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1d440b0                          // ldrh          r4, [r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xe3a03e7e                          // mov           r3, #2016
  .long  0xee833b90                          // vdup.32       d19, r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24011b1                          // vand          d17, d16, d17
  .long  0xf24031b3                          // vand          d19, d16, d19
  .long  0xf24001b2                          // vand          d16, d16, d18
  .long  0xf3fb2623                          // vcvt.f32.s32  d18, d19
  .long  0xeddf3b07                          // vldr          d19, [pc, #28]
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3021db4                          // vmul.f32      d1, d18, d20
  .long  0xf3010db3                          // vmul.f32      d0, d17, d19
  .long  0xf3002db5                          // vmul.f32      d2, d16, d21
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37842108                          // .word         0x37842108
  .long  0x37842108                          // .word         0x37842108
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3d042108                          // .word         0x3d042108
  .long  0x3d042108                          // .word         0x3d042108

HIDDEN _sk_store_565_vfp4
.globl _sk_store_565_vfp4
_sk_store_565_vfp4:
  .long  0xf2c30f1f                          // vmov.f32      d16, #31
  .long  0xeddf1b15                          // vldr          d17, [pc, #84]
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2413c31                          // vfma.f32      d19, d1, d17
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2422c30                          // vfma.f32      d18, d2, d16
  .long  0xe0833080                          // add           r3, r3, r0, lsl #1
  .long  0xf3fb07a3                          // vcvt.u32.f32  d16, d19
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf2e50530                          // vshl.s32      d16, d16, #5
  .long  0xf2eb1531                          // vshl.s32      d17, d17, #11
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xf26001b2                          // vorr          d16, d16, d18
  .long  0xf3f60121                          // vuzp.16       d16, d17
  .long  0xf4c3080f                          // vst1.32       {d16[0]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0x427c0000                          // .word         0x427c0000
  .long  0x427c0000                          // .word         0x427c0000

HIDDEN _sk_load_4444_vfp4
.globl _sk_load_4444_vfp4
_sk_load_4444_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c71210                          // vmov.i32      d17, #61440
  .long  0xf3c74010                          // vmov.i32      d20, #240
  .long  0xf2c0501f                          // vmov.i32      d21, #15
  .long  0xeddf6b1d                          // vldr          d22, [pc, #116]
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe7933080                          // ldr           r3, [r3, r0, lsl #1]
  .long  0xe58d3000                          // str           r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xf3d02a30                          // vmovl.u16     q9, d16
  .long  0xf2c0021f                          // vmov.i32      d16, #3840
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xf24201b0                          // vand          d16, d18, d16
  .long  0xf24241b4                          // vand          d20, d18, d20
  .long  0xf24221b5                          // vand          d18, d18, d21
  .long  0xeddf3b0c                          // vldr          d19, [pc, #48]
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xeddf5b0c                          // vldr          d21, [pc, #48]
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3010db3                          // vmul.f32      d0, d17, d19
  .long  0xeddf1b0b                          // vldr          d17, [pc, #44]
  .long  0xf3001db5                          // vmul.f32      d1, d16, d21
  .long  0xf3042db6                          // vmul.f32      d2, d20, d22
  .long  0xf3023db1                          // vmul.f32      d3, d18, d17
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37888889                          // .word         0x37888889
  .long  0x37888889                          // .word         0x37888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3d888889                          // .word         0x3d888889
  .long  0x3d888889                          // .word         0x3d888889

HIDDEN _sk_gather_4444_vfp4
.globl _sk_gather_4444_vfp4
_sk_gather_4444_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xf3c73010                          // vmov.i32      d19, #240
  .long  0xeddf5b21                          // vldr          d21, [pc, #132]
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf2c0401f                          // vmov.i32      d20, #15
  .long  0xeddf6b20                          // vldr          d22, [pc, #128]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xf2c0221f                          // vmov.i32      d18, #3840
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c71210                          // vmov.i32      d17, #61440
  .long  0xe08e3083                          // add           r3, lr, r3, lsl #1
  .long  0xe08e4084                          // add           r4, lr, r4, lsl #1
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1d440b0                          // ldrh          r4, [r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24011b1                          // vand          d17, d16, d17
  .long  0xf24021b2                          // vand          d18, d16, d18
  .long  0xf24031b3                          // vand          d19, d16, d19
  .long  0xf24001b4                          // vand          d16, d16, d20
  .long  0xeddf4b0a                          // vldr          d20, [pc, #40]
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3010db4                          // vmul.f32      d0, d17, d20
  .long  0xeddf1b0a                          // vldr          d17, [pc, #40]
  .long  0xf3021db5                          // vmul.f32      d1, d18, d21
  .long  0xf3032db6                          // vmul.f32      d2, d19, d22
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x37888889                          // .word         0x37888889
  .long  0x37888889                          // .word         0x37888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3d888889                          // .word         0x3d888889
  .long  0x3d888889                          // .word         0x3d888889

HIDDEN _sk_store_4444_vfp4
.globl _sk_store_4444_vfp4
_sk_store_4444_vfp4:
  .long  0xf2c20f1e                          // vmov.f32      d16, #15
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xf2402c30                          // vfma.f32      d18, d0, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2413c30                          // vfma.f32      d19, d1, d16
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xe0833080                          // add           r3, r3, r0, lsl #1
  .long  0xf2424c30                          // vfma.f32      d20, d2, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2431c30                          // vfma.f32      d17, d3, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xf3fb27a3                          // vcvt.u32.f32  d18, d19
  .long  0xf3fb37a4                          // vcvt.u32.f32  d19, d20
  .long  0xf2ec0530                          // vshl.s32      d16, d16, #12
  .long  0xf2e82532                          // vshl.s32      d18, d18, #8
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf2e43533                          // vshl.s32      d19, d19, #4
  .long  0xf26201b0                          // vorr          d16, d18, d16
  .long  0xf26001b3                          // vorr          d16, d16, d19
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xf3f60121                          // vuzp.16       d16, d17
  .long  0xf4c3080f                          // vst1.32       {d16[0]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_load_8888_vfp4
.globl _sk_load_8888_vfp4
_sk_load_8888_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c7001f                          // vmov.i32      d16, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833100                          // add           r3, r3, r0, lsl #2
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf24121b0                          // vand          d18, d17, d16
  .long  0xf3f83031                          // vshr.u32      d19, d17, #8
  .long  0xf3e84031                          // vshr.u32      d20, d17, #24
  .long  0xf3f01031                          // vshr.u32      d17, d17, #16
  .long  0xf24331b0                          // vand          d19, d19, d16
  .long  0xf24101b0                          // vand          d16, d17, d16
  .long  0xeddf1b08                          // vldr          d17, [pc, #32]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf3043db1                          // vmul.f32      d3, d20, d17
  .long  0xf3031db1                          // vmul.f32      d1, d19, d17
  .long  0xf3002db1                          // vmul.f32      d2, d16, d17
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_8888_vfp4
.globl _sk_gather_8888_vfp4
_sk_gather_8888_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe08e3103                          // add           r3, lr, r3, lsl #2
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe08e3104                          // add           r3, lr, r4, lsl #2
  .long  0xf4e308bf                          // vld1.32       {d16[1]}, [r3 :32]
  .long  0xf24021b1                          // vand          d18, d16, d17
  .long  0xf3f83030                          // vshr.u32      d19, d16, #8
  .long  0xf3e84030                          // vshr.u32      d20, d16, #24
  .long  0xf3f00030                          // vshr.u32      d16, d16, #16
  .long  0xf24331b1                          // vand          d19, d19, d17
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b09                          // vldr          d17, [pc, #36]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf3043db1                          // vmul.f32      d3, d20, d17
  .long  0xf3031db1                          // vmul.f32      d1, d19, d17
  .long  0xf3002db1                          // vmul.f32      d2, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_store_8888_vfp4
.globl _sk_store_8888_vfp4
_sk_store_8888_vfp4:
  .long  0xeddf0b1a                          // vldr          d16, [pc, #104]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2412c30                          // vfma.f32      d18, d1, d16
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2423c30                          // vfma.f32      d19, d2, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xe0833100                          // add           r3, r3, r0, lsl #2
  .long  0xf2434c30                          // vfma.f32      d20, d3, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xf3fb27a3                          // vcvt.u32.f32  d18, d19
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf3fb37a4                          // vcvt.u32.f32  d19, d20
  .long  0xf2e80530                          // vshl.s32      d16, d16, #8
  .long  0xf2f02532                          // vshl.s32      d18, d18, #16
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xf2f81533                          // vshl.s32      d17, d19, #24
  .long  0xf26001b2                          // vorr          d16, d16, d18
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xedc30b00                          // vstr          d16, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x437f0000                          // .word         0x437f0000

HIDDEN _sk_load_f16_vfp4
.globl _sk_load_f16_vfp4
_sk_load_f16_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf4e3070d                          // vld4.16       {d16[0],d17[0],d18[0],d19[0]}, [r3]!
  .long  0xf4e3074f                          // vld4.16       {d16[1],d17[1],d18[1],d19[1]}, [r3]
  .long  0xf3b60720                          // vcvt.f32.f16  q0, d16
  .long  0xf3b62722                          // vcvt.f32.f16  q1, d18
  .long  0xf3f64721                          // vcvt.f32.f16  q10, d17
  .long  0xf3f60723                          // vcvt.f32.f16  q8, d19
  .long  0xf22411b4                          // vorr          d1, d20, d20
  .long  0xf22031b0                          // vorr          d3, d16, d16
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_gather_f16_vfp4
.globl _sk_gather_f16_vfp4
_sk_gather_f16_vfp4:
  .long  0xe92d4c10                          // push          {r4, sl, fp, lr}
  .long  0xe28db008                          // add           fp, sp, #8
  .long  0xe24dd010                          // sub           sp, sp, #16
  .long  0xe7c3d01f                          // bfc           sp, #0, #4
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe493c008                          // ldr           ip, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee31eb90                          // vmov.32       lr, d17[1]
  .long  0xe08c4183                          // add           r4, ip, r3, lsl #3
  .long  0xe08c318e                          // add           r3, ip, lr, lsl #3
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xedd40b00                          // vldr          d16, [r4]
  .long  0xf4430aef                          // vst1.64       {d16-d17}, [r3 :128]
  .long  0xf4e3071f                          // vld4.16       {d16[0],d17[0],d18[0],d19[0]}, [r3 :64]
  .long  0xe3833008                          // orr           r3, r3, #8
  .long  0xf4e3075f                          // vld4.16       {d16[1],d17[1],d18[1],d19[1]}, [r3 :64]
  .long  0xf3b60720                          // vcvt.f32.f16  q0, d16
  .long  0xf3b62722                          // vcvt.f32.f16  q1, d18
  .long  0xe5913004                          // ldr           r3, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf3f64721                          // vcvt.f32.f16  q10, d17
  .long  0xf3f60723                          // vcvt.f32.f16  q8, d19
  .long  0xf22411b4                          // vorr          d1, d20, d20
  .long  0xf22031b0                          // vorr          d3, d16, d16
  .long  0xe12fff33                          // blx           r3
  .long  0xe24bd008                          // sub           sp, fp, #8
  .long  0xe8bd8c10                          // pop           {r4, sl, fp, pc}

HIDDEN _sk_store_f16_vfp4
.globl _sk_store_f16_vfp4
_sk_store_f16_vfp4:
  .long  0xf2630113                          // vorr          d16, d3, d3
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2612111                          // vorr          d18, d1, d1
  .long  0xf3f67620                          // vcvt.f16.f32  d23, q8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf3f66602                          // vcvt.f16.f32  d22, q1
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf3f65622                          // vcvt.f16.f32  d21, q9
  .long  0xf3f64600                          // vcvt.f16.f32  d20, q0
  .long  0xf22211b2                          // vorr          d1, d18, d18
  .long  0xf22031b0                          // vorr          d3, d16, d16
  .long  0xf4c3470d                          // vst4.16       {d20[0],d21[0],d22[0],d23[0]}, [r3]!
  .long  0xf4c3474f                          // vst4.16       {d20[1],d21[1],d22[1],d23[1]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_load_u16_be_vfp4
.globl _sk_load_u16_be_vfp4
_sk_load_u16_be_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf4e3070d                          // vld4.16       {d16[0],d17[0],d18[0],d19[0]}, [r3]!
  .long  0xf4e3074f                          // vld4.16       {d16[1],d17[1],d18[1],d19[1]}, [r3]
  .long  0xee903bb0                          // vmov.u16      r3, d16[0]
  .long  0xee92ebb0                          // vmov.u16      lr, d18[0]
  .long  0xee914bb0                          // vmov.u16      r4, d17[0]
  .long  0xee937bb0                          // vmov.u16      r7, d19[0]
  .long  0xee905bf0                          // vmov.u16      r5, d16[1]
  .long  0xee926bf0                          // vmov.u16      r6, d18[1]
  .long  0xee043b90                          // vmov.32       d20[0], r3
  .long  0xee05eb90                          // vmov.32       d21[0], lr
  .long  0xee93ebf0                          // vmov.u16      lr, d19[1]
  .long  0xee913bf0                          // vmov.u16      r3, d17[1]
  .long  0xf3c71c1f                          // vmov.i32      d17, #65535
  .long  0xee004b90                          // vmov.32       d16[0], r4
  .long  0xee027b90                          // vmov.32       d18[0], r7
  .long  0xee245b90                          // vmov.32       d20[1], r5
  .long  0xf24431b1                          // vand          d19, d20, d17
  .long  0xee256b90                          // vmov.32       d21[1], r6
  .long  0xf2e84534                          // vshl.s32      d20, d20, #8
  .long  0xf24561b1                          // vand          d22, d21, d17
  .long  0xf3f83033                          // vshr.u32      d19, d19, #8
  .long  0xf2e85535                          // vshl.s32      d21, d21, #8
  .long  0xf26431b3                          // vorr          d19, d20, d19
  .long  0xf3f86036                          // vshr.u32      d22, d22, #8
  .long  0xf24331b1                          // vand          d19, d19, d17
  .long  0xf26551b6                          // vorr          d21, d21, d22
  .long  0xf3fb36a3                          // vcvt.f32.u32  d19, d19
  .long  0xee22eb90                          // vmov.32       d18[1], lr
  .long  0xee203b90                          // vmov.32       d16[1], r3
  .long  0xf24281b1                          // vand          d24, d18, d17
  .long  0xf2e82532                          // vshl.s32      d18, d18, #8
  .long  0xf24071b1                          // vand          d23, d16, d17
  .long  0xf3f84038                          // vshr.u32      d20, d24, #8
  .long  0xf2e80530                          // vshl.s32      d16, d16, #8
  .long  0xf3f87037                          // vshr.u32      d23, d23, #8
  .long  0xf26221b4                          // vorr          d18, d18, d20
  .long  0xf26001b7                          // vorr          d16, d16, d23
  .long  0xf24541b1                          // vand          d20, d21, d17
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xeddf2b09                          // vldr          d18, [pc, #36]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3fb46a4                          // vcvt.f32.u32  d20, d20
  .long  0xf3fb16a1                          // vcvt.f32.u32  d17, d17
  .long  0xf3030db2                          // vmul.f32      d0, d19, d18
  .long  0xf3001db2                          // vmul.f32      d1, d16, d18
  .long  0xf3042db2                          // vmul.f32      d2, d20, d18
  .long  0xf3013db2                          // vmul.f32      d3, d17, d18
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37800080                          // .word         0x37800080
  .long  0x37800080                          // .word         0x37800080

HIDDEN _sk_store_u16_be_vfp4
.globl _sk_store_u16_be_vfp4
_sk_store_u16_be_vfp4:
  .long  0xeddf0b2a                          // vldr          d16, [pc, #168]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2432c30                          // vfma.f32      d18, d3, d16
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xf2423c30                          // vfma.f32      d19, d2, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2414c30                          // vfma.f32      d20, d1, d16
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xf3fb27a3                          // vcvt.u32.f32  d18, d19
  .long  0xf3c73c1f                          // vmov.i32      d19, #65535
  .long  0xf3fb47a4                          // vcvt.u32.f32  d20, d20
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf24051b3                          // vand          d21, d16, d19
  .long  0xf24261b3                          // vand          d22, d18, d19
  .long  0xf24471b3                          // vand          d23, d20, d19
  .long  0xf24131b3                          // vand          d19, d17, d19
  .long  0xf2e80530                          // vshl.s32      d16, d16, #8
  .long  0xf3f85035                          // vshr.u32      d21, d21, #8
  .long  0xf2e82532                          // vshl.s32      d18, d18, #8
  .long  0xf3f86036                          // vshr.u32      d22, d22, #8
  .long  0xf260b1b5                          // vorr          d27, d16, d21
  .long  0xf2e84534                          // vshl.s32      d20, d20, #8
  .long  0xf3f87037                          // vshr.u32      d23, d23, #8
  .long  0xf262a1b6                          // vorr          d26, d18, d22
  .long  0xf2e81531                          // vshl.s32      d17, d17, #8
  .long  0xf3f83033                          // vshr.u32      d19, d19, #8
  .long  0xf26491b7                          // vorr          d25, d20, d23
  .long  0xf26181b3                          // vorr          d24, d17, d19
  .long  0xf3f6b120                          // vuzp.16       d27, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf3f6a120                          // vuzp.16       d26, d16
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf3f69120                          // vuzp.16       d25, d16
  .long  0xf3f68120                          // vuzp.16       d24, d16
  .long  0xf4c3870d                          // vst4.16       {d24[0],d25[0],d26[0],d27[0]}, [r3]!
  .long  0xf4c3874f                          // vst4.16       {d24[1],d25[1],d26[1],d27[1]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x477fff00                          // .word         0x477fff00
  .long  0x477fff00                          // .word         0x477fff00

HIDDEN _sk_load_f32_vfp4
.globl _sk_load_f32_vfp4
_sk_load_f32_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833200                          // add           r3, r3, r0, lsl #4
  .long  0xf423008f                          // vld4.32       {d0-d3}, [r3]
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_store_f32_vfp4
.globl _sk_store_f32_vfp4
_sk_store_f32_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833200                          // add           r3, r3, r0, lsl #4
  .long  0xf403008f                          // vst4.32       {d0-d3}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_clamp_x_vfp4
.globl _sk_clamp_x_vfp4
_sk_clamp_x_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf2400f80                          // vmax.f32      d16, d16, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2200fa1                          // vmin.f32      d0, d16, d17
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_clamp_y_vfp4
.globl _sk_clamp_y_vfp4
_sk_clamp_y_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf2400f81                          // vmax.f32      d16, d16, d1
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2201fa1                          // vmin.f32      d1, d16, d17
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_repeat_x_vfp4
.globl _sk_repeat_x_vfp4
_sk_repeat_x_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c02010                          // vmov.i32      d18, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xeec09a88                          // vdiv.f32      s19, s1, s16
  .long  0xee809a08                          // vdiv.f32      s18, s0, s16
  .long  0xf3fb0709                          // vcvt.s32.f32  d16, d9
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3601e89                          // vcgt.f32      d17, d16, d9
  .long  0xf35311b2                          // vbsl          d17, d19, d18
  .long  0xf3f42c08                          // vdup.32       d18, d8[0]
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2e009c8                          // vmul.f32      d16, d16, d8[0]
  .long  0xf2600d20                          // vsub.f32      d16, d0, d16
  .long  0xf2200fa1                          // vmin.f32      d0, d16, d17
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_repeat_y_vfp4
.globl _sk_repeat_y_vfp4
_sk_repeat_y_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c02010                          // vmov.i32      d18, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xeec19a88                          // vdiv.f32      s19, s3, s16
  .long  0xee819a08                          // vdiv.f32      s18, s2, s16
  .long  0xf3fb0709                          // vcvt.s32.f32  d16, d9
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3601e89                          // vcgt.f32      d17, d16, d9
  .long  0xf35311b2                          // vbsl          d17, d19, d18
  .long  0xf3f42c08                          // vdup.32       d18, d8[0]
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2e009c8                          // vmul.f32      d16, d16, d8[0]
  .long  0xf2610d20                          // vsub.f32      d16, d1, d16
  .long  0xf2201fa1                          // vmin.f32      d1, d16, d17
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_mirror_x_vfp4
.globl _sk_mirror_x_vfp4
_sk_mirror_x_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf4b14                          // vldr          d20, [pc, #80]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xee389a08                          // vadd.f32      s18, s16, s16
  .long  0xf3f40c08                          // vdup.32       d16, d8[0]
  .long  0xf2200d20                          // vsub.f32      d0, d0, d16
  .long  0xeec08a89                          // vdiv.f32      s17, s1, s18
  .long  0xee808a09                          // vdiv.f32      s16, s0, s18
  .long  0xf3fb1708                          // vcvt.s32.f32  d17, d8
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612e88                          // vcgt.f32      d18, d17, d8
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xf3c72e1f                          // vmov.i8       d18, #255
  .long  0xf2e119c9                          // vmul.f32      d17, d17, d9[0]
  .long  0xf2601d21                          // vsub.f32      d17, d0, d17
  .long  0xf2611da0                          // vsub.f32      d17, d17, d16
  .long  0xf26008a2                          // vadd.i32      d16, d16, d18
  .long  0xf3f91721                          // vabs.f32      d17, d17
  .long  0xf2210fa0                          // vmin.f32      d0, d17, d16
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_mirror_y_vfp4
.globl _sk_mirror_y_vfp4
_sk_mirror_y_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf4b14                          // vldr          d20, [pc, #80]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xee389a08                          // vadd.f32      s18, s16, s16
  .long  0xf3f40c08                          // vdup.32       d16, d8[0]
  .long  0xf2211d20                          // vsub.f32      d1, d1, d16
  .long  0xeec18a89                          // vdiv.f32      s17, s3, s18
  .long  0xee818a09                          // vdiv.f32      s16, s2, s18
  .long  0xf3fb1708                          // vcvt.s32.f32  d17, d8
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612e88                          // vcgt.f32      d18, d17, d8
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xf3c72e1f                          // vmov.i8       d18, #255
  .long  0xf2e119c9                          // vmul.f32      d17, d17, d9[0]
  .long  0xf2611d21                          // vsub.f32      d17, d1, d17
  .long  0xf2611da0                          // vsub.f32      d17, d17, d16
  .long  0xf26008a2                          // vadd.i32      d16, d16, d18
  .long  0xf3f91721                          // vabs.f32      d17, d17
  .long  0xf2211fa0                          // vmin.f32      d1, d17, d16
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_luminance_to_alpha_vfp4
.globl _sk_luminance_to_alpha_vfp4
_sk_luminance_to_alpha_vfp4:
  .long  0xeddf0b0a                          // vldr          d16, [pc, #40]
  .long  0xeddf1b0b                          // vldr          d17, [pc, #44]
  .long  0xf3410d30                          // vmul.f32      d16, d1, d16
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3401d31                          // vmul.f32      d17, d0, d17
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xf2013da0                          // vadd.f32      d3, d17, d16
  .long  0xeddf0b06                          // vldr          d16, [pc, #24]
  .long  0xf2023c30                          // vfma.f32      d3, d2, d16
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xe12fff13                          // bx            r3
  .long  0x3f371759                          // .word         0x3f371759
  .long  0x3f371759                          // .word         0x3f371759
  .long  0x3e59b3d0                          // .word         0x3e59b3d0
  .long  0x3e59b3d0                          // .word         0x3e59b3d0
  .long  0x3d93dd98                          // .word         0x3d93dd98
  .long  0x3d93dd98                          // .word         0x3d93dd98

HIDDEN _sk_matrix_2x3_vfp4
.globl _sk_matrix_2x3_vfp4
_sk_matrix_2x3_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf2410c31                          // vfma.f32      d16, d1, d17
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xf2411c32                          // vfma.f32      d17, d1, d18
  .long  0xf4ee2c9d                          // vld1.32       {d18[]}, [lr :32]!
  .long  0xf4ee3c9f                          // vld1.32       {d19[]}, [lr :32]
  .long  0xf2400c32                          // vfma.f32      d16, d0, d18
  .long  0xf2401c33                          // vfma.f32      d17, d0, d19
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_matrix_3x4_vfp4
.globl _sk_matrix_3x4_vfp4
_sk_matrix_3x4_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe28e3020                          // add           r3, lr, #32
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xe28e302c                          // add           r3, lr, #44
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e301c                          // add           r3, lr, #28
  .long  0xf2420c33                          // vfma.f32      d16, d2, d19
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e3024                          // add           r3, lr, #36
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3028                          // add           r3, lr, #40
  .long  0xf2421c32                          // vfma.f32      d17, d2, d18
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf2422c34                          // vfma.f32      d18, d2, d20
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf2411c34                          // vfma.f32      d17, d1, d20
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf2410c34                          // vfma.f32      d16, d1, d20
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf2412c33                          // vfma.f32      d18, d1, d19
  .long  0xf4ee3c9d                          // vld1.32       {d19[]}, [lr :32]!
  .long  0xf4ee4c9f                          // vld1.32       {d20[]}, [lr :32]
  .long  0xf2401c33                          // vfma.f32      d17, d0, d19
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xf2400c33                          // vfma.f32      d16, d0, d19
  .long  0xf2402c34                          // vfma.f32      d18, d0, d20
  .long  0xf22101b1                          // vorr          d0, d17, d17
  .long  0xf22021b0                          // vorr          d2, d16, d16
  .long  0xf22211b2                          // vorr          d1, d18, d18
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_matrix_4x5_vfp4
.globl _sk_matrix_4x5_vfp4
_sk_matrix_4x5_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2620112                          // vorr          d16, d2, d2
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe2834014                          // add           r4, r3, #20
  .long  0xe1a0e003                          // mov           lr, r3
  .long  0xf4e45c9f                          // vld1.32       {d21[]}, [r4 :32]
  .long  0xe2834028                          // add           r4, r3, #40
  .long  0xf4e46c9f                          // vld1.32       {d22[]}, [r4 :32]
  .long  0xe2834038                          // add           r4, r3, #56
  .long  0xf4e47c9f                          // vld1.32       {d23[]}, [r4 :32]
  .long  0xe2834048                          // add           r4, r3, #72
  .long  0xf4a42c9f                          // vld1.32       {d2[]}, [r4 :32]
  .long  0xe2834034                          // add           r4, r3, #52
  .long  0xf2032c37                          // vfma.f32      d2, d3, d23
  .long  0xf4e48c9f                          // vld1.32       {d24[]}, [r4 :32]
  .long  0xe2834044                          // add           r4, r3, #68
  .long  0xf4e41c9f                          // vld1.32       {d17[]}, [r4 :32]
  .long  0xe2834030                          // add           r4, r3, #48
  .long  0xf2431c38                          // vfma.f32      d17, d3, d24
  .long  0xf4e49c9f                          // vld1.32       {d25[]}, [r4 :32]
  .long  0xe283403c                          // add           r4, r3, #60
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xe283404c                          // add           r4, r3, #76
  .long  0xf2002cb6                          // vfma.f32      d2, d16, d22
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe2834040                          // add           r4, r3, #64
  .long  0xf2432c33                          // vfma.f32      d18, d3, d19
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xe2834020                          // add           r4, r3, #32
  .long  0xf2433c39                          // vfma.f32      d19, d3, d25
  .long  0xf4e47c9f                          // vld1.32       {d23[]}, [r4 :32]
  .long  0xe283402c                          // add           r4, r3, #44
  .long  0xf4e48c9f                          // vld1.32       {d24[]}, [r4 :32]
  .long  0xe2834024                          // add           r4, r3, #36
  .long  0xf2402cb8                          // vfma.f32      d18, d16, d24
  .long  0xf4e48c9f                          // vld1.32       {d24[]}, [r4 :32]
  .long  0xf2401cb8                          // vfma.f32      d17, d16, d24
  .long  0xe2834010                          // add           r4, r3, #16
  .long  0xf2403cb7                          // vfma.f32      d19, d16, d23
  .long  0xf4ee4c9d                          // vld1.32       {d20[]}, [lr :32]!
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xe283401c                          // add           r4, r3, #28
  .long  0xf4e46c9f                          // vld1.32       {d22[]}, [r4 :32]
  .long  0xe2834018                          // add           r4, r3, #24
  .long  0xf2412c36                          // vfma.f32      d18, d1, d22
  .long  0xf2411c35                          // vfma.f32      d17, d1, d21
  .long  0xf4ee5c9f                          // vld1.32       {d21[]}, [lr :32]
  .long  0xf2413c30                          // vfma.f32      d19, d1, d16
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xe2834008                          // add           r4, r3, #8
  .long  0xe283300c                          // add           r3, r3, #12
  .long  0xf2012c30                          // vfma.f32      d2, d1, d16
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xf2401c35                          // vfma.f32      d17, d0, d21
  .long  0xf2403c34                          // vfma.f32      d19, d0, d20
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf2402c34                          // vfma.f32      d18, d0, d20
  .long  0xf2002c30                          // vfma.f32      d2, d0, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22301b3                          // vorr          d0, d19, d19
  .long  0xf22231b2                          // vorr          d3, d18, d18
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_matrix_perspective_vfp4
.globl _sk_matrix_perspective_vfp4
_sk_matrix_perspective_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe28e301c                          // add           r3, lr, #28
  .long  0xe28e4010                          // add           r4, lr, #16
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3020                          // add           r3, lr, #32
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf2411c30                          // vfma.f32      d17, d1, d16
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe1a0300e                          // mov           r3, lr
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe28e4008                          // add           r4, lr, #8
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xf4e30c9d                          // vld1.32       {d16[]}, [r3 :32]!
  .long  0xf4e35c9f                          // vld1.32       {d21[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf2413c35                          // vfma.f32      d19, d1, d21
  .long  0xf4e35c9f                          // vld1.32       {d21[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf2415c32                          // vfma.f32      d21, d1, d18
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf3fb4521                          // vrecpe.f32    d20, d17
  .long  0xf2403c30                          // vfma.f32      d19, d0, d16
  .long  0xf2411fb4                          // vrecps.f32    d17, d17, d20
  .long  0xf2405c32                          // vfma.f32      d21, d0, d18
  .long  0xf3440db1                          // vmul.f32      d16, d20, d17
  .long  0xf3030db0                          // vmul.f32      d0, d19, d16
  .long  0xf3051db0                          // vmul.f32      d1, d21, d16
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_linear_gradient_vfp4
.globl _sk_linear_gradient_vfp4
_sk_linear_gradient_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xe1a0400e                          // mov           r4, lr
  .long  0xf4a33c9f                          // vld1.32       {d3[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf4a32c9f                          // vld1.32       {d2[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe494c00c                          // ldr           ip, [r4], #12
  .long  0xf4a41c9f                          // vld1.32       {d1[]}, [r4 :32]
  .long  0xe35c0000                          // cmp           ip, #0
  .long  0x0a000036                          // beq           2680 <sk_linear_gradient_vfp4+0x110>
  .long  0xe59e3004                          // ldr           r3, [lr, #4]
  .long  0xf2c01010                          // vmov.i32      d17, #0
  .long  0xf2c07010                          // vmov.i32      d23, #0
  .long  0xf2c08010                          // vmov.i32      d24, #0
  .long  0xe2833020                          // add           r3, r3, #32
  .long  0xf2c06010                          // vmov.i32      d22, #0
  .long  0xe2434018                          // sub           r4, r3, #24
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xe25cc001                          // subs          ip, ip, #1
  .long  0xf4e4dc9f                          // vld1.32       {d29[]}, [r4 :32]
  .long  0xe2434014                          // sub           r4, r3, #20
  .long  0xf4e45c9f                          // vld1.32       {d21[]}, [r4 :32]
  .long  0xe243400c                          // sub           r4, r3, #12
  .long  0xf4e44c9f                          // vld1.32       {d20[]}, [r4 :32]
  .long  0xe2434020                          // sub           r4, r3, #32
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe2434004                          // sub           r4, r3, #4
  .long  0xf3622e80                          // vcgt.f32      d18, d18, d0
  .long  0xf4e4bc9f                          // vld1.32       {d27[]}, [r4 :32]
  .long  0xe2434008                          // sub           r4, r3, #8
  .long  0xf4e4cc9f                          // vld1.32       {d28[]}, [r4 :32]
  .long  0xe2434010                          // sub           r4, r3, #16
  .long  0xf262a1b2                          // vorr          d26, d18, d18
  .long  0xf4e4ec9f                          // vld1.32       {d30[]}, [r4 :32]
  .long  0xe243401c                          // sub           r4, r3, #28
  .long  0xf352a13b                          // vbsl          d26, d2, d27
  .long  0xe2833024                          // add           r3, r3, #36
  .long  0xf262b1b2                          // vorr          d27, d18, d18
  .long  0xf26291b2                          // vorr          d25, d18, d18
  .long  0xf351b13c                          // vbsl          d27, d1, d28
  .long  0xf262c1b2                          // vorr          d28, d18, d18
  .long  0xf3539133                          // vbsl          d25, d3, d19
  .long  0xf350c1b4                          // vbsl          d28, d16, d20
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xf26241b2                          // vorr          d20, d18, d18
  .long  0xf26231b2                          // vorr          d19, d18, d18
  .long  0xf35841b5                          // vbsl          d20, d24, d21
  .long  0xf26251b2                          // vorr          d21, d18, d18
  .long  0xf35121b0                          // vbsl          d18, d17, d16
  .long  0xf35731be                          // vbsl          d19, d23, d30
  .long  0xf35651bd                          // vbsl          d21, d22, d29
  .long  0xf26211b2                          // vorr          d17, d18, d18
  .long  0xf22931b9                          // vorr          d3, d25, d25
  .long  0xf22a21ba                          // vorr          d2, d26, d26
  .long  0xf22b11bb                          // vorr          d1, d27, d27
  .long  0xf26c01bc                          // vorr          d16, d28, d28
  .long  0xf26371b3                          // vorr          d23, d19, d19
  .long  0xf26481b4                          // vorr          d24, d20, d20
  .long  0xf26561b5                          // vorr          d22, d21, d21
  .long  0x1affffd3                          // bne           25bc <sk_linear_gradient_vfp4+0x4c>
  .long  0xf26c01bc                          // vorr          d16, d28, d28
  .long  0xf22b11bb                          // vorr          d1, d27, d27
  .long  0xf22a21ba                          // vorr          d2, d26, d26
  .long  0xf22931b9                          // vorr          d3, d25, d25
  .long  0xea000003                          // b             2690 <sk_linear_gradient_vfp4+0x120>
  .long  0xf2c05010                          // vmov.i32      d21, #0
  .long  0xf2c04010                          // vmov.i32      d20, #0
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2c02010                          // vmov.i32      d18, #0
  .long  0xf2400c32                          // vfma.f32      d16, d0, d18
  .long  0xe5913004                          // ldr           r3, [r1, #4]
  .long  0xf2001c35                          // vfma.f32      d1, d0, d21
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2002c34                          // vfma.f32      d2, d0, d20
  .long  0xf2003c33                          // vfma.f32      d3, d0, d19
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_linear_gradient_2stops_vfp4
.globl _sk_linear_gradient_2stops_vfp4
_sk_linear_gradient_2stops_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe283400c                          // add           r4, r3, #12
  .long  0xe1a0e003                          // mov           lr, r3
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe2834008                          // add           r4, r3, #8
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xe2834018                          // add           r4, r3, #24
  .long  0xf4a42c9f                          // vld1.32       {d2[]}, [r4 :32]
  .long  0xe2834010                          // add           r4, r3, #16
  .long  0xf2002c33                          // vfma.f32      d2, d0, d19
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xe283401c                          // add           r4, r3, #28
  .long  0xe2833014                          // add           r3, r3, #20
  .long  0xf4ee1c9d                          // vld1.32       {d17[]}, [lr :32]!
  .long  0xf2400c31                          // vfma.f32      d16, d0, d17
  .long  0xf4a43c9f                          // vld1.32       {d3[]}, [r4 :32]
  .long  0xf2003c32                          // vfma.f32      d3, d0, d18
  .long  0xf4ee1c9f                          // vld1.32       {d17[]}, [lr :32]
  .long  0xf4a31c9f                          // vld1.32       {d1[]}, [r3 :32]
  .long  0xf2001c31                          // vfma.f32      d1, d0, d17
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_save_xy_vfp4
.globl _sk_save_xy_vfp4
_sk_save_xy_vfp4:
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xeddf7b17                          // vldr          d23, [pc, #92]
  .long  0xf2c06010                          // vmov.i32      d22, #0
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2401d20                          // vadd.f32      d17, d0, d16
  .long  0xf2410d20                          // vadd.f32      d16, d1, d16
  .long  0xed830b00                          // vstr          d0, [r3]
  .long  0xed831b08                          // vstr          d1, [r3, #32]
  .long  0xf3fb2721                          // vcvt.s32.f32  d18, d17
  .long  0xf3fb3720                          // vcvt.s32.f32  d19, d16
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3624ea1                          // vcgt.f32      d20, d18, d17
  .long  0xf3635ea0                          // vcgt.f32      d21, d19, d16
  .long  0xf35741b6                          // vbsl          d20, d23, d22
  .long  0xf35751b6                          // vbsl          d21, d23, d22
  .long  0xf2622da4                          // vsub.f32      d18, d18, d20
  .long  0xf2633da5                          // vsub.f32      d19, d19, d21
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xf2600da3                          // vsub.f32      d16, d16, d19
  .long  0xedc31b10                          // vstr          d17, [r3, #64]
  .long  0xedc30b18                          // vstr          d16, [r3, #96]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_accumulate_vfp4
.globl _sk_accumulate_vfp4
_sk_accumulate_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xedd31b28                          // vldr          d17, [r3, #160]
  .long  0xedd30b20                          // vldr          d16, [r3, #128]
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf2004c90                          // vfma.f32      d4, d16, d0
  .long  0xf2005c91                          // vfma.f32      d5, d16, d1
  .long  0xf2006c92                          // vfma.f32      d6, d16, d2
  .long  0xf2007c93                          // vfma.f32      d7, d16, d3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_nx_vfp4
.globl _sk_bilinear_nx_vfp4
_sk_bilinear_nx_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf3c3261f                          // vmov.i32      d18, #-1090519040
  .long  0xf2010da2                          // vadd.f32      d0, d17, d18
  .long  0xedc30b20                          // vstr          d16, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_px_vfp4
.globl _sk_bilinear_px_vfp4
_sk_bilinear_px_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2010da0                          // vadd.f32      d0, d17, d16
  .long  0xedc32b20                          // vstr          d18, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_ny_vfp4
.globl _sk_bilinear_ny_vfp4
_sk_bilinear_ny_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf3c3261f                          // vmov.i32      d18, #-1090519040
  .long  0xf2011da2                          // vadd.f32      d1, d17, d18
  .long  0xedc30b28                          // vstr          d16, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_py_vfp4
.globl _sk_bilinear_py_vfp4
_sk_bilinear_py_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2011da0                          // vadd.f32      d1, d17, d16
  .long  0xedc32b28                          // vstr          d18, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bicubic_n3x_vfp4
.globl _sk_bicubic_n3x_vfp4
_sk_bicubic_n3x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0b                          // vldr          d18, [pc, #44]
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3400db0                          // vmul.f32      d16, d16, d16
  .long  0xf3c72f18                          // vmov.f32      d18, #-1.5
  .long  0xf2010da2                          // vadd.f32      d0, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b20                          // vstr          d16, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab

HIDDEN _sk_bicubic_n1x_vfp4
.globl _sk_bicubic_n1x_vfp4
_sk_bicubic_n1x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xf2c73f18                          // vmov.f32      d19, #1.5
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0d                          // vldr          d18, [pc, #52]
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2402cb3                          // vfma.f32      d18, d16, d19
  .long  0xeddf3b0a                          // vldr          d19, [pc, #40]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3c3061f                          // vmov.i32      d16, #-1090519040
  .long  0xf2010da0                          // vadd.f32      d0, d17, d16
  .long  0xedc33b20                          // vstr          d19, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p1x_vfp4
.globl _sk_bicubic_p1x_vfp4
_sk_bicubic_p1x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c71f18                          // vmov.f32      d17, #1.5
  .long  0xeddf0b0c                          // vldr          d16, [pc, #48]
  .long  0xedd33b10                          // vldr          d19, [r3, #64]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedd32b00                          // vldr          d18, [r3]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xf2020da0                          // vadd.f32      d0, d18, d16
  .long  0xf2430cb1                          // vfma.f32      d16, d19, d17
  .long  0xeddf1b07                          // vldr          d17, [pc, #28]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedc31b20                          // vstr          d17, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p3x_vfp4
.globl _sk_bicubic_p3x_vfp4
_sk_bicubic_p3x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xeddf0b0d                          // vldr          d16, [pc, #52]
  .long  0xeddf3b0e                          // vldr          d19, [pc, #56]
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2423cb0                          // vfma.f32      d19, d18, d16
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf3420db2                          // vmul.f32      d16, d18, d18
  .long  0xf2c72f18                          // vmov.f32      d18, #1.5
  .long  0xf2010da2                          // vadd.f32      d0, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b20                          // vstr          d16, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab

HIDDEN _sk_bicubic_n3y_vfp4
.globl _sk_bicubic_n3y_vfp4
_sk_bicubic_n3y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0b                          // vldr          d18, [pc, #44]
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3400db0                          // vmul.f32      d16, d16, d16
  .long  0xf3c72f18                          // vmov.f32      d18, #-1.5
  .long  0xf2011da2                          // vadd.f32      d1, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b28                          // vstr          d16, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab

HIDDEN _sk_bicubic_n1y_vfp4
.globl _sk_bicubic_n1y_vfp4
_sk_bicubic_n1y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xf2c73f18                          // vmov.f32      d19, #1.5
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0d                          // vldr          d18, [pc, #52]
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2402cb3                          // vfma.f32      d18, d16, d19
  .long  0xeddf3b0a                          // vldr          d19, [pc, #40]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3c3061f                          // vmov.i32      d16, #-1090519040
  .long  0xf2011da0                          // vadd.f32      d1, d17, d16
  .long  0xedc33b28                          // vstr          d19, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p1y_vfp4
.globl _sk_bicubic_p1y_vfp4
_sk_bicubic_p1y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c71f18                          // vmov.f32      d17, #1.5
  .long  0xeddf0b0c                          // vldr          d16, [pc, #48]
  .long  0xedd33b18                          // vldr          d19, [r3, #96]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedd32b08                          // vldr          d18, [r3, #32]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xf2021da0                          // vadd.f32      d1, d18, d16
  .long  0xf2430cb1                          // vfma.f32      d16, d19, d17
  .long  0xeddf1b07                          // vldr          d17, [pc, #28]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedc31b28                          // vstr          d17, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p3y_vfp4
.globl _sk_bicubic_p3y_vfp4
_sk_bicubic_p3y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xeddf0b0d                          // vldr          d16, [pc, #52]
  .long  0xeddf3b0e                          // vldr          d19, [pc, #56]
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2423cb0                          // vfma.f32      d19, d18, d16
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf3420db2                          // vmul.f32      d16, d18, d18
  .long  0xf2c72f18                          // vmov.f32      d18, #1.5
  .long  0xf2011da2                          // vadd.f32      d1, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b28                          // vstr          d16, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
#elif defined(__x86_64__)

HIDDEN _sk_start_pipeline_hsw
.globl _sk_start_pipeline_hsw
_sk_start_pipeline_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,205                          // mov           %rcx,%r13
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,199                          // mov           %rax,%r15
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  72,141,67,8                         // lea           0x8(%rbx),%rax
  .byte  76,57,232                           // cmp           %r13,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_hsw+0x28>
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  235,65                              // jmp           69 <_sk_start_pipeline_hsw+0x69>
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  72,141,123,8                        // lea           0x8(%rbx),%rdi
  .byte  72,131,195,16                       // add           $0x10,%rbx
  .byte  76,57,235                           // cmp           %r13,%rbx
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  118,191                             // jbe           28 <_sk_start_pipeline_hsw+0x28>
  .byte  76,137,233                          // mov           %r13,%rcx
  .byte  72,41,249                           // sub           %rdi,%rcx
  .byte  116,41                              // je            9a <_sk_start_pipeline_hsw+0x9a>
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  76,137,232                          // mov           %r13,%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  197,248,119                         // vzeroupper
  .byte  195                                 // retq

HIDDEN _sk_just_return_hsw
.globl _sk_just_return_hsw
_sk_just_return_hsw:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_hsw
.globl _sk_seed_shader_hsw
_sk_seed_shader_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,249,110,199                     // vmovd         %edi,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  197,252,88,2                        // vaddps        (%rdx),%ymm0,%ymm0
  .byte  196,226,125,24,16                   // vbroadcastss  (%rax),%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,236,88,201                      // vaddps        %ymm1,%ymm2,%ymm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_hsw
.globl _sk_constant_color_hsw
_sk_constant_color_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  196,226,125,24,88,12                // vbroadcastss  0xc(%rax),%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_hsw
.globl _sk_clear_hsw
_sk_clear_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_hsw
.globl _sk_srcatop_hsw
_sk_srcatop_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,204                       // vmulps        %ymm4,%ymm8,%ymm9
  .byte  196,194,69,168,193                  // vfmadd213ps   %ymm9,%ymm7,%ymm0
  .byte  197,60,89,205                       // vmulps        %ymm5,%ymm8,%ymm9
  .byte  196,194,69,168,201                  // vfmadd213ps   %ymm9,%ymm7,%ymm1
  .byte  197,60,89,206                       // vmulps        %ymm6,%ymm8,%ymm9
  .byte  196,194,69,168,209                  // vfmadd213ps   %ymm9,%ymm7,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  196,194,69,168,216                  // vfmadd213ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_hsw
.globl _sk_dstatop_hsw
_sk_dstatop_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  196,226,101,184,196                 // vfmadd231ps   %ymm4,%ymm3,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  196,226,101,184,205                 // vfmadd231ps   %ymm5,%ymm3,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  196,226,101,184,214                 // vfmadd231ps   %ymm6,%ymm3,%ymm2
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,168,216                  // vfmadd213ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_hsw
.globl _sk_srcin_hsw
_sk_srcin_hsw:
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_hsw
.globl _sk_dstin_hsw
_sk_dstin_hsw:
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_hsw
.globl _sk_srcout_hsw
_sk_srcout_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_hsw
.globl _sk_dstout_hsw
_sk_dstout_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,92,219                      // vsubps        %ymm3,%ymm0,%ymm3
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_hsw
.globl _sk_srcover_hsw
_sk_srcover_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,93,184,192                  // vfmadd231ps   %ymm8,%ymm4,%ymm0
  .byte  196,194,85,184,200                  // vfmadd231ps   %ymm8,%ymm5,%ymm1
  .byte  196,194,77,184,208                  // vfmadd231ps   %ymm8,%ymm6,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_hsw
.globl _sk_dstover_hsw
_sk_dstover_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  196,226,61,168,196                  // vfmadd213ps   %ymm4,%ymm8,%ymm0
  .byte  196,226,61,168,205                  // vfmadd213ps   %ymm5,%ymm8,%ymm1
  .byte  196,226,61,168,214                  // vfmadd213ps   %ymm6,%ymm8,%ymm2
  .byte  196,226,61,168,223                  // vfmadd213ps   %ymm7,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_hsw
.globl _sk_modulate_hsw
_sk_modulate_hsw:
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_hsw
.globl _sk_multiply_hsw
_sk_multiply_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,212                       // vmulps        %ymm4,%ymm8,%ymm10
  .byte  196,98,53,184,208                   // vfmadd231ps   %ymm0,%ymm9,%ymm10
  .byte  196,194,93,168,194                  // vfmadd213ps   %ymm10,%ymm4,%ymm0
  .byte  197,52,89,209                       // vmulps        %ymm1,%ymm9,%ymm10
  .byte  196,98,61,184,213                   // vfmadd231ps   %ymm5,%ymm8,%ymm10
  .byte  196,194,85,168,202                  // vfmadd213ps   %ymm10,%ymm5,%ymm1
  .byte  197,52,89,210                       // vmulps        %ymm2,%ymm9,%ymm10
  .byte  196,98,61,184,214                   // vfmadd231ps   %ymm6,%ymm8,%ymm10
  .byte  196,194,77,168,210                  // vfmadd213ps   %ymm10,%ymm6,%ymm2
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  196,66,69,168,193                   // vfmadd213ps   %ymm9,%ymm7,%ymm8
  .byte  196,194,69,168,216                  // vfmadd213ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__hsw
.globl _sk_plus__hsw
_sk_plus__hsw:
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_hsw
.globl _sk_screen_hsw
_sk_screen_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  196,194,93,172,192                  // vfnmadd213ps  %ymm8,%ymm4,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  196,194,85,172,200                  // vfnmadd213ps  %ymm8,%ymm5,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  196,194,77,172,208                  // vfnmadd213ps  %ymm8,%ymm6,%ymm2
  .byte  197,100,88,199                      // vaddps        %ymm7,%ymm3,%ymm8
  .byte  196,194,69,172,216                  // vfnmadd213ps  %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__hsw
.globl _sk_xor__hsw
_sk_xor__hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,212                       // vmulps        %ymm4,%ymm8,%ymm10
  .byte  196,194,53,168,194                  // vfmadd213ps   %ymm10,%ymm9,%ymm0
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  196,226,61,184,205                  // vfmadd231ps   %ymm5,%ymm8,%ymm1
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  196,226,61,184,214                  // vfmadd231ps   %ymm6,%ymm8,%ymm2
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  196,98,69,168,195                   // vfmadd213ps   %ymm3,%ymm7,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,195                      // vmovaps       %ymm8,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_hsw
.globl _sk_darken_hsw
_sk_darken_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,95,193                  // vmaxps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,95,201                  // vmaxps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,95,209                  // vmaxps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_hsw
.globl _sk_lighten_hsw
_sk_lighten_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_hsw
.globl _sk_difference_hsw
_sk_difference_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_hsw
.globl _sk_exclusion_hsw
_sk_exclusion_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_hsw
.globl _sk_colorburn_hsw
_sk_colorburn_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,52,89,216                       // vmulps        %ymm0,%ymm9,%ymm11
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,228                       // vmulps        %ymm4,%ymm8,%ymm12
  .byte  197,68,92,236                       // vsubps        %ymm4,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,232                       // vdivps        %ymm0,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  196,66,101,168,235                  // vfmadd213ps   %ymm11,%ymm3,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,224                       // vaddps        %ymm0,%ymm12,%ymm12
  .byte  196,193,124,194,194,0               // vcmpeqps      %ymm10,%ymm0,%ymm0
  .byte  196,195,21,74,196,0                 // vblendvps     %ymm0,%ymm12,%ymm13,%ymm0
  .byte  197,92,194,231,0                    // vcmpeqps      %ymm7,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,52,89,217                       // vmulps        %ymm1,%ymm9,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  197,68,92,237                       // vsubps        %ymm5,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,233                       // vdivps        %ymm1,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  196,66,101,168,235                  // vfmadd213ps   %ymm11,%ymm3,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,225                       // vaddps        %ymm1,%ymm12,%ymm12
  .byte  196,193,116,194,202,0               // vcmpeqps      %ymm10,%ymm1,%ymm1
  .byte  196,195,21,74,204,16                // vblendvps     %ymm1,%ymm12,%ymm13,%ymm1
  .byte  197,84,194,231,0                    // vcmpeqps      %ymm7,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,52,89,202                       // vmulps        %ymm2,%ymm9,%ymm9
  .byte  196,65,108,194,210,0                // vcmpeqps      %ymm10,%ymm2,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  197,68,92,230                       // vsubps        %ymm6,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  197,28,94,226                       // vdivps        %ymm2,%ymm12,%ymm12
  .byte  197,164,88,210                      // vaddps        %ymm2,%ymm11,%ymm2
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,65,68,92,228                    // vsubps        %ymm12,%ymm7,%ymm12
  .byte  196,66,101,168,225                  // vfmadd213ps   %ymm9,%ymm3,%ymm12
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,227,37,74,210,160               // vblendvps     %ymm10,%ymm2,%ymm11,%ymm2
  .byte  197,76,194,215,0                    // vcmpeqps      %ymm7,%ymm6,%ymm10
  .byte  197,52,88,206                       // vaddps        %ymm6,%ymm9,%ymm9
  .byte  196,195,109,74,209,160              // vblendvps     %ymm10,%ymm9,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_hsw
.globl _sk_colordodge_hsw
_sk_colordodge_hsw:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  197,52,92,215                       // vsubps        %ymm7,%ymm9,%ymm10
  .byte  197,44,89,216                       // vmulps        %ymm0,%ymm10,%ymm11
  .byte  197,52,92,203                       // vsubps        %ymm3,%ymm9,%ymm9
  .byte  197,100,89,228                      // vmulps        %ymm4,%ymm3,%ymm12
  .byte  197,100,92,232                      // vsubps        %ymm0,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,236                       // vmulps        %ymm4,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,66,101,168,227                  // vfmadd213ps   %ymm11,%ymm3,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,232                       // vaddps        %ymm0,%ymm13,%ymm13
  .byte  197,252,194,195,0                   // vcmpeqps      %ymm3,%ymm0,%ymm0
  .byte  196,195,29,74,197,0                 // vblendvps     %ymm0,%ymm13,%ymm12,%ymm0
  .byte  196,65,92,194,224,0                 // vcmpeqps      %ymm8,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,100,89,229                      // vmulps        %ymm5,%ymm3,%ymm12
  .byte  197,100,92,233                      // vsubps        %ymm1,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,237                       // vmulps        %ymm5,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,66,101,168,227                  // vfmadd213ps   %ymm11,%ymm3,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,233                       // vaddps        %ymm1,%ymm13,%ymm13
  .byte  197,244,194,203,0                   // vcmpeqps      %ymm3,%ymm1,%ymm1
  .byte  196,195,29,74,205,16                // vblendvps     %ymm1,%ymm13,%ymm12,%ymm1
  .byte  196,65,84,194,224,0                 // vcmpeqps      %ymm8,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,100,89,222                      // vmulps        %ymm6,%ymm3,%ymm11
  .byte  197,100,92,226                      // vsubps        %ymm2,%ymm3,%ymm12
  .byte  196,65,36,94,220                    // vdivps        %ymm12,%ymm11,%ymm11
  .byte  197,52,89,230                       // vmulps        %ymm6,%ymm9,%ymm12
  .byte  196,65,68,93,219                    // vminps        %ymm11,%ymm7,%ymm11
  .byte  196,66,101,168,218                  // vfmadd213ps   %ymm10,%ymm3,%ymm11
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,28,88,226                       // vaddps        %ymm2,%ymm12,%ymm12
  .byte  197,236,194,211,0                   // vcmpeqps      %ymm3,%ymm2,%ymm2
  .byte  196,195,37,74,212,32                // vblendvps     %ymm2,%ymm12,%ymm11,%ymm2
  .byte  196,65,76,194,192,0                 // vcmpeqps      %ymm8,%ymm6,%ymm8
  .byte  197,44,88,214                       // vaddps        %ymm6,%ymm10,%ymm10
  .byte  196,195,109,74,210,128              // vblendvps     %ymm8,%ymm10,%ymm2,%ymm2
  .byte  196,194,69,184,217                  // vfmadd231ps   %ymm9,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_hsw
.globl _sk_hardlight_hsw
_sk_hardlight_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,98,45,184,216                   // vfmadd231ps   %ymm0,%ymm10,%ymm11
  .byte  197,124,88,200                      // vaddps        %ymm0,%ymm0,%ymm9
  .byte  197,52,194,227,2                    // vcmpleps      %ymm3,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  196,98,61,184,221                   // vfmadd231ps   %ymm5,%ymm8,%ymm11
  .byte  197,116,88,225                      // vaddps        %ymm1,%ymm1,%ymm12
  .byte  197,28,194,227,2                    // vcmpleps      %ymm3,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,98,61,184,214                   // vfmadd231ps   %ymm6,%ymm8,%ymm10
  .byte  197,108,88,218                      // vaddps        %ymm2,%ymm2,%ymm11
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_hsw
.globl _sk_overlay_hsw
_sk_overlay_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,98,45,184,216                   // vfmadd231ps   %ymm0,%ymm10,%ymm11
  .byte  197,92,88,204                       // vaddps        %ymm4,%ymm4,%ymm9
  .byte  197,52,194,231,2                    // vcmpleps      %ymm7,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  196,98,61,184,221                   // vfmadd231ps   %ymm5,%ymm8,%ymm11
  .byte  197,84,88,229                       // vaddps        %ymm5,%ymm5,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,98,61,184,214                   // vfmadd231ps   %ymm6,%ymm8,%ymm10
  .byte  197,76,88,222                       // vaddps        %ymm6,%ymm6,%ymm11
  .byte  197,36,194,223,2                    // vcmpleps      %ymm7,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_hsw
.globl _sk_softlight_hsw
_sk_softlight_hsw:
  .byte  197,252,17,84,36,200                // vmovups       %ymm2,-0x38(%rsp)
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  197,44,194,223,1                    // vcmpltps      %ymm7,%ymm10,%ymm11
  .byte  197,92,94,199                       // vdivps        %ymm7,%ymm4,%ymm8
  .byte  196,67,45,74,224,176                // vblendvps     %ymm11,%ymm8,%ymm10,%ymm12
  .byte  196,65,28,88,196                    // vaddps        %ymm12,%ymm12,%ymm8
  .byte  196,65,60,88,232                    // vaddps        %ymm8,%ymm8,%ymm13
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,66,21,168,237                   // vfmadd213ps   %ymm13,%ymm13,%ymm13
  .byte  196,65,28,92,240                    // vsubps        %ymm8,%ymm12,%ymm14
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,28,89,249                    // vmulps        %ymm9,%ymm12,%ymm15
  .byte  196,66,21,184,254                   // vfmadd231ps   %ymm14,%ymm13,%ymm15
  .byte  196,65,124,82,236                   // vrsqrtps      %ymm12,%ymm13
  .byte  196,65,124,83,237                   // vrcpps        %ymm13,%ymm13
  .byte  196,65,20,92,236                    // vsubps        %ymm12,%ymm13,%ymm13
  .byte  197,92,88,244                       // vaddps        %ymm4,%ymm4,%ymm14
  .byte  196,65,12,88,246                    // vaddps        %ymm14,%ymm14,%ymm14
  .byte  197,12,194,247,2                    // vcmpleps      %ymm7,%ymm14,%ymm14
  .byte  196,67,21,74,239,224                // vblendvps     %ymm14,%ymm15,%ymm13,%ymm13
  .byte  197,124,88,240                      // vaddps        %ymm0,%ymm0,%ymm14
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,65,60,92,228                    // vsubps        %ymm12,%ymm8,%ymm12
  .byte  196,98,5,168,227                    // vfmadd213ps   %ymm3,%ymm15,%ymm12
  .byte  197,28,89,228                       // vmulps        %ymm4,%ymm12,%ymm12
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,237                     // vmulps        %ymm13,%ymm15,%ymm13
  .byte  196,98,101,184,236                  // vfmadd231ps   %ymm4,%ymm3,%ymm13
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,195,21,74,212,224               // vblendvps     %ymm14,%ymm12,%ymm13,%ymm2
  .byte  197,84,94,239                       // vdivps        %ymm7,%ymm5,%ymm13
  .byte  196,67,45,74,237,176                // vblendvps     %ymm11,%ymm13,%ymm10,%ymm13
  .byte  196,65,20,88,245                    // vaddps        %ymm13,%ymm13,%ymm14
  .byte  196,65,12,88,246                    // vaddps        %ymm14,%ymm14,%ymm14
  .byte  196,66,13,168,246                   // vfmadd213ps   %ymm14,%ymm14,%ymm14
  .byte  196,65,20,92,248                    // vsubps        %ymm8,%ymm13,%ymm15
  .byte  196,65,4,89,246                     // vmulps        %ymm14,%ymm15,%ymm14
  .byte  196,66,53,184,245                   // vfmadd231ps   %ymm13,%ymm9,%ymm14
  .byte  196,65,124,82,253                   // vrsqrtps      %ymm13,%ymm15
  .byte  196,65,124,83,255                   // vrcpps        %ymm15,%ymm15
  .byte  196,65,4,92,253                     // vsubps        %ymm13,%ymm15,%ymm15
  .byte  197,84,88,229                       // vaddps        %ymm5,%ymm5,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  196,67,5,74,230,192                 // vblendvps     %ymm12,%ymm14,%ymm15,%ymm12
  .byte  197,116,88,241                      // vaddps        %ymm1,%ymm1,%ymm14
  .byte  196,65,60,92,237                    // vsubps        %ymm13,%ymm8,%ymm13
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,98,5,168,235                    // vfmadd213ps   %ymm3,%ymm15,%ymm13
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,228                     // vmulps        %ymm12,%ymm15,%ymm12
  .byte  197,20,89,237                       // vmulps        %ymm5,%ymm13,%ymm13
  .byte  196,98,101,184,229                  // vfmadd231ps   %ymm5,%ymm3,%ymm12
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,67,29,74,237,224                // vblendvps     %ymm14,%ymm13,%ymm12,%ymm13
  .byte  197,76,94,231                       // vdivps        %ymm7,%ymm6,%ymm12
  .byte  196,67,45,74,212,176                // vblendvps     %ymm11,%ymm12,%ymm10,%ymm10
  .byte  196,65,44,88,218                    // vaddps        %ymm10,%ymm10,%ymm11
  .byte  196,65,36,88,219                    // vaddps        %ymm11,%ymm11,%ymm11
  .byte  196,66,37,168,219                   // vfmadd213ps   %ymm11,%ymm11,%ymm11
  .byte  196,65,44,92,224                    // vsubps        %ymm8,%ymm10,%ymm12
  .byte  196,65,28,89,219                    // vmulps        %ymm11,%ymm12,%ymm11
  .byte  196,66,45,168,203                   // vfmadd213ps   %ymm11,%ymm10,%ymm9
  .byte  196,65,124,82,218                   // vrsqrtps      %ymm10,%ymm11
  .byte  196,65,124,83,219                   // vrcpps        %ymm11,%ymm11
  .byte  196,65,36,92,218                    // vsubps        %ymm10,%ymm11,%ymm11
  .byte  197,76,88,230                       // vaddps        %ymm6,%ymm6,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  196,67,37,74,201,192                // vblendvps     %ymm12,%ymm9,%ymm11,%ymm9
  .byte  197,124,16,116,36,200               // vmovups       -0x38(%rsp),%ymm14
  .byte  196,65,12,88,222                    // vaddps        %ymm14,%ymm14,%ymm11
  .byte  197,36,92,227                       // vsubps        %ymm3,%ymm11,%ymm12
  .byte  196,65,60,92,210                    // vsubps        %ymm10,%ymm8,%ymm10
  .byte  196,98,29,168,211                   // vfmadd213ps   %ymm3,%ymm12,%ymm10
  .byte  197,28,89,231                       // vmulps        %ymm7,%ymm12,%ymm12
  .byte  196,65,28,89,201                    // vmulps        %ymm9,%ymm12,%ymm9
  .byte  197,44,89,214                       // vmulps        %ymm6,%ymm10,%ymm10
  .byte  196,98,101,184,206                  // vfmadd231ps   %ymm6,%ymm3,%ymm9
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  196,67,53,74,202,176                // vblendvps     %ymm11,%ymm10,%ymm9,%ymm9
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,98,45,184,216                   // vfmadd231ps   %ymm0,%ymm10,%ymm11
  .byte  196,193,108,88,195                  // vaddps        %ymm11,%ymm2,%ymm0
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,226,61,184,205                  // vfmadd231ps   %ymm5,%ymm8,%ymm1
  .byte  196,193,116,88,205                  // vaddps        %ymm13,%ymm1,%ymm1
  .byte  196,193,44,89,214                   // vmulps        %ymm14,%ymm10,%ymm2
  .byte  196,226,61,184,214                  // vfmadd231ps   %ymm6,%ymm8,%ymm2
  .byte  196,193,108,88,209                  // vaddps        %ymm9,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_hsw
.globl _sk_clamp_0_hsw
_sk_clamp_0_hsw:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,95,216                  // vmaxps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_hsw
.globl _sk_clamp_1_hsw
_sk_clamp_1_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,93,208                  // vminps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_hsw
.globl _sk_clamp_a_hsw
_sk_clamp_a_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  197,252,93,195                      // vminps        %ymm3,%ymm0,%ymm0
  .byte  197,244,93,203                      // vminps        %ymm3,%ymm1,%ymm1
  .byte  197,236,93,211                      // vminps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_hsw
.globl _sk_set_rgb_hsw
_sk_set_rgb_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_hsw
.globl _sk_swap_rb_hsw
_sk_swap_rb_hsw:
  .byte  197,124,40,192                      // vmovaps       %ymm0,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,194                      // vmovaps       %ymm2,%ymm0
  .byte  197,124,41,194                      // vmovaps       %ymm8,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_hsw
.globl _sk_swap_hsw
_sk_swap_hsw:
  .byte  197,124,40,195                      // vmovaps       %ymm3,%ymm8
  .byte  197,124,40,202                      // vmovaps       %ymm2,%ymm9
  .byte  197,124,40,209                      // vmovaps       %ymm1,%ymm10
  .byte  197,124,40,216                      // vmovaps       %ymm0,%ymm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  197,124,41,220                      // vmovaps       %ymm11,%ymm4
  .byte  197,124,41,213                      // vmovaps       %ymm10,%ymm5
  .byte  197,124,41,206                      // vmovaps       %ymm9,%ymm6
  .byte  197,124,41,199                      // vmovaps       %ymm8,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_hsw
.globl _sk_move_src_dst_hsw
_sk_move_src_dst_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,224                      // vmovaps       %ymm0,%ymm4
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  197,252,40,242                      // vmovaps       %ymm2,%ymm6
  .byte  197,252,40,251                      // vmovaps       %ymm3,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_hsw
.globl _sk_move_dst_src_hsw
_sk_move_dst_src_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_hsw
.globl _sk_premul_hsw
_sk_premul_hsw:
  .byte  197,252,89,195                      // vmulps        %ymm3,%ymm0,%ymm0
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_hsw
.globl _sk_unpremul_hsw
_sk_unpremul_hsw:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,100,194,200,0                // vcmpeqps      %ymm8,%ymm3,%ymm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  197,44,94,211                       // vdivps        %ymm3,%ymm10,%ymm10
  .byte  196,67,45,74,192,144                // vblendvps     %ymm9,%ymm8,%ymm10,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_hsw
.globl _sk_from_srgb_hsw
_sk_from_srgb_hsw:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  197,124,89,208                      // vmulps        %ymm0,%ymm0,%ymm10
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,66,125,88,228                   // vpbroadcastd  %xmm12,%ymm12
  .byte  196,65,125,111,235                  // vmovdqa       %ymm11,%ymm13
  .byte  196,66,125,168,236                  // vfmadd213ps   %ymm12,%ymm0,%ymm13
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,66,125,88,246                   // vpbroadcastd  %xmm14,%ymm14
  .byte  196,66,45,168,238                   // vfmadd213ps   %ymm14,%ymm10,%ymm13
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,193,124,194,194,1               // vcmpltps      %ymm10,%ymm0,%ymm0
  .byte  196,195,21,74,193,0                 // vblendvps     %ymm0,%ymm9,%ymm13,%ymm0
  .byte  197,60,89,201                       // vmulps        %ymm1,%ymm8,%ymm9
  .byte  197,116,89,233                      // vmulps        %ymm1,%ymm1,%ymm13
  .byte  196,65,125,111,251                  // vmovdqa       %ymm11,%ymm15
  .byte  196,66,117,168,252                  // vfmadd213ps   %ymm12,%ymm1,%ymm15
  .byte  196,66,21,168,254                   // vfmadd213ps   %ymm14,%ymm13,%ymm15
  .byte  196,193,116,194,202,1               // vcmpltps      %ymm10,%ymm1,%ymm1
  .byte  196,195,5,74,201,16                 // vblendvps     %ymm1,%ymm9,%ymm15,%ymm1
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  197,108,89,202                      // vmulps        %ymm2,%ymm2,%ymm9
  .byte  196,66,109,168,220                  // vfmadd213ps   %ymm12,%ymm2,%ymm11
  .byte  196,66,53,168,222                   // vfmadd213ps   %ymm14,%ymm9,%ymm11
  .byte  196,193,108,194,210,1               // vcmpltps      %ymm10,%ymm2,%ymm2
  .byte  196,195,37,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm11,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_hsw
.globl _sk_to_srgb_hsw
_sk_to_srgb_hsw:
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,83,216                   // vrcpps        %ymm8,%ymm11
  .byte  196,65,124,82,224                   // vrsqrtps      %ymm8,%ymm12
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,232                       // vmulps        %ymm0,%ymm8,%ymm13
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,66,125,88,246                   // vpbroadcastd  %xmm14,%ymm14
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  197,121,110,248                     // vmovd         %eax,%xmm15
  .byte  196,66,125,88,255                   // vpbroadcastd  %xmm15,%ymm15
  .byte  196,66,13,168,223                   // vfmadd213ps   %ymm15,%ymm14,%ymm11
  .byte  196,66,45,184,220                   // vfmadd231ps   %ymm12,%ymm10,%ymm11
  .byte  196,65,52,93,219                    // vminps        %ymm11,%ymm9,%ymm11
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,66,125,88,228                   // vpbroadcastd  %xmm12,%ymm12
  .byte  196,193,124,194,196,1               // vcmpltps      %ymm12,%ymm0,%ymm0
  .byte  196,195,37,74,197,0                 // vblendvps     %ymm0,%ymm13,%ymm11,%ymm0
  .byte  197,124,82,217                      // vrsqrtps      %ymm1,%ymm11
  .byte  196,65,124,83,235                   // vrcpps        %ymm11,%ymm13
  .byte  196,65,124,82,219                   // vrsqrtps      %ymm11,%ymm11
  .byte  196,66,13,168,239                   // vfmadd213ps   %ymm15,%ymm14,%ymm13
  .byte  196,66,45,184,235                   // vfmadd231ps   %ymm11,%ymm10,%ymm13
  .byte  197,60,89,217                       // vmulps        %ymm1,%ymm8,%ymm11
  .byte  196,65,52,93,237                    // vminps        %ymm13,%ymm9,%ymm13
  .byte  196,193,116,194,204,1               // vcmpltps      %ymm12,%ymm1,%ymm1
  .byte  196,195,21,74,203,16                // vblendvps     %ymm1,%ymm11,%ymm13,%ymm1
  .byte  197,124,82,218                      // vrsqrtps      %ymm2,%ymm11
  .byte  196,65,124,83,235                   // vrcpps        %ymm11,%ymm13
  .byte  196,66,13,168,239                   // vfmadd213ps   %ymm15,%ymm14,%ymm13
  .byte  196,65,124,82,219                   // vrsqrtps      %ymm11,%ymm11
  .byte  196,66,45,184,235                   // vfmadd231ps   %ymm11,%ymm10,%ymm13
  .byte  196,65,52,93,205                    // vminps        %ymm13,%ymm9,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,193,108,194,212,1               // vcmpltps      %ymm12,%ymm2,%ymm2
  .byte  196,195,53,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_2dot2_hsw
.globl _sk_from_2dot2_hsw
_sk_from_2dot2_hsw:
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,200                   // vrsqrtps      %ymm8,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  197,252,89,192                      // vmulps        %ymm0,%ymm0,%ymm0
  .byte  196,65,60,89,208                    // vmulps        %ymm8,%ymm8,%ymm10
  .byte  196,65,60,89,194                    // vmulps        %ymm10,%ymm8,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  197,124,82,201                      // vrsqrtps      %ymm1,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  196,65,124,82,210                   // vrsqrtps      %ymm10,%ymm10
  .byte  197,244,89,201                      // vmulps        %ymm1,%ymm1,%ymm1
  .byte  196,65,52,89,217                    // vmulps        %ymm9,%ymm9,%ymm11
  .byte  196,65,52,89,203                    // vmulps        %ymm11,%ymm9,%ymm9
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  197,124,82,202                      // vrsqrtps      %ymm2,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  196,65,124,82,210                   // vrsqrtps      %ymm10,%ymm10
  .byte  197,236,89,210                      // vmulps        %ymm2,%ymm2,%ymm2
  .byte  196,65,52,89,217                    // vmulps        %ymm9,%ymm9,%ymm11
  .byte  196,65,52,89,203                    // vmulps        %ymm11,%ymm9,%ymm9
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_2dot2_hsw
.globl _sk_to_2dot2_hsw
_sk_to_2dot2_hsw:
  .byte  197,252,82,192                      // vrsqrtps      %ymm0,%ymm0
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,200                   // vrsqrtps      %ymm8,%ymm9
  .byte  197,252,83,192                      // vrcpps        %ymm0,%ymm0
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  196,65,124,83,193                   // vrcpps        %ymm9,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  197,252,82,201                      // vrsqrtps      %ymm1,%ymm1
  .byte  197,124,82,201                      // vrsqrtps      %ymm1,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  197,252,83,201                      // vrcpps        %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  196,65,124,83,202                   // vrcpps        %ymm10,%ymm9
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  197,252,82,210                      // vrsqrtps      %ymm2,%ymm2
  .byte  197,124,82,202                      // vrsqrtps      %ymm2,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  197,252,83,210                      // vrcpps        %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  196,65,124,83,202                   // vrcpps        %ymm10,%ymm9
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_hsw
.globl _sk_rgb_to_hsl_hsw
_sk_rgb_to_hsl_hsw:
  .byte  197,252,17,124,36,200               // vmovups       %ymm7,-0x38(%rsp)
  .byte  197,252,40,254                      // vmovaps       %ymm6,%ymm7
  .byte  197,252,40,245                      // vmovaps       %ymm5,%ymm6
  .byte  197,252,40,236                      // vmovaps       %ymm4,%ymm5
  .byte  197,252,40,227                      // vmovaps       %ymm3,%ymm4
  .byte  197,252,40,216                      // vmovaps       %ymm0,%ymm3
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  184,0,0,192,64                      // mov           $0x40c00000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  65,185,0,0,0,64                     // mov           $0x40000000,%r9d
  .byte  184,0,0,128,64                      // mov           $0x40800000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  197,100,95,217                      // vmaxps        %ymm1,%ymm3,%ymm11
  .byte  197,36,95,218                       // vmaxps        %ymm2,%ymm11,%ymm11
  .byte  197,100,93,225                      // vminps        %ymm1,%ymm3,%ymm12
  .byte  197,28,93,226                       // vminps        %ymm2,%ymm12,%ymm12
  .byte  196,65,36,92,236                    // vsubps        %ymm12,%ymm11,%ymm13
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,60,94,197                    // vdivps        %ymm13,%ymm8,%ymm8
  .byte  197,116,194,242,1                   // vcmpltps      %ymm2,%ymm1,%ymm14
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,4,87,255                     // vxorps        %ymm15,%ymm15,%ymm15
  .byte  196,67,5,74,201,224                 // vblendvps     %ymm14,%ymm9,%ymm15,%ymm9
  .byte  197,116,92,242                      // vsubps        %ymm2,%ymm1,%ymm14
  .byte  196,66,61,168,241                   // vfmadd213ps   %ymm9,%ymm8,%ymm14
  .byte  197,236,92,195                      // vsubps        %ymm3,%ymm2,%ymm0
  .byte  197,100,92,201                      // vsubps        %ymm1,%ymm3,%ymm9
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,168,202                   // vfmadd213ps   %ymm10,%ymm8,%ymm9
  .byte  196,193,121,110,209                 // vmovd         %r9d,%xmm2
  .byte  196,98,125,88,210                   // vpbroadcastd  %xmm2,%ymm10
  .byte  196,194,61,168,194                  // vfmadd213ps   %ymm10,%ymm8,%ymm0
  .byte  197,164,194,201,0                   // vcmpeqps      %ymm1,%ymm11,%ymm1
  .byte  196,227,53,74,192,16                // vblendvps     %ymm1,%ymm0,%ymm9,%ymm0
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,164,194,211,0                   // vcmpeqps      %ymm3,%ymm11,%ymm2
  .byte  196,195,125,74,198,32               // vblendvps     %ymm2,%ymm14,%ymm0,%ymm0
  .byte  196,193,36,88,220                   // vaddps        %ymm12,%ymm11,%ymm3
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,228,89,209                      // vmulps        %ymm1,%ymm3,%ymm2
  .byte  197,244,194,202,1                   // vcmpltps      %ymm2,%ymm1,%ymm1
  .byte  196,65,44,92,195                    // vsubps        %ymm11,%ymm10,%ymm8
  .byte  196,65,60,92,196                    // vsubps        %ymm12,%ymm8,%ymm8
  .byte  196,195,101,74,200,16               // vblendvps     %ymm1,%ymm8,%ymm3,%ymm1
  .byte  196,193,36,194,220,0                // vcmpeqps      %ymm12,%ymm11,%ymm3
  .byte  197,148,94,201                      // vdivps        %ymm1,%ymm13,%ymm1
  .byte  196,195,125,74,199,48               // vblendvps     %ymm3,%ymm15,%ymm0,%ymm0
  .byte  196,195,117,74,207,48               // vblendvps     %ymm3,%ymm15,%ymm1,%ymm1
  .byte  196,193,121,110,216                 // vmovd         %r8d,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,228,89,192                      // vmulps        %ymm0,%ymm3,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,220                      // vmovaps       %ymm4,%ymm3
  .byte  197,252,40,229                      // vmovaps       %ymm5,%ymm4
  .byte  197,252,40,238                      // vmovaps       %ymm6,%ymm5
  .byte  197,252,40,247                      // vmovaps       %ymm7,%ymm6
  .byte  197,252,16,124,36,200               // vmovups       -0x38(%rsp),%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_hsw
.globl _sk_hsl_to_rgb_hsw
_sk_hsl_to_rgb_hsw:
  .byte  72,131,236,56                       // sub           $0x38,%rsp
  .byte  197,252,17,60,36                    // vmovups       %ymm7,(%rsp)
  .byte  197,252,17,116,36,224               // vmovups       %ymm6,-0x20(%rsp)
  .byte  197,252,17,108,36,192               // vmovups       %ymm5,-0x40(%rsp)
  .byte  197,252,17,100,36,160               // vmovups       %ymm4,-0x60(%rsp)
  .byte  197,252,17,92,36,128                // vmovups       %ymm3,-0x80(%rsp)
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,108,194,200,1               // vcmpltps      %ymm8,%ymm2,%ymm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,224                     // vmovd         %eax,%xmm4
  .byte  196,98,125,88,212                   // vpbroadcastd  %xmm4,%ymm10
  .byte  197,172,88,229                      // vaddps        %ymm5,%ymm10,%ymm4
  .byte  197,220,89,226                      // vmulps        %ymm2,%ymm4,%ymm4
  .byte  197,84,88,202                       // vaddps        %ymm2,%ymm5,%ymm9
  .byte  196,98,85,188,202                   // vfnmadd231ps  %ymm2,%ymm5,%ymm9
  .byte  196,99,53,74,204,16                 // vblendvps     %ymm1,%ymm4,%ymm9,%ymm9
  .byte  65,184,0,0,0,64                     // mov           $0x40000000,%r8d
  .byte  184,171,170,170,62                  // mov           $0x3eaaaaab,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,233                   // vpbroadcastd  %xmm1,%ymm13
  .byte  197,148,88,224                      // vaddps        %ymm0,%ymm13,%ymm4
  .byte  184,0,0,0,0                         // mov           $0x0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,225                   // vpbroadcastd  %xmm1,%ymm12
  .byte  197,172,194,204,1                   // vcmpltps      %ymm4,%ymm10,%ymm1
  .byte  196,65,92,92,218                    // vsubps        %ymm10,%ymm4,%ymm11
  .byte  196,195,93,74,203,16                // vblendvps     %ymm1,%ymm11,%ymm4,%ymm1
  .byte  196,65,92,194,220,1                 // vcmpltps      %ymm12,%ymm4,%ymm11
  .byte  197,44,88,244                       // vaddps        %ymm4,%ymm10,%ymm14
  .byte  196,195,117,74,206,176              // vblendvps     %ymm11,%ymm14,%ymm1,%ymm1
  .byte  196,193,121,110,216                 // vmovd         %r8d,%xmm3
  .byte  196,98,125,88,219                   // vpbroadcastd  %xmm3,%ymm11
  .byte  196,66,109,170,217                  // vfmsub213ps   %ymm9,%ymm2,%ymm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  184,0,0,192,64                      // mov           $0x40c00000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,65,52,92,243                    // vsubps        %ymm11,%ymm9,%ymm14
  .byte  197,12,89,243                       // vmulps        %ymm3,%ymm14,%ymm14
  .byte  184,171,170,42,63                   // mov           $0x3f2aaaab,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,98,125,88,251                   // vpbroadcastd  %xmm3,%ymm15
  .byte  197,132,92,217                      // vsubps        %ymm1,%ymm15,%ymm3
  .byte  196,194,13,168,219                  // vfmadd213ps   %ymm11,%ymm14,%ymm3
  .byte  196,193,116,194,255,1               // vcmpltps      %ymm15,%ymm1,%ymm7
  .byte  196,227,37,74,219,112               // vblendvps     %ymm7,%ymm3,%ymm11,%ymm3
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,101,74,249,112              // vblendvps     %ymm7,%ymm9,%ymm3,%ymm7
  .byte  196,193,121,110,216                 // vmovd         %r8d,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,244,194,203,1                   // vcmpltps      %ymm3,%ymm1,%ymm1
  .byte  196,194,13,168,227                  // vfmadd213ps   %ymm11,%ymm14,%ymm4
  .byte  196,227,69,74,228,16                // vblendvps     %ymm1,%ymm4,%ymm7,%ymm4
  .byte  197,172,194,200,1                   // vcmpltps      %ymm0,%ymm10,%ymm1
  .byte  196,193,124,92,250                  // vsubps        %ymm10,%ymm0,%ymm7
  .byte  196,227,125,74,207,16               // vblendvps     %ymm1,%ymm7,%ymm0,%ymm1
  .byte  196,193,124,194,252,1               // vcmpltps      %ymm12,%ymm0,%ymm7
  .byte  197,172,88,240                      // vaddps        %ymm0,%ymm10,%ymm6
  .byte  196,227,117,74,206,112              // vblendvps     %ymm7,%ymm6,%ymm1,%ymm1
  .byte  197,132,92,241                      // vsubps        %ymm1,%ymm15,%ymm6
  .byte  196,194,13,168,243                  // vfmadd213ps   %ymm11,%ymm14,%ymm6
  .byte  196,193,116,194,255,1               // vcmpltps      %ymm15,%ymm1,%ymm7
  .byte  196,227,37,74,246,112               // vblendvps     %ymm7,%ymm6,%ymm11,%ymm6
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,77,74,241,112               // vblendvps     %ymm7,%ymm9,%ymm6,%ymm6
  .byte  197,244,194,203,1                   // vcmpltps      %ymm3,%ymm1,%ymm1
  .byte  196,193,124,92,253                  // vsubps        %ymm13,%ymm0,%ymm7
  .byte  196,194,13,168,195                  // vfmadd213ps   %ymm11,%ymm14,%ymm0
  .byte  196,227,77,74,200,16                // vblendvps     %ymm1,%ymm0,%ymm6,%ymm1
  .byte  197,172,194,199,1                   // vcmpltps      %ymm7,%ymm10,%ymm0
  .byte  196,193,68,92,242                   // vsubps        %ymm10,%ymm7,%ymm6
  .byte  196,227,69,74,198,0                 // vblendvps     %ymm0,%ymm6,%ymm7,%ymm0
  .byte  196,193,68,194,244,1                // vcmpltps      %ymm12,%ymm7,%ymm6
  .byte  197,44,88,215                       // vaddps        %ymm7,%ymm10,%ymm10
  .byte  196,195,125,74,194,96               // vblendvps     %ymm6,%ymm10,%ymm0,%ymm0
  .byte  196,194,13,168,251                  // vfmadd213ps   %ymm11,%ymm14,%ymm7
  .byte  197,132,92,240                      // vsubps        %ymm0,%ymm15,%ymm6
  .byte  196,194,13,168,243                  // vfmadd213ps   %ymm11,%ymm14,%ymm6
  .byte  196,65,124,194,215,1                // vcmpltps      %ymm15,%ymm0,%ymm10
  .byte  196,227,37,74,246,160               // vblendvps     %ymm10,%ymm6,%ymm11,%ymm6
  .byte  196,65,124,194,192,1                // vcmpltps      %ymm8,%ymm0,%ymm8
  .byte  196,195,77,74,241,128               // vblendvps     %ymm8,%ymm9,%ymm6,%ymm6
  .byte  197,252,194,195,1                   // vcmpltps      %ymm3,%ymm0,%ymm0
  .byte  196,227,77,74,223,0                 // vblendvps     %ymm0,%ymm7,%ymm6,%ymm3
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,212,194,232,0                   // vcmpeqps      %ymm0,%ymm5,%ymm5
  .byte  196,227,93,74,194,80                // vblendvps     %ymm5,%ymm2,%ymm4,%ymm0
  .byte  196,227,117,74,202,80               // vblendvps     %ymm5,%ymm2,%ymm1,%ymm1
  .byte  196,227,101,74,210,80               // vblendvps     %ymm5,%ymm2,%ymm3,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,16,92,36,128                // vmovups       -0x80(%rsp),%ymm3
  .byte  197,252,16,100,36,160               // vmovups       -0x60(%rsp),%ymm4
  .byte  197,252,16,108,36,192               // vmovups       -0x40(%rsp),%ymm5
  .byte  197,252,16,116,36,224               // vmovups       -0x20(%rsp),%ymm6
  .byte  197,252,16,60,36                    // vmovups       (%rsp),%ymm7
  .byte  72,131,196,56                       // add           $0x38,%rsp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_hsw
.globl _sk_scale_1_float_hsw
_sk_scale_1_float_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_hsw
.globl _sk_scale_u8_hsw
_sk_scale_u8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,56                              // jne           11bc <_sk_scale_u8_hsw+0x48>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,125,49,192                   // vpmovzxbd     %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           11c4 <_sk_scale_u8_hsw+0x50>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  235,167                             // jmp           1188 <_sk_scale_u8_hsw+0x14>

HIDDEN _sk_lerp_1_float_hsw
.globl _sk_lerp_1_float_hsw
_sk_lerp_1_float_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,226,61,168,196                  // vfmadd213ps   %ymm4,%ymm8,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,226,61,168,205                  // vfmadd213ps   %ymm5,%ymm8,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,226,61,168,214                  // vfmadd213ps   %ymm6,%ymm8,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,226,61,168,223                  // vfmadd213ps   %ymm7,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_hsw
.globl _sk_lerp_u8_hsw
_sk_lerp_u8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,76                              // jne           126c <_sk_lerp_u8_hsw+0x5c>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,125,49,192                   // vpmovzxbd     %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,226,61,168,196                  // vfmadd213ps   %ymm4,%ymm8,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,226,61,168,205                  // vfmadd213ps   %ymm5,%ymm8,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,226,61,168,214                  // vfmadd213ps   %ymm6,%ymm8,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,226,61,168,223                  // vfmadd213ps   %ymm7,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           1274 <_sk_lerp_u8_hsw+0x64>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  235,147                             // jmp           1224 <_sk_lerp_u8_hsw+0x14>

HIDDEN _sk_lerp_565_hsw
.globl _sk_lerp_565_hsw
_sk_lerp_565_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,179,0,0,0                    // jne           1352 <_sk_lerp_565_hsw+0xc1>
  .byte  196,193,122,111,28,122              // vmovdqu       (%r10,%rdi,2),%xmm3
  .byte  196,98,125,51,195                   // vpmovzxwd     %xmm3,%ymm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,216                 // vpand         %ymm8,%ymm3,%ymm3
  .byte  197,124,91,203                      // vcvtdq2ps     %ymm3,%ymm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,216                 // vpand         %ymm8,%ymm3,%ymm3
  .byte  197,124,91,211                      // vcvtdq2ps     %ymm3,%ymm10
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,44,89,211                       // vmulps        %ymm3,%ymm10,%ymm10
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,216                 // vpand         %ymm8,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,226,53,168,196                  // vfmadd213ps   %ymm4,%ymm9,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,226,45,168,205                  // vfmadd213ps   %ymm5,%ymm10,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,226,101,168,214                 // vfmadd213ps   %ymm6,%ymm3,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,59,255,255,255               // ja            12a5 <_sk_lerp_565_hsw+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,75,0,0,0                  // lea           0x4b(%rip),%r9        # 13c0 <_sk_lerp_565_hsw+0x12f>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  196,193,97,196,92,122,12,6          // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,10,5          // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,8,4           // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,6,3           // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,4,2           // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,2,1           // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,28,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm3,%xmm3
  .byte  233,231,254,255,255                 // jmpq          12a5 <_sk_lerp_565_hsw+0x14>
  .byte  102,144                             // xchg          %ax,%ax
  .byte  242,255                             // repnz         (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  234                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,226                             // jmpq          *%rdx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  218,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,210                             // callq         *%rdx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,202                             // dec           %edx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  190                                 // .byte         0xbe
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_tables_hsw
.globl _sk_load_tables_hsw
_sk_load_tables_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,3,8                              // add           (%rax),%r9
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,121                             // jne           146a <_sk_load_tables_hsw+0x8e>
  .byte  196,193,126,111,25                  // vmovdqu       (%r9),%ymm3
  .byte  185,255,0,0,0                       // mov           $0xff,%ecx
  .byte  197,249,110,193                     // vmovd         %ecx,%xmm0
  .byte  196,226,125,88,208                  // vpbroadcastd  %xmm0,%ymm2
  .byte  197,237,219,203                     // vpand         %ymm3,%ymm2,%ymm1
  .byte  196,65,61,118,192                   // vpcmpeqd      %ymm8,%ymm8,%ymm8
  .byte  72,139,72,8                         // mov           0x8(%rax),%rcx
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,226,53,146,4,137                // vgatherdps    %ymm9,(%rcx,%ymm1,4),%ymm0
  .byte  197,245,114,211,8                   // vpsrld        $0x8,%ymm3,%ymm1
  .byte  197,109,219,201                     // vpand         %ymm1,%ymm2,%ymm9
  .byte  196,65,45,118,210                   // vpcmpeqd      %ymm10,%ymm10,%ymm10
  .byte  196,130,45,146,12,137               // vgatherdps    %ymm10,(%r9,%ymm9,4),%ymm1
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  197,181,114,211,16                  // vpsrld        $0x10,%ymm3,%ymm9
  .byte  196,65,109,219,201                  // vpand         %ymm9,%ymm2,%ymm9
  .byte  196,162,61,146,20,136               // vgatherdps    %ymm8,(%rax,%ymm9,4),%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  185,8,0,0,0                         // mov           $0x8,%ecx
  .byte  68,41,193                           // sub           %r8d,%ecx
  .byte  192,225,3                           // shl           $0x3,%cl
  .byte  73,199,194,255,255,255,255          // mov           $0xffffffffffffffff,%r10
  .byte  73,211,234                          // shr           %cl,%r10
  .byte  196,193,249,110,194                 // vmovq         %r10,%xmm0
  .byte  196,226,125,33,192                  // vpmovsxbd     %xmm0,%ymm0
  .byte  196,194,125,140,25                  // vpmaskmovd    (%r9),%ymm0,%ymm3
  .byte  233,99,255,255,255                  // jmpq          13f6 <_sk_load_tables_hsw+0x1a>

HIDDEN _sk_byte_tables_hsw
.globl _sk_byte_tables_hsw
_sk_byte_tables_hsw:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,127,67                   // mov           $0x437f0000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,41                     // movzbl        (%r9,%r13,1),%ebp
  .byte  196,227,121,32,197,4                // vpinsrb       $0x4,%ebp,%xmm0,%xmm0
  .byte  65,15,182,44,25                     // movzbl        (%r9,%rbx,1),%ebp
  .byte  196,227,121,32,197,5                // vpinsrb       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,6                // vpinsrb       $0x6,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,7                // vpinsrb       $0x7,%ebp,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,98,125,88,200                   // vpbroadcastd  %xmm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,201,1                // vextracti128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,32                     // movzbl        (%r8,%r12,1),%ebp
  .byte  196,227,113,32,205,4                // vpinsrb       $0x4,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,56                     // movzbl        (%r8,%r15,1),%ebp
  .byte  196,227,113,32,205,5                // vpinsrb       $0x5,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,6                // vpinsrb       $0x6,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,7                // vpinsrb       $0x7,%ebp,%xmm1,%xmm1
  .byte  196,226,125,49,201                  // vpmovzxbd     %xmm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,210,1                // vextracti128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,211,1                // vpextrq       $0x1,%xmm2,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,215                 // vmovq         %xmm2,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,20,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm2
  .byte  196,195,105,32,20,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm2,%xmm2
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,32                     // movzbl        (%r8,%r12,1),%ebp
  .byte  196,227,105,32,213,4                // vpinsrb       $0x4,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,56                     // movzbl        (%r8,%r15,1),%ebp
  .byte  196,227,105,32,213,5                // vpinsrb       $0x5,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,105,32,213,6                // vpinsrb       $0x6,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,105,32,213,7                // vpinsrb       $0x7,%ebp,%xmm2,%xmm2
  .byte  196,226,125,49,210                  // vpmovzxbd     %xmm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,253,91,219                      // vcvtps2dq     %ymm3,%ymm3
  .byte  196,227,249,22,221,1                // vpextrq       $0x1,%xmm3,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,219                 // vmovq         %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,219,1                // vextracti128  $0x1,%ymm3,%xmm3
  .byte  196,195,249,22,218,1                // vpextrq       $0x1,%xmm3,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,222                 // vmovq         %xmm3,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,28,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm3
  .byte  196,227,97,32,28,24,1               // vpinsrb       $0x1,(%rax,%rbx,1),%xmm3,%xmm3
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,97,32,219,2                 // vpinsrb       $0x2,%ebx,%xmm3,%xmm3
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,97,32,221,3                 // vpinsrb       $0x3,%ebp,%xmm3,%xmm3
  .byte  66,15,182,44,56                     // movzbl        (%rax,%r15,1),%ebp
  .byte  196,227,97,32,221,4                 // vpinsrb       $0x4,%ebp,%xmm3,%xmm3
  .byte  66,15,182,44,48                     // movzbl        (%rax,%r14,1),%ebp
  .byte  196,227,97,32,221,5                 // vpinsrb       $0x5,%ebp,%xmm3,%xmm3
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,97,32,221,6                 // vpinsrb       $0x6,%ebp,%xmm3,%xmm3
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,97,32,216,7                 // vpinsrb       $0x7,%eax,%xmm3,%xmm3
  .byte  196,226,125,49,219                  // vpmovzxbd     %xmm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_hsw
.globl _sk_byte_tables_rgb_hsw
_sk_byte_tables_rgb_hsw:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,139,64,24                        // mov           0x18(%rax),%r8d
  .byte  65,255,200                          // dec           %r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,41                     // movzbl        (%r9,%r13,1),%ebp
  .byte  196,227,121,32,197,4                // vpinsrb       $0x4,%ebp,%xmm0,%xmm0
  .byte  65,15,182,44,25                     // movzbl        (%r9,%rbx,1),%ebp
  .byte  196,227,121,32,197,5                // vpinsrb       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,6                // vpinsrb       $0x6,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,7                // vpinsrb       $0x7,%ebp,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,98,125,88,200                   // vpbroadcastd  %xmm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,201,1                // vextracti128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,32                     // movzbl        (%r8,%r12,1),%ebp
  .byte  196,227,113,32,205,4                // vpinsrb       $0x4,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,56                     // movzbl        (%r8,%r15,1),%ebp
  .byte  196,227,113,32,205,5                // vpinsrb       $0x5,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,6                // vpinsrb       $0x6,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,7                // vpinsrb       $0x7,%ebp,%xmm1,%xmm1
  .byte  196,226,125,49,201                  // vpmovzxbd     %xmm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,210,1                // vextracti128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,210,1                // vpextrq       $0x1,%xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,214                 // vmovq         %xmm2,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,20,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm2
  .byte  196,227,105,32,20,24,1              // vpinsrb       $0x1,(%rax,%rbx,1),%xmm2,%xmm2
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  66,15,182,44,56                     // movzbl        (%rax,%r15,1),%ebp
  .byte  196,227,105,32,213,4                // vpinsrb       $0x4,%ebp,%xmm2,%xmm2
  .byte  66,15,182,44,48                     // movzbl        (%rax,%r14,1),%ebp
  .byte  196,227,105,32,213,5                // vpinsrb       $0x5,%ebp,%xmm2,%xmm2
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,105,32,213,6                // vpinsrb       $0x6,%ebp,%xmm2,%xmm2
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,105,32,208,7                // vpinsrb       $0x7,%eax,%xmm2,%xmm2
  .byte  196,226,125,49,210                  // vpmovzxbd     %xmm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_hsw
.globl _sk_load_a8_hsw
_sk_load_a8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,50                              // jne           19c2 <_sk_load_a8_hsw+0x42>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           19ca <_sk_load_a8_hsw+0x4a>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,173                             // jmp           1994 <_sk_load_a8_hsw+0x14>

HIDDEN _sk_gather_a8_hsw
.globl _sk_gather_a8_hsw
_sk_gather_a8_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,4,24,0               // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,16,1               // vpinsrb       $0x1,(%r8,%r10,1),%xmm0,%xmm0
  .byte  71,15,182,12,8                      // movzbl        (%r8,%r9,1),%r9d
  .byte  196,195,121,32,193,2                // vpinsrb       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,121,32,192,3                // vpinsrb       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,32                      // movzbl        (%r8,%r12,1),%eax
  .byte  196,227,121,32,192,4                // vpinsrb       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,56                      // movzbl        (%r8,%r15,1),%eax
  .byte  196,227,121,32,192,5                // vpinsrb       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,48                      // movzbl        (%r8,%r14,1),%eax
  .byte  196,227,121,32,192,6                // vpinsrb       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,182,4,24                      // movzbl        (%r8,%rbx,1),%eax
  .byte  196,227,121,32,192,7                // vpinsrb       $0x7,%eax,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,237,239,210                     // vpxor         %ymm2,%ymm2,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_hsw
.globl _sk_store_a8_hsw
_sk_store_a8_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  196,65,57,103,192                   // vpackuswb     %xmm8,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           1aff <_sk_store_a8_hsw+0x3b>
  .byte  196,65,123,17,4,57                  // vmovsd        %xmm8,(%r9,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            1afb <_sk_store_a8_hsw+0x37>
  .byte  196,66,121,48,192                   // vpmovzxbw     %xmm8,%xmm8
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,69,0,0,0                   // lea           0x45(%rip),%r8        # 1b64 <_sk_store_a8_hsw+0xa0>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,20,68,57,6,12            // vpextrb       $0xc,%xmm8,0x6(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,5,10            // vpextrb       $0xa,%xmm8,0x5(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,4,8             // vpextrb       $0x8,%xmm8,0x4(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,3,6             // vpextrb       $0x6,%xmm8,0x3(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,2,4             // vpextrb       $0x4,%xmm8,0x2(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,1,2             // vpextrb       $0x2,%xmm8,0x1(%r9,%rdi,1)
  .byte  196,67,121,20,4,57,0                // vpextrb       $0x0,%xmm8,(%r9,%rdi,1)
  .byte  235,154                             // jmp           1afb <_sk_store_a8_hsw+0x37>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  244                                 // hlt
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  236                                 // in            (%dx),%al
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,228                             // jmpq          *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  220,255                             // fdivr         %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,212                             // callq         *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,204                             // dec           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,196                             // inc           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_g8_hsw
.globl _sk_load_g8_hsw
_sk_load_g8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,60                              // jne           1bcc <_sk_load_g8_hsw+0x4c>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,217                  // vpbroadcastd  %xmm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           1bd4 <_sk_load_g8_hsw+0x54>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,163                             // jmp           1b94 <_sk_load_g8_hsw+0x14>

HIDDEN _sk_gather_g8_hsw
.globl _sk_gather_g8_hsw
_sk_gather_g8_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,4,24,0               // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,16,1               // vpinsrb       $0x1,(%r8,%r10,1),%xmm0,%xmm0
  .byte  71,15,182,12,8                      // movzbl        (%r8,%r9,1),%r9d
  .byte  196,195,121,32,193,2                // vpinsrb       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,121,32,192,3                // vpinsrb       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,32                      // movzbl        (%r8,%r12,1),%eax
  .byte  196,227,121,32,192,4                // vpinsrb       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,56                      // movzbl        (%r8,%r15,1),%eax
  .byte  196,227,121,32,192,5                // vpinsrb       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,48                      // movzbl        (%r8,%r14,1),%eax
  .byte  196,227,121,32,192,6                // vpinsrb       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,182,4,24                      // movzbl        (%r8,%rbx,1),%eax
  .byte  196,227,121,32,192,7                // vpinsrb       $0x7,%eax,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,217                  // vpbroadcastd  %xmm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_hsw
.globl _sk_gather_i8_hsw
_sk_gather_i8_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            1ce7 <_sk_gather_i8_hsw+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           1ce9 <_sk_gather_i8_hsw+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,194                          // mov           %eax,%r10d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,195                 // vmovq         %xmm0,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,196                 // vmovq         %xmm0,%r12
  .byte  69,137,229                          // mov           %r12d,%r13d
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,131,121,32,4,49,0               // vpinsrb       $0x0,(%r9,%r14,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,17,2               // vpinsrb       $0x2,(%r9,%r10,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,1,3                // vpinsrb       $0x3,(%r9,%rax,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,41,4               // vpinsrb       $0x4,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,33,5               // vpinsrb       $0x5,(%r9,%r12,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,6               // vpinsrb       $0x6,(%r9,%r15,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,7               // vpinsrb       $0x7,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  73,139,64,8                         // mov           0x8(%r8),%rax
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  196,226,117,144,28,128              // vpgatherdd    %ymm1,(%rax,%ymm0,4),%ymm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,208                  // vpbroadcastd  %xmm0,%ymm2
  .byte  197,237,219,195                     // vpand         %ymm3,%ymm2,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,245,114,211,8                   // vpsrld        $0x8,%ymm3,%ymm1
  .byte  197,237,219,201                     // vpand         %ymm1,%ymm2,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  197,181,114,211,16                  // vpsrld        $0x10,%ymm3,%ymm9
  .byte  196,193,109,219,209                 // vpand         %ymm9,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_hsw
.globl _sk_load_565_hsw
_sk_load_565_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,149,0,0,0                    // jne           1e9b <_sk_load_565_hsw+0xa3>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  196,226,125,51,208                  // vpmovzxwd     %xmm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,253,219,194                     // vpand         %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,245,219,202                     // vpand         %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,229,219,210                     // vpand         %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,89,255,255,255               // ja            1e0c <_sk_load_565_hsw+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,74,0,0,0                  // lea           0x4a(%rip),%r9        # 1f08 <_sk_load_565_hsw+0x110>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,5,255,255,255                   // jmpq          1e0c <_sk_load_565_hsw+0x14>
  .byte  144                                 // nop
  .byte  243,255                             // repz          (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  235,255                             // jmp           1f0d <_sk_load_565_hsw+0x115>
  .byte  255                                 // (bad)
  .byte  255,227                             // jmpq          *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  219,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,211                             // callq         *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,203                             // dec           %ebx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  191                                 // .byte         0xbf
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_565_hsw
.globl _sk_gather_565_hsw
_sk_gather_565_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  71,15,183,20,80                     // movzwl        (%r8,%r10,2),%r10d
  .byte  71,15,183,28,88                     // movzwl        (%r8,%r11,2),%r11d
  .byte  196,193,121,110,195                 // vmovd         %r11d,%xmm0
  .byte  196,193,121,196,194,1               // vpinsrw       $0x1,%r10d,%xmm0,%xmm0
  .byte  71,15,183,12,72                     // movzwl        (%r8,%r9,2),%r9d
  .byte  196,193,121,196,193,2               // vpinsrw       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,3                   // vpinsrw       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,96                      // movzwl        (%r8,%r12,2),%eax
  .byte  197,249,196,192,4                   // vpinsrw       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,120                     // movzwl        (%r8,%r15,2),%eax
  .byte  197,249,196,192,5                   // vpinsrw       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,112                     // movzwl        (%r8,%r14,2),%eax
  .byte  197,249,196,192,6                   // vpinsrw       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,183,4,88                      // movzwl        (%r8,%rbx,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  196,226,125,51,208                  // vpmovzxwd     %xmm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,253,219,194                     // vpand         %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,245,219,202                     // vpand         %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,229,219,210                     // vpand         %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_hsw
.globl _sk_store_565_hsw
_sk_store_565_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,248,65                      // mov           $0x41f80000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,53,114,241,11               // vpslld        $0xb,%ymm9,%ymm9
  .byte  184,0,0,124,66                      // mov           $0x427c0000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,5                // vpslld        $0x5,%ymm10,%ymm10
  .byte  196,65,45,235,201                   // vpor          %ymm9,%ymm10,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,53,235,192                   // vpor          %ymm8,%ymm9,%ymm8
  .byte  196,67,125,57,193,1                 // vextracti128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           20d3 <_sk_store_565_hsw+0x6c>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            20cf <_sk_store_565_hsw+0x68>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,66,0,0,0                   // lea           0x42(%rip),%r8        # 2130 <_sk_store_565_hsw+0xc9>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           20cf <_sk_store_565_hsw+0x68>
  .byte  247,255                             // idiv          %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  239                                 // out           %eax,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,231                             // jmpq          *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  223,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,215                             // callq         *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,207                             // dec           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,199                             // inc           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_4444_hsw
.globl _sk_load_4444_hsw
_sk_load_4444_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,179,0,0,0                    // jne           220d <_sk_load_4444_hsw+0xc1>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  196,98,125,51,200                   // vpmovzxwd     %xmm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  196,193,125,219,193                 // vpand         %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  196,193,117,219,201                 // vpand         %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  196,193,109,219,209                 // vpand         %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,217                 // vpand         %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,59,255,255,255               // ja            2160 <_sk_load_4444_hsw+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,76,0,0,0                  // lea           0x4c(%rip),%r9        # 227c <_sk_load_4444_hsw+0x130>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,231,254,255,255                 // jmpq          2160 <_sk_load_4444_hsw+0x14>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  241                                 // icebp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  233,255,255,255,225                 // jmpq          ffffffffe2002284 <_sk_bicubic_p3y_hsw+0xffffffffe1ffecd5>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  217,255                             // fcos
  .byte  255                                 // (bad)
  .byte  255,209                             // callq         *%rcx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,201                             // dec           %ecx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  189                                 // .byte         0xbd
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_4444_hsw
.globl _sk_gather_4444_hsw
_sk_gather_4444_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  71,15,183,20,80                     // movzwl        (%r8,%r10,2),%r10d
  .byte  71,15,183,28,88                     // movzwl        (%r8,%r11,2),%r11d
  .byte  196,193,121,110,195                 // vmovd         %r11d,%xmm0
  .byte  196,193,121,196,194,1               // vpinsrw       $0x1,%r10d,%xmm0,%xmm0
  .byte  71,15,183,12,72                     // movzwl        (%r8,%r9,2),%r9d
  .byte  196,193,121,196,193,2               // vpinsrw       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,3                   // vpinsrw       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,96                      // movzwl        (%r8,%r12,2),%eax
  .byte  197,249,196,192,4                   // vpinsrw       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,120                     // movzwl        (%r8,%r15,2),%eax
  .byte  197,249,196,192,5                   // vpinsrw       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,112                     // movzwl        (%r8,%r14,2),%eax
  .byte  197,249,196,192,6                   // vpinsrw       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,183,4,88                      // movzwl        (%r8,%rbx,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  196,98,125,51,200                   // vpmovzxwd     %xmm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  196,193,125,219,193                 // vpand         %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  196,193,117,219,201                 // vpand         %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  196,193,109,219,209                 // vpand         %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,217                 // vpand         %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_hsw
.globl _sk_store_4444_hsw
_sk_store_4444_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,112,65                      // mov           $0x41700000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,53,114,241,12               // vpslld        $0xc,%ymm9,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,8                // vpslld        $0x8,%ymm10,%ymm10
  .byte  196,65,45,235,201                   // vpor          %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,4                // vpslld        $0x4,%ymm10,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,45,235,192                   // vpor          %ymm8,%ymm10,%ymm8
  .byte  196,65,53,235,192                   // vpor          %ymm8,%ymm9,%ymm8
  .byte  196,67,125,57,193,1                 // vextracti128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           246b <_sk_store_4444_hsw+0x72>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            2467 <_sk_store_4444_hsw+0x6e>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,66,0,0,0                   // lea           0x42(%rip),%r8        # 24c8 <_sk_store_4444_hsw+0xcf>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           2467 <_sk_store_4444_hsw+0x6e>
  .byte  247,255                             // idiv          %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  239                                 // out           %eax,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,231                             // jmpq          *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  223,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,215                             // callq         *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,207                             // dec           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,199                             // inc           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_8888_hsw
.globl _sk_load_8888_hsw
_sk_load_8888_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,3,8                              // add           (%rax),%r9
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,104                             // jne           2561 <_sk_load_8888_hsw+0x7d>
  .byte  196,193,126,111,25                  // vmovdqu       (%r9),%ymm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,208                  // vpbroadcastd  %xmm0,%ymm2
  .byte  197,237,219,195                     // vpand         %ymm3,%ymm2,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,245,114,211,8                   // vpsrld        $0x8,%ymm3,%ymm1
  .byte  197,237,219,201                     // vpand         %ymm1,%ymm2,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  197,181,114,211,16                  // vpsrld        $0x10,%ymm3,%ymm9
  .byte  196,193,109,219,209                 // vpand         %ymm9,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  185,8,0,0,0                         // mov           $0x8,%ecx
  .byte  68,41,193                           // sub           %r8d,%ecx
  .byte  192,225,3                           // shl           $0x3,%cl
  .byte  72,199,192,255,255,255,255          // mov           $0xffffffffffffffff,%rax
  .byte  72,211,232                          // shr           %cl,%rax
  .byte  196,225,249,110,192                 // vmovq         %rax,%xmm0
  .byte  196,226,125,33,192                  // vpmovsxbd     %xmm0,%ymm0
  .byte  196,194,125,140,25                  // vpmaskmovd    (%r9),%ymm0,%ymm3
  .byte  233,116,255,255,255                 // jmpq          24fe <_sk_load_8888_hsw+0x1a>

HIDDEN _sk_gather_8888_hsw
.globl _sk_gather_8888_hsw
_sk_gather_8888_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  196,194,117,144,28,128              // vpgatherdd    %ymm1,(%r8,%ymm0,4),%ymm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,208                  // vpbroadcastd  %xmm0,%ymm2
  .byte  197,237,219,195                     // vpand         %ymm3,%ymm2,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,245,114,211,8                   // vpsrld        $0x8,%ymm3,%ymm1
  .byte  197,237,219,201                     // vpand         %ymm1,%ymm2,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  197,181,114,211,16                  // vpsrld        $0x10,%ymm3,%ymm9
  .byte  196,193,109,219,209                 // vpand         %ymm9,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_hsw
.globl _sk_store_8888_hsw
_sk_store_8888_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,3,8                              // add           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,8                // vpslld        $0x8,%ymm10,%ymm10
  .byte  196,65,45,235,201                   // vpor          %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,16               // vpslld        $0x10,%ymm10,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,193,61,114,240,24               // vpslld        $0x18,%ymm8,%ymm8
  .byte  196,65,45,235,192                   // vpor          %ymm8,%ymm10,%ymm8
  .byte  196,65,53,235,192                   // vpor          %ymm8,%ymm9,%ymm8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,12                              // jne           2684 <_sk_store_8888_hsw+0x74>
  .byte  196,65,126,127,1                    // vmovdqu       %ymm8,(%r9)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  185,8,0,0,0                         // mov           $0x8,%ecx
  .byte  68,41,193                           // sub           %r8d,%ecx
  .byte  192,225,3                           // shl           $0x3,%cl
  .byte  72,199,192,255,255,255,255          // mov           $0xffffffffffffffff,%rax
  .byte  72,211,232                          // shr           %cl,%rax
  .byte  196,97,249,110,200                  // vmovq         %rax,%xmm9
  .byte  196,66,125,33,201                   // vpmovsxbd     %xmm9,%ymm9
  .byte  196,66,53,142,1                     // vpmaskmovd    %ymm8,%ymm9,(%r9)
  .byte  235,211                             // jmp           267d <_sk_store_8888_hsw+0x6d>

HIDDEN _sk_load_f16_hsw
.globl _sk_load_f16_hsw
_sk_load_f16_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,97                              // jne           2715 <_sk_load_f16_hsw+0x6b>
  .byte  197,121,16,4,248                    // vmovupd       (%rax,%rdi,8),%xmm8
  .byte  197,249,16,84,248,16                // vmovupd       0x10(%rax,%rdi,8),%xmm2
  .byte  197,249,16,92,248,32                // vmovupd       0x20(%rax,%rdi,8),%xmm3
  .byte  197,122,111,76,248,48               // vmovdqu       0x30(%rax,%rdi,8),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,121,105,202                     // vpunpckhwd    %xmm2,%xmm0,%xmm9
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,241,105,219                     // vpunpckhwd    %xmm3,%xmm1,%xmm3
  .byte  197,185,108,194                     // vpunpcklqdq   %xmm2,%xmm8,%xmm0
  .byte  196,226,125,19,192                  // vcvtph2ps     %xmm0,%ymm0
  .byte  197,185,109,202                     // vpunpckhqdq   %xmm2,%xmm8,%xmm1
  .byte  196,226,125,19,201                  // vcvtph2ps     %xmm1,%ymm1
  .byte  197,177,108,211                     // vpunpcklqdq   %xmm3,%xmm9,%xmm2
  .byte  196,226,125,19,210                  // vcvtph2ps     %xmm2,%ymm2
  .byte  197,177,109,219                     // vpunpckhqdq   %xmm3,%xmm9,%xmm3
  .byte  196,226,125,19,219                  // vcvtph2ps     %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,123,16,4,248                    // vmovsd        (%rax,%rdi,8),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,79                              // je            2774 <_sk_load_f16_hsw+0xca>
  .byte  197,57,22,68,248,8                  // vmovhpd       0x8(%rax,%rdi,8),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,67                              // jb            2774 <_sk_load_f16_hsw+0xca>
  .byte  197,251,16,84,248,16                // vmovsd        0x10(%rax,%rdi,8),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,68                              // je            2781 <_sk_load_f16_hsw+0xd7>
  .byte  197,233,22,84,248,24                // vmovhpd       0x18(%rax,%rdi,8),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,56                              // jb            2781 <_sk_load_f16_hsw+0xd7>
  .byte  197,251,16,92,248,32                // vmovsd        0x20(%rax,%rdi,8),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,114,255,255,255              // je            26cb <_sk_load_f16_hsw+0x21>
  .byte  197,225,22,92,248,40                // vmovhpd       0x28(%rax,%rdi,8),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,98,255,255,255               // jb            26cb <_sk_load_f16_hsw+0x21>
  .byte  197,122,126,76,248,48               // vmovq         0x30(%rax,%rdi,8),%xmm9
  .byte  233,87,255,255,255                  // jmpq          26cb <_sk_load_f16_hsw+0x21>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,74,255,255,255                  // jmpq          26cb <_sk_load_f16_hsw+0x21>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,65,255,255,255                  // jmpq          26cb <_sk_load_f16_hsw+0x21>

HIDDEN _sk_gather_f16_hsw
.globl _sk_gather_f16_hsw
_sk_gather_f16_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  197,237,118,210                     // vpcmpeqd      %ymm2,%ymm2,%ymm2
  .byte  196,194,237,144,28,192              // vpgatherdq    %ymm2,(%r8,%xmm0,8),%ymm3
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,194,245,144,20,192              // vpgatherdq    %ymm1,(%r8,%xmm0,8),%ymm2
  .byte  196,227,125,57,216,1                // vextracti128  $0x1,%ymm3,%xmm0
  .byte  196,227,125,57,209,1                // vextracti128  $0x1,%ymm2,%xmm1
  .byte  197,97,97,192                       // vpunpcklwd    %xmm0,%xmm3,%xmm8
  .byte  197,225,105,192                     // vpunpckhwd    %xmm0,%xmm3,%xmm0
  .byte  197,233,97,217                      // vpunpcklwd    %xmm1,%xmm2,%xmm3
  .byte  197,233,105,201                     // vpunpckhwd    %xmm1,%xmm2,%xmm1
  .byte  197,57,97,200                       // vpunpcklwd    %xmm0,%xmm8,%xmm9
  .byte  197,57,105,192                      // vpunpckhwd    %xmm0,%xmm8,%xmm8
  .byte  197,225,97,209                      // vpunpcklwd    %xmm1,%xmm3,%xmm2
  .byte  197,225,105,217                     // vpunpckhwd    %xmm1,%xmm3,%xmm3
  .byte  197,177,108,194                     // vpunpcklqdq   %xmm2,%xmm9,%xmm0
  .byte  196,226,125,19,192                  // vcvtph2ps     %xmm0,%ymm0
  .byte  197,177,109,202                     // vpunpckhqdq   %xmm2,%xmm9,%xmm1
  .byte  196,226,125,19,201                  // vcvtph2ps     %xmm1,%ymm1
  .byte  197,185,108,211                     // vpunpcklqdq   %xmm3,%xmm8,%xmm2
  .byte  196,226,125,19,210                  // vcvtph2ps     %xmm2,%ymm2
  .byte  197,185,109,219                     // vpunpckhqdq   %xmm3,%xmm8,%xmm3
  .byte  196,226,125,19,219                  // vcvtph2ps     %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_hsw
.globl _sk_store_f16_hsw
_sk_store_f16_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  196,195,125,29,192,4                // vcvtps2ph     $0x4,%ymm0,%xmm8
  .byte  196,195,125,29,201,4                // vcvtps2ph     $0x4,%ymm1,%xmm9
  .byte  196,195,125,29,210,4                // vcvtps2ph     $0x4,%ymm2,%xmm10
  .byte  196,195,125,29,219,4                // vcvtps2ph     $0x4,%ymm3,%xmm11
  .byte  196,65,57,97,225                    // vpunpcklwd    %xmm9,%xmm8,%xmm12
  .byte  196,65,57,105,193                   // vpunpckhwd    %xmm9,%xmm8,%xmm8
  .byte  196,65,41,97,203                    // vpunpcklwd    %xmm11,%xmm10,%xmm9
  .byte  196,65,41,105,235                   // vpunpckhwd    %xmm11,%xmm10,%xmm13
  .byte  196,65,25,98,217                    // vpunpckldq    %xmm9,%xmm12,%xmm11
  .byte  196,65,25,106,209                   // vpunpckhdq    %xmm9,%xmm12,%xmm10
  .byte  196,65,57,98,205                    // vpunpckldq    %xmm13,%xmm8,%xmm9
  .byte  196,65,57,106,197                   // vpunpckhdq    %xmm13,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,27                              // jne           2879 <_sk_store_f16_hsw+0x65>
  .byte  197,120,17,28,248                   // vmovups       %xmm11,(%rax,%rdi,8)
  .byte  197,120,17,84,248,16                // vmovups       %xmm10,0x10(%rax,%rdi,8)
  .byte  197,120,17,76,248,32                // vmovups       %xmm9,0x20(%rax,%rdi,8)
  .byte  197,122,127,68,248,48               // vmovdqu       %xmm8,0x30(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,121,214,28,248                  // vmovq         %xmm11,(%rax,%rdi,8)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,241                             // je            2875 <_sk_store_f16_hsw+0x61>
  .byte  197,121,23,92,248,8                 // vmovhpd       %xmm11,0x8(%rax,%rdi,8)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,229                             // jb            2875 <_sk_store_f16_hsw+0x61>
  .byte  197,121,214,84,248,16               // vmovq         %xmm10,0x10(%rax,%rdi,8)
  .byte  116,221                             // je            2875 <_sk_store_f16_hsw+0x61>
  .byte  197,121,23,84,248,24                // vmovhpd       %xmm10,0x18(%rax,%rdi,8)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,209                             // jb            2875 <_sk_store_f16_hsw+0x61>
  .byte  197,121,214,76,248,32               // vmovq         %xmm9,0x20(%rax,%rdi,8)
  .byte  116,201                             // je            2875 <_sk_store_f16_hsw+0x61>
  .byte  197,121,23,76,248,40                // vmovhpd       %xmm9,0x28(%rax,%rdi,8)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,189                             // jb            2875 <_sk_store_f16_hsw+0x61>
  .byte  197,121,214,68,248,48               // vmovq         %xmm8,0x30(%rax,%rdi,8)
  .byte  235,181                             // jmp           2875 <_sk_store_f16_hsw+0x61>

HIDDEN _sk_load_u16_be_hsw
.globl _sk_load_u16_be_hsw
_sk_load_u16_be_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,201,0,0,0                    // jne           2997 <_sk_load_u16_be_hsw+0xd7>
  .byte  197,121,16,4,248                    // vmovupd       (%rax,%rdi,8),%xmm8
  .byte  197,249,16,84,248,16                // vmovupd       0x10(%rax,%rdi,8),%xmm2
  .byte  197,249,16,92,248,32                // vmovupd       0x20(%rax,%rdi,8),%xmm3
  .byte  197,122,111,76,248,48               // vmovdqu       0x30(%rax,%rdi,8),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,121,105,202                     // vpunpckhwd    %xmm2,%xmm0,%xmm9
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,113,105,219                     // vpunpckhwd    %xmm3,%xmm1,%xmm11
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,98,125,88,208                   // vpbroadcastd  %xmm0,%ymm10
  .byte  197,185,108,194                     // vpunpcklqdq   %xmm2,%xmm8,%xmm0
  .byte  197,241,113,240,8                   // vpsllw        $0x8,%xmm0,%xmm1
  .byte  197,249,113,208,8                   // vpsrlw        $0x8,%xmm0,%xmm0
  .byte  197,241,235,192                     // vpor          %xmm0,%xmm1,%xmm0
  .byte  196,226,125,51,192                  // vpmovzxwd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,185,109,202                     // vpunpckhqdq   %xmm2,%xmm8,%xmm1
  .byte  197,233,113,241,8                   // vpsllw        $0x8,%xmm1,%xmm2
  .byte  197,241,113,209,8                   // vpsrlw        $0x8,%xmm1,%xmm1
  .byte  197,233,235,201                     // vpor          %xmm1,%xmm2,%xmm1
  .byte  196,226,125,51,201                  // vpmovzxwd     %xmm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,49,108,211                  // vpunpcklqdq   %xmm11,%xmm9,%xmm2
  .byte  197,225,113,242,8                   // vpsllw        $0x8,%xmm2,%xmm3
  .byte  197,233,113,210,8                   // vpsrlw        $0x8,%xmm2,%xmm2
  .byte  197,225,235,210                     // vpor          %xmm2,%xmm3,%xmm2
  .byte  196,226,125,51,210                  // vpmovzxwd     %xmm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  196,193,49,109,219                  // vpunpckhqdq   %xmm11,%xmm9,%xmm3
  .byte  197,185,113,243,8                   // vpsllw        $0x8,%xmm3,%xmm8
  .byte  197,225,113,211,8                   // vpsrlw        $0x8,%xmm3,%xmm3
  .byte  197,185,235,219                     // vpor          %xmm3,%xmm8,%xmm3
  .byte  196,226,125,51,219                  // vpmovzxwd     %xmm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,172,89,219                      // vmulps        %ymm3,%ymm10,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,123,16,4,248                    // vmovsd        (%rax,%rdi,8),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,79                              // je            29f6 <_sk_load_u16_be_hsw+0x136>
  .byte  197,57,22,68,248,8                  // vmovhpd       0x8(%rax,%rdi,8),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,67                              // jb            29f6 <_sk_load_u16_be_hsw+0x136>
  .byte  197,251,16,84,248,16                // vmovsd        0x10(%rax,%rdi,8),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,68                              // je            2a03 <_sk_load_u16_be_hsw+0x143>
  .byte  197,233,22,84,248,24                // vmovhpd       0x18(%rax,%rdi,8),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,56                              // jb            2a03 <_sk_load_u16_be_hsw+0x143>
  .byte  197,251,16,92,248,32                // vmovsd        0x20(%rax,%rdi,8),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,10,255,255,255               // je            28e5 <_sk_load_u16_be_hsw+0x25>
  .byte  197,225,22,92,248,40                // vmovhpd       0x28(%rax,%rdi,8),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,250,254,255,255              // jb            28e5 <_sk_load_u16_be_hsw+0x25>
  .byte  197,122,126,76,248,48               // vmovq         0x30(%rax,%rdi,8),%xmm9
  .byte  233,239,254,255,255                 // jmpq          28e5 <_sk_load_u16_be_hsw+0x25>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,226,254,255,255                 // jmpq          28e5 <_sk_load_u16_be_hsw+0x25>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,217,254,255,255                 // jmpq          28e5 <_sk_load_u16_be_hsw+0x25>

HIDDEN _sk_store_u16_be_hsw
.globl _sk_store_u16_be_hsw
_sk_store_u16_be_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  184,0,255,127,71                    // mov           $0x477fff00,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,67,125,25,202,1                 // vextractf128  $0x1,%ymm9,%xmm10
  .byte  196,66,49,43,202                    // vpackusdw     %xmm10,%xmm9,%xmm9
  .byte  196,193,41,113,241,8                // vpsllw        $0x8,%xmm9,%xmm10
  .byte  196,193,49,113,209,8                // vpsrlw        $0x8,%xmm9,%xmm9
  .byte  196,65,41,235,201                   // vpor          %xmm9,%xmm10,%xmm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,67,125,25,211,1                 // vextractf128  $0x1,%ymm10,%xmm11
  .byte  196,66,41,43,211                    // vpackusdw     %xmm11,%xmm10,%xmm10
  .byte  196,193,33,113,242,8                // vpsllw        $0x8,%xmm10,%xmm11
  .byte  196,193,41,113,210,8                // vpsrlw        $0x8,%xmm10,%xmm10
  .byte  196,65,33,235,210                   // vpor          %xmm10,%xmm11,%xmm10
  .byte  197,60,89,218                       // vmulps        %ymm2,%ymm8,%ymm11
  .byte  196,65,125,91,219                   // vcvtps2dq     %ymm11,%ymm11
  .byte  196,67,125,25,220,1                 // vextractf128  $0x1,%ymm11,%xmm12
  .byte  196,66,33,43,220                    // vpackusdw     %xmm12,%xmm11,%xmm11
  .byte  196,193,25,113,243,8                // vpsllw        $0x8,%xmm11,%xmm12
  .byte  196,193,33,113,211,8                // vpsrlw        $0x8,%xmm11,%xmm11
  .byte  196,65,25,235,219                   // vpor          %xmm11,%xmm12,%xmm11
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,196,1                 // vextractf128  $0x1,%ymm8,%xmm12
  .byte  196,66,57,43,196                    // vpackusdw     %xmm12,%xmm8,%xmm8
  .byte  196,193,25,113,240,8                // vpsllw        $0x8,%xmm8,%xmm12
  .byte  196,193,57,113,208,8                // vpsrlw        $0x8,%xmm8,%xmm8
  .byte  196,65,25,235,192                   // vpor          %xmm8,%xmm12,%xmm8
  .byte  196,65,49,97,226                    // vpunpcklwd    %xmm10,%xmm9,%xmm12
  .byte  196,65,49,105,234                   // vpunpckhwd    %xmm10,%xmm9,%xmm13
  .byte  196,65,33,97,200                    // vpunpcklwd    %xmm8,%xmm11,%xmm9
  .byte  196,65,33,105,192                   // vpunpckhwd    %xmm8,%xmm11,%xmm8
  .byte  196,65,25,98,217                    // vpunpckldq    %xmm9,%xmm12,%xmm11
  .byte  196,65,25,106,209                   // vpunpckhdq    %xmm9,%xmm12,%xmm10
  .byte  196,65,17,98,200                    // vpunpckldq    %xmm8,%xmm13,%xmm9
  .byte  196,65,17,106,192                   // vpunpckhdq    %xmm8,%xmm13,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,31                              // jne           2aff <_sk_store_u16_be_hsw+0xf3>
  .byte  196,65,120,17,28,248                // vmovups       %xmm11,(%r8,%rdi,8)
  .byte  196,65,120,17,84,248,16             // vmovups       %xmm10,0x10(%r8,%rdi,8)
  .byte  196,65,120,17,76,248,32             // vmovups       %xmm9,0x20(%r8,%rdi,8)
  .byte  196,65,122,127,68,248,48            // vmovdqu       %xmm8,0x30(%r8,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,121,214,28,248               // vmovq         %xmm11,(%r8,%rdi,8)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            2afb <_sk_store_u16_be_hsw+0xef>
  .byte  196,65,121,23,92,248,8              // vmovhpd       %xmm11,0x8(%r8,%rdi,8)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            2afb <_sk_store_u16_be_hsw+0xef>
  .byte  196,65,121,214,84,248,16            // vmovq         %xmm10,0x10(%r8,%rdi,8)
  .byte  116,218                             // je            2afb <_sk_store_u16_be_hsw+0xef>
  .byte  196,65,121,23,84,248,24             // vmovhpd       %xmm10,0x18(%r8,%rdi,8)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            2afb <_sk_store_u16_be_hsw+0xef>
  .byte  196,65,121,214,76,248,32            // vmovq         %xmm9,0x20(%r8,%rdi,8)
  .byte  116,196                             // je            2afb <_sk_store_u16_be_hsw+0xef>
  .byte  196,65,121,23,76,248,40             // vmovhpd       %xmm9,0x28(%r8,%rdi,8)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,183                             // jb            2afb <_sk_store_u16_be_hsw+0xef>
  .byte  196,65,121,214,68,248,48            // vmovq         %xmm8,0x30(%r8,%rdi,8)
  .byte  235,174                             // jmp           2afb <_sk_store_u16_be_hsw+0xef>

HIDDEN _sk_load_f32_hsw
.globl _sk_load_f32_hsw
_sk_load_f32_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  119,110                             // ja            2bc3 <_sk_load_f32_hsw+0x76>
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,141,21,133,0,0,0                 // lea           0x85(%rip),%r10        # 2bec <_sk_load_f32_hsw+0x9f>
  .byte  73,99,4,138                         // movslq        (%r10,%rcx,4),%rax
  .byte  76,1,208                            // add           %r10,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,3,125,24,68,136,112,1           // vinsertf128   $0x1,0x70(%r8,%r9,4),%ymm0,%ymm8
  .byte  196,131,125,24,92,136,96,1          // vinsertf128   $0x1,0x60(%r8,%r9,4),%ymm0,%ymm3
  .byte  196,131,125,24,76,136,80,1          // vinsertf128   $0x1,0x50(%r8,%r9,4),%ymm0,%ymm1
  .byte  196,131,125,24,84,136,64,1          // vinsertf128   $0x1,0x40(%r8,%r9,4),%ymm0,%ymm2
  .byte  196,129,121,16,68,136,48            // vmovupd       0x30(%r8,%r9,4),%xmm0
  .byte  196,195,125,13,192,12               // vblendpd      $0xc,%ymm8,%ymm0,%ymm0
  .byte  196,1,121,16,68,136,32              // vmovupd       0x20(%r8,%r9,4),%xmm8
  .byte  196,99,61,13,203,12                 // vblendpd      $0xc,%ymm3,%ymm8,%ymm9
  .byte  196,129,121,16,92,136,16            // vmovupd       0x10(%r8,%r9,4),%xmm3
  .byte  196,99,101,13,209,12                // vblendpd      $0xc,%ymm1,%ymm3,%ymm10
  .byte  196,129,121,16,12,136               // vmovupd       (%r8,%r9,4),%xmm1
  .byte  196,227,117,13,202,12               // vblendpd      $0xc,%ymm2,%ymm1,%ymm1
  .byte  196,193,116,20,210                  // vunpcklps     %ymm10,%ymm1,%ymm2
  .byte  196,193,116,21,218                  // vunpckhps     %ymm10,%ymm1,%ymm3
  .byte  197,180,20,200                      // vunpcklps     %ymm0,%ymm9,%ymm1
  .byte  197,52,21,192                       // vunpckhps     %ymm0,%ymm9,%ymm8
  .byte  197,237,20,193                      // vunpcklpd     %ymm1,%ymm2,%ymm0
  .byte  197,237,21,201                      // vunpckhpd     %ymm1,%ymm2,%ymm1
  .byte  196,193,101,20,208                  // vunpcklpd     %ymm8,%ymm3,%ymm2
  .byte  196,193,101,21,216                  // vunpckhpd     %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  144                                 // nop
  .byte  132,255                             // test          %bh,%bh
  .byte  255                                 // (bad)
  .byte  255,203                             // dec           %ebx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  190,255,255,255,177                 // mov           $0xb1ffffff,%esi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,164,255,255,255,156,255         // jmpq          *-0x630001(%rdi,%rdi,8)
  .byte  255                                 // (bad)
  .byte  255,148,255,255,255,140,255         // callq         *-0x730001(%rdi,%rdi,8)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_store_f32_hsw
.globl _sk_store_f32_hsw
_sk_store_f32_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,189,0,0,0,0                // lea           0x0(,%rdi,4),%rax
  .byte  197,124,20,193                      // vunpcklps     %ymm1,%ymm0,%ymm8
  .byte  197,124,21,217                      // vunpckhps     %ymm1,%ymm0,%ymm11
  .byte  197,108,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm9
  .byte  197,108,21,227                      // vunpckhps     %ymm3,%ymm2,%ymm12
  .byte  196,65,61,20,209                    // vunpcklpd     %ymm9,%ymm8,%ymm10
  .byte  196,65,61,21,201                    // vunpckhpd     %ymm9,%ymm8,%ymm9
  .byte  196,65,37,20,196                    // vunpcklpd     %ymm12,%ymm11,%ymm8
  .byte  196,65,37,21,220                    // vunpckhpd     %ymm12,%ymm11,%ymm11
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,55                              // jne           2c79 <_sk_store_f32_hsw+0x6d>
  .byte  196,67,45,24,225,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm12
  .byte  196,67,61,24,235,1                  // vinsertf128   $0x1,%xmm11,%ymm8,%ymm13
  .byte  196,67,45,6,201,49                  // vperm2f128    $0x31,%ymm9,%ymm10,%ymm9
  .byte  196,67,61,6,195,49                  // vperm2f128    $0x31,%ymm11,%ymm8,%ymm8
  .byte  196,65,125,17,36,128                // vmovupd       %ymm12,(%r8,%rax,4)
  .byte  196,65,125,17,108,128,32            // vmovupd       %ymm13,0x20(%r8,%rax,4)
  .byte  196,65,125,17,76,128,64             // vmovupd       %ymm9,0x40(%r8,%rax,4)
  .byte  196,65,125,17,68,128,96             // vmovupd       %ymm8,0x60(%r8,%rax,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,121,17,20,128                // vmovupd       %xmm10,(%r8,%rax,4)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            2c75 <_sk_store_f32_hsw+0x69>
  .byte  196,65,121,17,76,128,16             // vmovupd       %xmm9,0x10(%r8,%rax,4)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            2c75 <_sk_store_f32_hsw+0x69>
  .byte  196,65,121,17,68,128,32             // vmovupd       %xmm8,0x20(%r8,%rax,4)
  .byte  116,218                             // je            2c75 <_sk_store_f32_hsw+0x69>
  .byte  196,65,121,17,92,128,48             // vmovupd       %xmm11,0x30(%r8,%rax,4)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            2c75 <_sk_store_f32_hsw+0x69>
  .byte  196,67,125,25,84,128,64,1           // vextractf128  $0x1,%ymm10,0x40(%r8,%rax,4)
  .byte  116,195                             // je            2c75 <_sk_store_f32_hsw+0x69>
  .byte  196,67,125,25,76,128,80,1           // vextractf128  $0x1,%ymm9,0x50(%r8,%rax,4)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,181                             // jb            2c75 <_sk_store_f32_hsw+0x69>
  .byte  196,67,125,25,68,128,96,1           // vextractf128  $0x1,%ymm8,0x60(%r8,%rax,4)
  .byte  235,171                             // jmp           2c75 <_sk_store_f32_hsw+0x69>

HIDDEN _sk_clamp_x_hsw
.globl _sk_clamp_x_hsw
_sk_clamp_x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,188,95,192                      // vmaxps        %ymm0,%ymm8,%ymm0
  .byte  196,98,125,88,0                     // vpbroadcastd  (%rax),%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,65,61,254,193                   // vpaddd        %ymm9,%ymm8,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_hsw
.globl _sk_clamp_y_hsw
_sk_clamp_y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,188,95,201                      // vmaxps        %ymm1,%ymm8,%ymm1
  .byte  196,98,125,88,0                     // vpbroadcastd  (%rax),%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,65,61,254,193                   // vpaddd        %ymm9,%ymm8,%ymm8
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_hsw
.globl _sk_repeat_x_hsw
_sk_repeat_x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,124,94,200                   // vdivps        %ymm8,%ymm0,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,98,61,172,200                   // vfnmadd213ps  %ymm0,%ymm8,%ymm9
  .byte  197,253,118,192                     // vpcmpeqd      %ymm0,%ymm0,%ymm0
  .byte  197,189,254,192                     // vpaddd        %ymm0,%ymm8,%ymm0
  .byte  197,180,93,192                      // vminps        %ymm0,%ymm9,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_hsw
.globl _sk_repeat_y_hsw
_sk_repeat_y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,116,94,200                   // vdivps        %ymm8,%ymm1,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,98,61,172,201                   // vfnmadd213ps  %ymm1,%ymm8,%ymm9
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  197,189,254,201                     // vpaddd        %ymm1,%ymm8,%ymm1
  .byte  197,180,93,201                      // vminps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_hsw
.globl _sk_mirror_x_hsw
_sk_mirror_x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,122,16,0                        // vmovss        (%rax),%xmm8
  .byte  196,66,125,24,200                   // vbroadcastss  %xmm8,%ymm9
  .byte  196,65,124,92,209                   // vsubps        %ymm9,%ymm0,%ymm10
  .byte  196,193,58,88,192                   // vaddss        %xmm8,%xmm8,%xmm0
  .byte  196,226,125,24,192                  // vbroadcastss  %xmm0,%ymm0
  .byte  197,44,94,192                       // vdivps        %ymm0,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  196,66,125,172,194                  // vfnmadd213ps  %ymm10,%ymm0,%ymm8
  .byte  196,193,60,92,193                   // vsubps        %ymm9,%ymm8,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,192                       // vsubps        %ymm0,%ymm8,%ymm8
  .byte  197,188,84,192                      // vandps        %ymm0,%ymm8,%ymm0
  .byte  196,65,61,118,192                   // vpcmpeqd      %ymm8,%ymm8,%ymm8
  .byte  196,65,53,254,192                   // vpaddd        %ymm8,%ymm9,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_hsw
.globl _sk_mirror_y_hsw
_sk_mirror_y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,122,16,0                        // vmovss        (%rax),%xmm8
  .byte  196,66,125,24,200                   // vbroadcastss  %xmm8,%ymm9
  .byte  196,65,116,92,209                   // vsubps        %ymm9,%ymm1,%ymm10
  .byte  196,193,58,88,200                   // vaddss        %xmm8,%xmm8,%xmm1
  .byte  196,226,125,24,201                  // vbroadcastss  %xmm1,%ymm1
  .byte  197,44,94,193                       // vdivps        %ymm1,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  196,66,117,172,194                  // vfnmadd213ps  %ymm10,%ymm1,%ymm8
  .byte  196,193,60,92,201                   // vsubps        %ymm9,%ymm8,%ymm1
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,193                       // vsubps        %ymm1,%ymm8,%ymm8
  .byte  197,188,84,201                      // vandps        %ymm1,%ymm8,%ymm1
  .byte  196,65,61,118,192                   // vpcmpeqd      %ymm8,%ymm8,%ymm8
  .byte  196,65,53,254,192                   // vpaddd        %ymm8,%ymm9,%ymm8
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_hsw
.globl _sk_luminance_to_alpha_hsw
_sk_luminance_to_alpha_hsw:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,98,125,88,195                   // vpbroadcastd  %xmm3,%ymm8
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,228,89,201                      // vmulps        %ymm1,%ymm3,%ymm1
  .byte  196,98,125,168,193                  // vfmadd213ps   %ymm1,%ymm0,%ymm8
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,216                  // vpbroadcastd  %xmm0,%ymm3
  .byte  196,194,109,168,216                 // vfmadd213ps   %ymm8,%ymm2,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,253,239,192                     // vpxor         %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_hsw
.globl _sk_matrix_2x3_hsw
_sk_matrix_2x3_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,8                     // vbroadcastss  (%rax),%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,66,117,184,194                  // vfmadd231ps   %ymm10,%ymm1,%ymm8
  .byte  196,66,125,184,193                  // vfmadd231ps   %ymm9,%ymm0,%ymm8
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,12                 // vbroadcastss  0xc(%rax),%ymm11
  .byte  196,98,125,24,72,20                 // vbroadcastss  0x14(%rax),%ymm9
  .byte  196,66,117,184,203                  // vfmadd231ps   %ymm11,%ymm1,%ymm9
  .byte  196,66,125,184,202                  // vfmadd231ps   %ymm10,%ymm0,%ymm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_hsw
.globl _sk_matrix_3x4_hsw
_sk_matrix_3x4_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,8                     // vbroadcastss  (%rax),%ymm9
  .byte  196,98,125,24,80,12                 // vbroadcastss  0xc(%rax),%ymm10
  .byte  196,98,125,24,88,24                 // vbroadcastss  0x18(%rax),%ymm11
  .byte  196,98,125,24,64,36                 // vbroadcastss  0x24(%rax),%ymm8
  .byte  196,66,109,184,195                  // vfmadd231ps   %ymm11,%ymm2,%ymm8
  .byte  196,66,117,184,194                  // vfmadd231ps   %ymm10,%ymm1,%ymm8
  .byte  196,66,125,184,193                  // vfmadd231ps   %ymm9,%ymm0,%ymm8
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,16                 // vbroadcastss  0x10(%rax),%ymm11
  .byte  196,98,125,24,96,28                 // vbroadcastss  0x1c(%rax),%ymm12
  .byte  196,98,125,24,72,40                 // vbroadcastss  0x28(%rax),%ymm9
  .byte  196,66,109,184,204                  // vfmadd231ps   %ymm12,%ymm2,%ymm9
  .byte  196,66,117,184,203                  // vfmadd231ps   %ymm11,%ymm1,%ymm9
  .byte  196,66,125,184,202                  // vfmadd231ps   %ymm10,%ymm0,%ymm9
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,98,125,24,96,20                 // vbroadcastss  0x14(%rax),%ymm12
  .byte  196,98,125,24,104,32                // vbroadcastss  0x20(%rax),%ymm13
  .byte  196,98,125,24,80,44                 // vbroadcastss  0x2c(%rax),%ymm10
  .byte  196,66,109,184,213                  // vfmadd231ps   %ymm13,%ymm2,%ymm10
  .byte  196,66,117,184,212                  // vfmadd231ps   %ymm12,%ymm1,%ymm10
  .byte  196,66,125,184,211                  // vfmadd231ps   %ymm11,%ymm0,%ymm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  197,124,41,210                      // vmovaps       %ymm10,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_hsw
.globl _sk_matrix_4x5_hsw
_sk_matrix_4x5_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,8                     // vbroadcastss  (%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  196,98,125,24,88,32                 // vbroadcastss  0x20(%rax),%ymm11
  .byte  196,98,125,24,96,48                 // vbroadcastss  0x30(%rax),%ymm12
  .byte  196,98,125,24,64,64                 // vbroadcastss  0x40(%rax),%ymm8
  .byte  196,66,101,184,196                  // vfmadd231ps   %ymm12,%ymm3,%ymm8
  .byte  196,66,109,184,195                  // vfmadd231ps   %ymm11,%ymm2,%ymm8
  .byte  196,66,117,184,194                  // vfmadd231ps   %ymm10,%ymm1,%ymm8
  .byte  196,66,125,184,193                  // vfmadd231ps   %ymm9,%ymm0,%ymm8
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,98,125,24,96,36                 // vbroadcastss  0x24(%rax),%ymm12
  .byte  196,98,125,24,104,52                // vbroadcastss  0x34(%rax),%ymm13
  .byte  196,98,125,24,72,68                 // vbroadcastss  0x44(%rax),%ymm9
  .byte  196,66,101,184,205                  // vfmadd231ps   %ymm13,%ymm3,%ymm9
  .byte  196,66,109,184,204                  // vfmadd231ps   %ymm12,%ymm2,%ymm9
  .byte  196,66,117,184,203                  // vfmadd231ps   %ymm11,%ymm1,%ymm9
  .byte  196,66,125,184,202                  // vfmadd231ps   %ymm10,%ymm0,%ymm9
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,98,125,24,96,24                 // vbroadcastss  0x18(%rax),%ymm12
  .byte  196,98,125,24,104,40                // vbroadcastss  0x28(%rax),%ymm13
  .byte  196,98,125,24,112,56                // vbroadcastss  0x38(%rax),%ymm14
  .byte  196,98,125,24,80,72                 // vbroadcastss  0x48(%rax),%ymm10
  .byte  196,66,101,184,214                  // vfmadd231ps   %ymm14,%ymm3,%ymm10
  .byte  196,66,109,184,213                  // vfmadd231ps   %ymm13,%ymm2,%ymm10
  .byte  196,66,117,184,212                  // vfmadd231ps   %ymm12,%ymm1,%ymm10
  .byte  196,66,125,184,211                  // vfmadd231ps   %ymm11,%ymm0,%ymm10
  .byte  196,98,125,24,96,12                 // vbroadcastss  0xc(%rax),%ymm12
  .byte  196,98,125,24,104,28                // vbroadcastss  0x1c(%rax),%ymm13
  .byte  196,98,125,24,112,44                // vbroadcastss  0x2c(%rax),%ymm14
  .byte  196,98,125,24,120,60                // vbroadcastss  0x3c(%rax),%ymm15
  .byte  196,98,125,24,88,76                 // vbroadcastss  0x4c(%rax),%ymm11
  .byte  196,66,101,184,223                  // vfmadd231ps   %ymm15,%ymm3,%ymm11
  .byte  196,66,109,184,222                  // vfmadd231ps   %ymm14,%ymm2,%ymm11
  .byte  196,66,117,184,221                  // vfmadd231ps   %ymm13,%ymm1,%ymm11
  .byte  196,66,125,184,220                  // vfmadd231ps   %ymm12,%ymm0,%ymm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  197,124,41,210                      // vmovaps       %ymm10,%ymm2
  .byte  197,124,41,219                      // vmovaps       %ymm11,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_hsw
.globl _sk_matrix_perspective_hsw
_sk_matrix_perspective_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,66,117,184,209                  // vfmadd231ps   %ymm9,%ymm1,%ymm10
  .byte  196,66,125,184,208                  // vfmadd231ps   %ymm8,%ymm0,%ymm10
  .byte  196,98,125,24,64,12                 // vbroadcastss  0xc(%rax),%ymm8
  .byte  196,98,125,24,72,16                 // vbroadcastss  0x10(%rax),%ymm9
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,66,117,184,217                  // vfmadd231ps   %ymm9,%ymm1,%ymm11
  .byte  196,66,125,184,216                  // vfmadd231ps   %ymm8,%ymm0,%ymm11
  .byte  196,98,125,24,64,24                 // vbroadcastss  0x18(%rax),%ymm8
  .byte  196,98,125,24,72,28                 // vbroadcastss  0x1c(%rax),%ymm9
  .byte  196,98,125,24,96,32                 // vbroadcastss  0x20(%rax),%ymm12
  .byte  196,66,117,184,225                  // vfmadd231ps   %ymm9,%ymm1,%ymm12
  .byte  196,66,125,184,224                  // vfmadd231ps   %ymm8,%ymm0,%ymm12
  .byte  196,193,124,83,204                  // vrcpps        %ymm12,%ymm1
  .byte  197,172,89,193                      // vmulps        %ymm1,%ymm10,%ymm0
  .byte  197,164,89,201                      // vmulps        %ymm1,%ymm11,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_hsw
.globl _sk_linear_gradient_hsw
_sk_linear_gradient_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,98,125,24,72,28                 // vbroadcastss  0x1c(%rax),%ymm9
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  15,132,143,0,0,0                    // je            3105 <_sk_linear_gradient_hsw+0xb5>
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  196,98,125,24,104,224               // vbroadcastss  -0x20(%rax),%ymm13
  .byte  196,65,124,194,237,1                // vcmpltps      %ymm13,%ymm0,%ymm13
  .byte  196,98,125,24,112,228               // vbroadcastss  -0x1c(%rax),%ymm14
  .byte  196,67,13,74,228,208                // vblendvps     %ymm13,%ymm12,%ymm14,%ymm12
  .byte  196,98,125,24,112,232               // vbroadcastss  -0x18(%rax),%ymm14
  .byte  196,227,13,74,201,208               // vblendvps     %ymm13,%ymm1,%ymm14,%ymm1
  .byte  196,98,125,24,112,236               // vbroadcastss  -0x14(%rax),%ymm14
  .byte  196,227,13,74,210,208               // vblendvps     %ymm13,%ymm2,%ymm14,%ymm2
  .byte  196,98,125,24,112,240               // vbroadcastss  -0x10(%rax),%ymm14
  .byte  196,227,13,74,219,208               // vblendvps     %ymm13,%ymm3,%ymm14,%ymm3
  .byte  196,98,125,24,112,244               // vbroadcastss  -0xc(%rax),%ymm14
  .byte  196,67,13,74,192,208                // vblendvps     %ymm13,%ymm8,%ymm14,%ymm8
  .byte  196,98,125,24,112,248               // vbroadcastss  -0x8(%rax),%ymm14
  .byte  196,67,13,74,219,208                // vblendvps     %ymm13,%ymm11,%ymm14,%ymm11
  .byte  196,98,125,24,112,252               // vbroadcastss  -0x4(%rax),%ymm14
  .byte  196,67,13,74,210,208                // vblendvps     %ymm13,%ymm10,%ymm14,%ymm10
  .byte  196,98,125,24,48                    // vbroadcastss  (%rax),%ymm14
  .byte  196,67,13,74,201,208                // vblendvps     %ymm13,%ymm9,%ymm14,%ymm9
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  73,255,200                          // dec           %r8
  .byte  117,140                             // jne           308f <_sk_linear_gradient_hsw+0x3f>
  .byte  235,17                              // jmp           3116 <_sk_linear_gradient_hsw+0xc6>
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  196,66,125,184,196                  // vfmadd231ps   %ymm12,%ymm0,%ymm8
  .byte  196,194,125,168,203                 // vfmadd213ps   %ymm11,%ymm0,%ymm1
  .byte  196,194,125,168,210                 // vfmadd213ps   %ymm10,%ymm0,%ymm2
  .byte  196,194,125,168,217                 // vfmadd213ps   %ymm9,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_hsw
.globl _sk_linear_gradient_2stops_hsw
_sk_linear_gradient_2stops_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,8                    // vbroadcastss  (%rax),%ymm1
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,98,125,184,193                  // vfmadd231ps   %ymm1,%ymm0,%ymm8
  .byte  196,226,125,24,80,4                 // vbroadcastss  0x4(%rax),%ymm2
  .byte  196,226,125,24,72,20                // vbroadcastss  0x14(%rax),%ymm1
  .byte  196,226,125,184,202                 // vfmadd231ps   %ymm2,%ymm0,%ymm1
  .byte  196,226,125,24,88,8                 // vbroadcastss  0x8(%rax),%ymm3
  .byte  196,226,125,24,80,24                // vbroadcastss  0x18(%rax),%ymm2
  .byte  196,226,125,184,211                 // vfmadd231ps   %ymm3,%ymm0,%ymm2
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,226,125,24,88,28                // vbroadcastss  0x1c(%rax),%ymm3
  .byte  196,194,125,184,217                 // vfmadd231ps   %ymm9,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_hsw
.globl _sk_save_xy_hsw
_sk_save_xy_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,88,200                       // vaddps        %ymm0,%ymm8,%ymm9
  .byte  196,67,125,8,209,1                  // vroundps      $0x1,%ymm9,%ymm10
  .byte  196,65,52,92,202                    // vsubps        %ymm10,%ymm9,%ymm9
  .byte  197,60,88,193                       // vaddps        %ymm1,%ymm8,%ymm8
  .byte  196,67,125,8,208,1                  // vroundps      $0x1,%ymm8,%ymm10
  .byte  196,65,60,92,194                    // vsubps        %ymm10,%ymm8,%ymm8
  .byte  197,252,17,0                        // vmovups       %ymm0,(%rax)
  .byte  197,252,17,72,32                    // vmovups       %ymm1,0x20(%rax)
  .byte  197,124,17,72,64                    // vmovups       %ymm9,0x40(%rax)
  .byte  197,124,17,64,96                    // vmovups       %ymm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_hsw
.globl _sk_accumulate_hsw
_sk_accumulate_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,16,128,128,0,0,0            // vmovups       0x80(%rax),%ymm8
  .byte  197,60,89,128,160,0,0,0             // vmulps        0xa0(%rax),%ymm8,%ymm8
  .byte  196,226,61,184,224                  // vfmadd231ps   %ymm0,%ymm8,%ymm4
  .byte  196,226,61,184,233                  // vfmadd231ps   %ymm1,%ymm8,%ymm5
  .byte  196,226,61,184,242                  // vfmadd231ps   %ymm2,%ymm8,%ymm6
  .byte  196,98,101,168,199                  // vfmadd213ps   %ymm7,%ymm3,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,199                      // vmovaps       %ymm8,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_hsw
.globl _sk_bilinear_nx_hsw
_sk_bilinear_nx_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_hsw
.globl _sk_bilinear_px_hsw
_sk_bilinear_px_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_hsw
.globl _sk_bilinear_ny_hsw
_sk_bilinear_ny_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_hsw
.globl _sk_bilinear_py_hsw
_sk_bilinear_py_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_hsw
.globl _sk_bicubic_n3x_hsw
_sk_bicubic_n3x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,44,89,193                    // vmulps        %ymm9,%ymm10,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_hsw
.globl _sk_bicubic_n1x_hsw
_sk_bicubic_n1x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,168,202                   // vfmadd213ps   %ymm10,%ymm8,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,184,209                   // vfmadd231ps   %ymm9,%ymm8,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,66,61,184,202                   // vfmadd231ps   %ymm10,%ymm8,%ymm9
  .byte  197,124,17,136,128,0,0,0            // vmovups       %ymm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_hsw
.globl _sk_bicubic_p1x_hsw
_sk_bicubic_p1x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,98,125,88,192                   // vpbroadcastd  %xmm0,%ymm8
  .byte  197,188,88,0                        // vaddps        (%rax),%ymm8,%ymm0
  .byte  197,124,16,72,64                    // vmovups       0x40(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,53,168,211                   // vfmadd213ps   %ymm11,%ymm9,%ymm10
  .byte  196,66,53,168,208                   // vfmadd213ps   %ymm8,%ymm9,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,66,53,184,194                   // vfmadd231ps   %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_hsw
.globl _sk_bicubic_p3x_hsw
_sk_bicubic_p3x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,52,89,194                    // vmulps        %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_hsw
.globl _sk_bicubic_n3y_hsw
_sk_bicubic_n3y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,44,89,193                    // vmulps        %ymm9,%ymm10,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_hsw
.globl _sk_bicubic_n1y_hsw
_sk_bicubic_n1y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,168,202                   // vfmadd213ps   %ymm10,%ymm8,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,184,209                   // vfmadd231ps   %ymm9,%ymm8,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,66,61,184,202                   // vfmadd231ps   %ymm10,%ymm8,%ymm9
  .byte  197,124,17,136,160,0,0,0            // vmovups       %ymm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_hsw
.globl _sk_bicubic_p1y_hsw
_sk_bicubic_p1y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  197,188,88,72,32                    // vaddps        0x20(%rax),%ymm8,%ymm1
  .byte  197,124,16,72,96                    // vmovups       0x60(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,53,168,211                   // vfmadd213ps   %ymm11,%ymm9,%ymm10
  .byte  196,66,53,168,208                   // vfmadd213ps   %ymm8,%ymm9,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,66,53,184,194                   // vfmadd231ps   %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_hsw
.globl _sk_bicubic_p3y_hsw
_sk_bicubic_p3y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,52,89,194                    // vmulps        %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_start_pipeline_avx
.globl _sk_start_pipeline_avx
_sk_start_pipeline_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,205                          // mov           %rcx,%r13
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,199                          // mov           %rax,%r15
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  72,141,67,8                         // lea           0x8(%rbx),%rax
  .byte  76,57,232                           // cmp           %r13,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_avx+0x28>
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  235,65                              // jmp           69 <_sk_start_pipeline_avx+0x69>
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  72,141,123,8                        // lea           0x8(%rbx),%rdi
  .byte  72,131,195,16                       // add           $0x10,%rbx
  .byte  76,57,235                           // cmp           %r13,%rbx
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  118,191                             // jbe           28 <_sk_start_pipeline_avx+0x28>
  .byte  76,137,233                          // mov           %r13,%rcx
  .byte  72,41,249                           // sub           %rdi,%rcx
  .byte  116,41                              // je            9a <_sk_start_pipeline_avx+0x9a>
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  76,137,232                          // mov           %r13,%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  197,248,119                         // vzeroupper
  .byte  195                                 // retq

HIDDEN _sk_just_return_avx
.globl _sk_just_return_avx
_sk_just_return_avx:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_avx
.globl _sk_seed_shader_avx
_sk_seed_shader_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,249,110,199                     // vmovd         %edi,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  197,252,88,2                        // vaddps        (%rdx),%ymm0,%ymm0
  .byte  196,226,125,24,16                   // vbroadcastss  (%rax),%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,236,88,201                      // vaddps        %ymm1,%ymm2,%ymm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_avx
.globl _sk_constant_color_avx
_sk_constant_color_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  196,226,125,24,88,12                // vbroadcastss  0xc(%rax),%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_avx
.globl _sk_clear_avx
_sk_clear_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_avx
.globl _sk_srcatop_avx
_sk_srcatop_avx:
  .byte  197,124,89,199                      // vmulps        %ymm7,%ymm0,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,124,92,203                      // vsubps        %ymm3,%ymm0,%ymm9
  .byte  197,180,89,196                      // vmulps        %ymm4,%ymm9,%ymm0
  .byte  197,188,88,192                      // vaddps        %ymm0,%ymm8,%ymm0
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,52,89,197                       // vmulps        %ymm5,%ymm9,%ymm8
  .byte  196,193,116,88,200                  // vaddps        %ymm8,%ymm1,%ymm1
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,52,89,198                       // vmulps        %ymm6,%ymm9,%ymm8
  .byte  196,193,108,88,208                  // vaddps        %ymm8,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  197,52,89,199                       // vmulps        %ymm7,%ymm9,%ymm8
  .byte  196,193,100,88,216                  // vaddps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_avx
.globl _sk_dstatop_avx
_sk_dstatop_avx:
  .byte  197,100,89,196                      // vmulps        %ymm4,%ymm3,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  197,52,92,207                       // vsubps        %ymm7,%ymm9,%ymm9
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,188,88,192                      // vaddps        %ymm0,%ymm8,%ymm0
  .byte  197,100,89,197                      // vmulps        %ymm5,%ymm3,%ymm8
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  197,188,88,201                      // vaddps        %ymm1,%ymm8,%ymm1
  .byte  197,100,89,198                      // vmulps        %ymm6,%ymm3,%ymm8
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  197,188,88,210                      // vaddps        %ymm2,%ymm8,%ymm2
  .byte  197,100,89,199                      // vmulps        %ymm7,%ymm3,%ymm8
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_avx
.globl _sk_srcin_avx
_sk_srcin_avx:
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_avx
.globl _sk_dstin_avx
_sk_dstin_avx:
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_avx
.globl _sk_srcout_avx
_sk_srcout_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_avx
.globl _sk_dstout_avx
_sk_dstout_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,92,219                      // vsubps        %ymm3,%ymm0,%ymm3
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_avx
.globl _sk_srcover_avx
_sk_srcover_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,204                       // vmulps        %ymm4,%ymm8,%ymm9
  .byte  197,180,88,192                      // vaddps        %ymm0,%ymm9,%ymm0
  .byte  197,60,89,205                       // vmulps        %ymm5,%ymm8,%ymm9
  .byte  197,180,88,201                      // vaddps        %ymm1,%ymm9,%ymm1
  .byte  197,60,89,206                       // vmulps        %ymm6,%ymm8,%ymm9
  .byte  197,180,88,210                      // vaddps        %ymm2,%ymm9,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_avx
.globl _sk_dstover_avx
_sk_dstover_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_avx
.globl _sk_modulate_avx
_sk_modulate_avx:
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_avx
.globl _sk_multiply_avx
_sk_multiply_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,52,89,208                       // vmulps        %ymm0,%ymm9,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,88,194                  // vaddps        %ymm10,%ymm0,%ymm0
  .byte  197,52,89,209                       // vmulps        %ymm1,%ymm9,%ymm10
  .byte  197,60,89,221                       // vmulps        %ymm5,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,88,202                  // vaddps        %ymm10,%ymm1,%ymm1
  .byte  197,52,89,210                       // vmulps        %ymm2,%ymm9,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  196,193,100,88,216                  // vaddps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__avx
.globl _sk_plus__avx
_sk_plus__avx:
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_avx
.globl _sk_screen_avx
_sk_screen_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  197,100,88,199                      // vaddps        %ymm7,%ymm3,%ymm8
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  197,188,92,219                      // vsubps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__avx
.globl _sk_xor__avx
_sk_xor__avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,212                       // vmulps        %ymm4,%ymm8,%ymm10
  .byte  196,193,124,88,194                  // vaddps        %ymm10,%ymm0,%ymm0
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  197,60,89,213                       // vmulps        %ymm5,%ymm8,%ymm10
  .byte  197,172,88,201                      // vaddps        %ymm1,%ymm10,%ymm1
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  197,60,89,214                       // vmulps        %ymm6,%ymm8,%ymm10
  .byte  197,172,88,210                      // vaddps        %ymm2,%ymm10,%ymm2
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_avx
.globl _sk_darken_avx
_sk_darken_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,95,193                  // vmaxps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,95,201                  // vmaxps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,95,209                  // vmaxps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_avx
.globl _sk_lighten_avx
_sk_lighten_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_avx
.globl _sk_difference_avx
_sk_difference_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_avx
.globl _sk_exclusion_avx
_sk_exclusion_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_avx
.globl _sk_colorburn_avx
_sk_colorburn_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,52,89,216                       // vmulps        %ymm0,%ymm9,%ymm11
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,228                       // vmulps        %ymm4,%ymm8,%ymm12
  .byte  197,68,92,236                       // vsubps        %ymm4,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,232                       // vdivps        %ymm0,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  196,65,20,88,235                    // vaddps        %ymm11,%ymm13,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,224                       // vaddps        %ymm0,%ymm12,%ymm12
  .byte  196,193,124,194,194,0               // vcmpeqps      %ymm10,%ymm0,%ymm0
  .byte  196,195,21,74,196,0                 // vblendvps     %ymm0,%ymm12,%ymm13,%ymm0
  .byte  197,92,194,231,0                    // vcmpeqps      %ymm7,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,52,89,217                       // vmulps        %ymm1,%ymm9,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  197,68,92,237                       // vsubps        %ymm5,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,233                       // vdivps        %ymm1,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  196,65,36,88,237                    // vaddps        %ymm13,%ymm11,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,225                       // vaddps        %ymm1,%ymm12,%ymm12
  .byte  196,193,116,194,202,0               // vcmpeqps      %ymm10,%ymm1,%ymm1
  .byte  196,195,21,74,204,16                // vblendvps     %ymm1,%ymm12,%ymm13,%ymm1
  .byte  197,84,194,231,0                    // vcmpeqps      %ymm7,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,52,89,202                       // vmulps        %ymm2,%ymm9,%ymm9
  .byte  196,65,108,194,210,0                // vcmpeqps      %ymm10,%ymm2,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  197,68,92,230                       // vsubps        %ymm6,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  197,28,94,226                       // vdivps        %ymm2,%ymm12,%ymm12
  .byte  197,164,88,210                      // vaddps        %ymm2,%ymm11,%ymm2
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,65,68,92,228                    // vsubps        %ymm12,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,52,88,228                    // vaddps        %ymm12,%ymm9,%ymm12
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,227,37,74,210,160               // vblendvps     %ymm10,%ymm2,%ymm11,%ymm2
  .byte  197,76,194,215,0                    // vcmpeqps      %ymm7,%ymm6,%ymm10
  .byte  197,52,88,206                       // vaddps        %ymm6,%ymm9,%ymm9
  .byte  196,195,109,74,209,160              // vblendvps     %ymm10,%ymm9,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_avx
.globl _sk_colordodge_avx
_sk_colordodge_avx:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  197,52,92,215                       // vsubps        %ymm7,%ymm9,%ymm10
  .byte  197,44,89,216                       // vmulps        %ymm0,%ymm10,%ymm11
  .byte  197,52,92,203                       // vsubps        %ymm3,%ymm9,%ymm9
  .byte  197,100,89,228                      // vmulps        %ymm4,%ymm3,%ymm12
  .byte  197,100,92,232                      // vsubps        %ymm0,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,236                       // vmulps        %ymm4,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,28,88,227                    // vaddps        %ymm11,%ymm12,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,232                       // vaddps        %ymm0,%ymm13,%ymm13
  .byte  197,252,194,195,0                   // vcmpeqps      %ymm3,%ymm0,%ymm0
  .byte  196,195,29,74,197,0                 // vblendvps     %ymm0,%ymm13,%ymm12,%ymm0
  .byte  196,65,92,194,224,0                 // vcmpeqps      %ymm8,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,100,89,229                      // vmulps        %ymm5,%ymm3,%ymm12
  .byte  197,100,92,233                      // vsubps        %ymm1,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,237                       // vmulps        %ymm5,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,28,88,227                    // vaddps        %ymm11,%ymm12,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,233                       // vaddps        %ymm1,%ymm13,%ymm13
  .byte  197,244,194,203,0                   // vcmpeqps      %ymm3,%ymm1,%ymm1
  .byte  196,195,29,74,205,16                // vblendvps     %ymm1,%ymm13,%ymm12,%ymm1
  .byte  196,65,84,194,224,0                 // vcmpeqps      %ymm8,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,100,89,222                      // vmulps        %ymm6,%ymm3,%ymm11
  .byte  197,100,92,226                      // vsubps        %ymm2,%ymm3,%ymm12
  .byte  196,65,36,94,220                    // vdivps        %ymm12,%ymm11,%ymm11
  .byte  197,52,89,230                       // vmulps        %ymm6,%ymm9,%ymm12
  .byte  196,65,68,93,219                    // vminps        %ymm11,%ymm7,%ymm11
  .byte  197,36,89,219                       // vmulps        %ymm3,%ymm11,%ymm11
  .byte  196,65,44,88,219                    // vaddps        %ymm11,%ymm10,%ymm11
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,28,88,226                       // vaddps        %ymm2,%ymm12,%ymm12
  .byte  197,236,194,211,0                   // vcmpeqps      %ymm3,%ymm2,%ymm2
  .byte  196,195,37,74,212,32                // vblendvps     %ymm2,%ymm12,%ymm11,%ymm2
  .byte  196,65,76,194,192,0                 // vcmpeqps      %ymm8,%ymm6,%ymm8
  .byte  197,44,88,214                       // vaddps        %ymm6,%ymm10,%ymm10
  .byte  196,195,109,74,210,128              // vblendvps     %ymm8,%ymm10,%ymm2,%ymm2
  .byte  197,52,89,199                       // vmulps        %ymm7,%ymm9,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_avx
.globl _sk_hardlight_avx
_sk_hardlight_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,44,89,200                       // vmulps        %ymm0,%ymm10,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,65,52,88,219                    // vaddps        %ymm11,%ymm9,%ymm11
  .byte  197,124,88,200                      // vaddps        %ymm0,%ymm0,%ymm9
  .byte  197,52,194,227,2                    // vcmpleps      %ymm3,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,116,88,225                      // vaddps        %ymm1,%ymm1,%ymm12
  .byte  197,28,194,227,2                    // vcmpleps      %ymm3,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,108,88,218                      // vaddps        %ymm2,%ymm2,%ymm11
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_avx
.globl _sk_overlay_avx
_sk_overlay_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,44,89,200                       // vmulps        %ymm0,%ymm10,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,65,52,88,219                    // vaddps        %ymm11,%ymm9,%ymm11
  .byte  197,92,88,204                       // vaddps        %ymm4,%ymm4,%ymm9
  .byte  197,52,194,231,2                    // vcmpleps      %ymm7,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,84,88,229                       // vaddps        %ymm5,%ymm5,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,76,88,222                       // vaddps        %ymm6,%ymm6,%ymm11
  .byte  197,36,194,223,2                    // vcmpleps      %ymm7,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_avx
.globl _sk_softlight_avx
_sk_softlight_avx:
  .byte  197,252,17,84,36,200                // vmovups       %ymm2,-0x38(%rsp)
  .byte  197,252,40,209                      // vmovaps       %ymm1,%ymm2
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  197,52,194,215,1                    // vcmpltps      %ymm7,%ymm9,%ymm10
  .byte  197,92,94,199                       // vdivps        %ymm7,%ymm4,%ymm8
  .byte  196,67,53,74,216,160                // vblendvps     %ymm10,%ymm8,%ymm9,%ymm11
  .byte  196,65,36,88,195                    // vaddps        %ymm11,%ymm11,%ymm8
  .byte  196,65,60,88,224                    // vaddps        %ymm8,%ymm8,%ymm12
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,28,89,236                    // vmulps        %ymm12,%ymm12,%ymm13
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  196,65,36,92,232                    // vsubps        %ymm8,%ymm11,%ymm13
  .byte  196,65,28,89,237                    // vmulps        %ymm13,%ymm12,%ymm13
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,67,121,4,228,0                  // vpermilps     $0x0,%xmm12,%xmm12
  .byte  196,67,29,24,228,1                  // vinsertf128   $0x1,%xmm12,%ymm12,%ymm12
  .byte  196,65,36,89,244                    // vmulps        %ymm12,%ymm11,%ymm14
  .byte  196,65,20,88,238                    // vaddps        %ymm14,%ymm13,%ymm13
  .byte  196,65,124,82,243                   // vrsqrtps      %ymm11,%ymm14
  .byte  196,65,124,83,246                   // vrcpps        %ymm14,%ymm14
  .byte  196,65,12,92,243                    // vsubps        %ymm11,%ymm14,%ymm14
  .byte  197,92,88,252                       // vaddps        %ymm4,%ymm4,%ymm15
  .byte  196,65,4,88,255                     // vaddps        %ymm15,%ymm15,%ymm15
  .byte  197,4,194,255,2                     // vcmpleps      %ymm7,%ymm15,%ymm15
  .byte  196,67,13,74,237,240                // vblendvps     %ymm15,%ymm13,%ymm14,%ymm13
  .byte  197,124,88,240                      // vaddps        %ymm0,%ymm0,%ymm14
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,65,60,92,219                    // vsubps        %ymm11,%ymm8,%ymm11
  .byte  196,65,4,89,219                     // vmulps        %ymm11,%ymm15,%ymm11
  .byte  197,36,88,219                       // vaddps        %ymm3,%ymm11,%ymm11
  .byte  197,36,89,220                       // vmulps        %ymm4,%ymm11,%ymm11
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,237                     // vmulps        %ymm13,%ymm15,%ymm13
  .byte  197,100,89,252                      // vmulps        %ymm4,%ymm3,%ymm15
  .byte  196,65,4,88,237                     // vaddps        %ymm13,%ymm15,%ymm13
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,195,21,74,203,224               // vblendvps     %ymm14,%ymm11,%ymm13,%ymm1
  .byte  197,84,94,239                       // vdivps        %ymm7,%ymm5,%ymm13
  .byte  196,67,53,74,237,160                // vblendvps     %ymm10,%ymm13,%ymm9,%ymm13
  .byte  196,65,20,88,245                    // vaddps        %ymm13,%ymm13,%ymm14
  .byte  196,65,12,88,246                    // vaddps        %ymm14,%ymm14,%ymm14
  .byte  196,65,12,89,254                    // vmulps        %ymm14,%ymm14,%ymm15
  .byte  196,65,12,88,247                    // vaddps        %ymm15,%ymm14,%ymm14
  .byte  196,65,20,92,248                    // vsubps        %ymm8,%ymm13,%ymm15
  .byte  196,65,4,89,246                     // vmulps        %ymm14,%ymm15,%ymm14
  .byte  196,65,28,89,253                    // vmulps        %ymm13,%ymm12,%ymm15
  .byte  196,65,4,88,246                     // vaddps        %ymm14,%ymm15,%ymm14
  .byte  196,65,124,82,253                   // vrsqrtps      %ymm13,%ymm15
  .byte  196,65,124,83,255                   // vrcpps        %ymm15,%ymm15
  .byte  196,65,4,92,253                     // vsubps        %ymm13,%ymm15,%ymm15
  .byte  197,84,88,221                       // vaddps        %ymm5,%ymm5,%ymm11
  .byte  196,65,36,88,219                    // vaddps        %ymm11,%ymm11,%ymm11
  .byte  197,36,194,223,2                    // vcmpleps      %ymm7,%ymm11,%ymm11
  .byte  196,67,5,74,222,176                 // vblendvps     %ymm11,%ymm14,%ymm15,%ymm11
  .byte  197,108,88,242                      // vaddps        %ymm2,%ymm2,%ymm14
  .byte  196,65,60,92,237                    // vsubps        %ymm13,%ymm8,%ymm13
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,65,4,89,237                     // vmulps        %ymm13,%ymm15,%ymm13
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,219                     // vmulps        %ymm11,%ymm15,%ymm11
  .byte  197,100,89,253                      // vmulps        %ymm5,%ymm3,%ymm15
  .byte  196,65,4,88,219                     // vaddps        %ymm11,%ymm15,%ymm11
  .byte  197,20,88,235                       // vaddps        %ymm3,%ymm13,%ymm13
  .byte  197,20,89,237                       // vmulps        %ymm5,%ymm13,%ymm13
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,67,37,74,237,224                // vblendvps     %ymm14,%ymm13,%ymm11,%ymm13
  .byte  197,76,94,223                       // vdivps        %ymm7,%ymm6,%ymm11
  .byte  196,67,53,74,203,160                // vblendvps     %ymm10,%ymm11,%ymm9,%ymm9
  .byte  196,65,52,88,209                    // vaddps        %ymm9,%ymm9,%ymm10
  .byte  196,65,44,88,210                    // vaddps        %ymm10,%ymm10,%ymm10
  .byte  196,65,44,89,218                    // vmulps        %ymm10,%ymm10,%ymm11
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,92,216                    // vsubps        %ymm8,%ymm9,%ymm11
  .byte  196,65,36,89,210                    // vmulps        %ymm10,%ymm11,%ymm10
  .byte  196,65,28,89,217                    // vmulps        %ymm9,%ymm12,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  196,65,124,82,217                   // vrsqrtps      %ymm9,%ymm11
  .byte  196,65,124,83,219                   // vrcpps        %ymm11,%ymm11
  .byte  196,65,36,92,217                    // vsubps        %ymm9,%ymm11,%ymm11
  .byte  197,76,88,230                       // vaddps        %ymm6,%ymm6,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  196,67,37,74,210,192                // vblendvps     %ymm12,%ymm10,%ymm11,%ymm10
  .byte  197,124,16,116,36,200               // vmovups       -0x38(%rsp),%ymm14
  .byte  196,65,12,88,222                    // vaddps        %ymm14,%ymm14,%ymm11
  .byte  197,36,92,227                       // vsubps        %ymm3,%ymm11,%ymm12
  .byte  196,65,60,92,201                    // vsubps        %ymm9,%ymm8,%ymm9
  .byte  196,65,28,89,201                    // vmulps        %ymm9,%ymm12,%ymm9
  .byte  197,28,89,231                       // vmulps        %ymm7,%ymm12,%ymm12
  .byte  196,65,28,89,210                    // vmulps        %ymm10,%ymm12,%ymm10
  .byte  197,100,89,230                      // vmulps        %ymm6,%ymm3,%ymm12
  .byte  196,65,28,88,210                    // vaddps        %ymm10,%ymm12,%ymm10
  .byte  197,52,88,203                       // vaddps        %ymm3,%ymm9,%ymm9
  .byte  197,52,89,206                       // vmulps        %ymm6,%ymm9,%ymm9
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  196,67,45,74,201,176                // vblendvps     %ymm11,%ymm9,%ymm10,%ymm9
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,244,88,192                      // vaddps        %ymm0,%ymm1,%ymm0
  .byte  197,172,89,202                      // vmulps        %ymm2,%ymm10,%ymm1
  .byte  197,188,89,213                      // vmulps        %ymm5,%ymm8,%ymm2
  .byte  197,236,88,201                      // vaddps        %ymm1,%ymm2,%ymm1
  .byte  196,193,116,88,205                  // vaddps        %ymm13,%ymm1,%ymm1
  .byte  196,193,44,89,214                   // vmulps        %ymm14,%ymm10,%ymm2
  .byte  197,60,89,214                       // vmulps        %ymm6,%ymm8,%ymm10
  .byte  197,172,88,210                      // vaddps        %ymm2,%ymm10,%ymm2
  .byte  196,193,108,88,209                  // vaddps        %ymm9,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_avx
.globl _sk_clamp_0_avx
_sk_clamp_0_avx:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,95,216                  // vmaxps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_avx
.globl _sk_clamp_1_avx
_sk_clamp_1_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,93,208                  // vminps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_avx
.globl _sk_clamp_a_avx
_sk_clamp_a_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  197,252,93,195                      // vminps        %ymm3,%ymm0,%ymm0
  .byte  197,244,93,203                      // vminps        %ymm3,%ymm1,%ymm1
  .byte  197,236,93,211                      // vminps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_avx
.globl _sk_set_rgb_avx
_sk_set_rgb_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_avx
.globl _sk_swap_rb_avx
_sk_swap_rb_avx:
  .byte  197,124,40,192                      // vmovaps       %ymm0,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,194                      // vmovaps       %ymm2,%ymm0
  .byte  197,124,41,194                      // vmovaps       %ymm8,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_avx
.globl _sk_swap_avx
_sk_swap_avx:
  .byte  197,124,40,195                      // vmovaps       %ymm3,%ymm8
  .byte  197,124,40,202                      // vmovaps       %ymm2,%ymm9
  .byte  197,124,40,209                      // vmovaps       %ymm1,%ymm10
  .byte  197,124,40,216                      // vmovaps       %ymm0,%ymm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  197,124,41,220                      // vmovaps       %ymm11,%ymm4
  .byte  197,124,41,213                      // vmovaps       %ymm10,%ymm5
  .byte  197,124,41,206                      // vmovaps       %ymm9,%ymm6
  .byte  197,124,41,199                      // vmovaps       %ymm8,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_avx
.globl _sk_move_src_dst_avx
_sk_move_src_dst_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,224                      // vmovaps       %ymm0,%ymm4
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  197,252,40,242                      // vmovaps       %ymm2,%ymm6
  .byte  197,252,40,251                      // vmovaps       %ymm3,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_avx
.globl _sk_move_dst_src_avx
_sk_move_dst_src_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_avx
.globl _sk_premul_avx
_sk_premul_avx:
  .byte  197,252,89,195                      // vmulps        %ymm3,%ymm0,%ymm0
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_avx
.globl _sk_unpremul_avx
_sk_unpremul_avx:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,100,194,200,0                // vcmpeqps      %ymm8,%ymm3,%ymm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  197,44,94,211                       // vdivps        %ymm3,%ymm10,%ymm10
  .byte  196,67,45,74,192,144                // vblendvps     %ymm9,%ymm8,%ymm10,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_avx
.globl _sk_from_srgb_avx
_sk_from_srgb_avx:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  197,124,89,208                      // vmulps        %ymm0,%ymm0,%ymm10
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,67,121,4,228,0                  // vpermilps     $0x0,%xmm12,%xmm12
  .byte  196,67,29,24,228,1                  // vinsertf128   $0x1,%xmm12,%ymm12,%ymm12
  .byte  197,36,89,232                       // vmulps        %ymm0,%ymm11,%ymm13
  .byte  196,65,20,88,236                    // vaddps        %ymm12,%ymm13,%ymm13
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,65,44,89,213                    // vmulps        %ymm13,%ymm10,%ymm10
  .byte  196,65,12,88,210                    // vaddps        %ymm10,%ymm14,%ymm10
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  197,121,110,232                     // vmovd         %eax,%xmm13
  .byte  196,67,121,4,237,0                  // vpermilps     $0x0,%xmm13,%xmm13
  .byte  196,67,21,24,237,1                  // vinsertf128   $0x1,%xmm13,%ymm13,%ymm13
  .byte  196,193,124,194,197,1               // vcmpltps      %ymm13,%ymm0,%ymm0
  .byte  196,195,45,74,193,0                 // vblendvps     %ymm0,%ymm9,%ymm10,%ymm0
  .byte  197,60,89,201                       // vmulps        %ymm1,%ymm8,%ymm9
  .byte  197,116,89,209                      // vmulps        %ymm1,%ymm1,%ymm10
  .byte  197,36,89,249                       // vmulps        %ymm1,%ymm11,%ymm15
  .byte  196,65,28,88,255                    // vaddps        %ymm15,%ymm12,%ymm15
  .byte  196,65,44,89,215                    // vmulps        %ymm15,%ymm10,%ymm10
  .byte  196,65,12,88,210                    // vaddps        %ymm10,%ymm14,%ymm10
  .byte  196,193,116,194,205,1               // vcmpltps      %ymm13,%ymm1,%ymm1
  .byte  196,195,45,74,201,16                // vblendvps     %ymm1,%ymm9,%ymm10,%ymm1
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  197,108,89,202                      // vmulps        %ymm2,%ymm2,%ymm9
  .byte  197,36,89,210                       // vmulps        %ymm2,%ymm11,%ymm10
  .byte  196,65,28,88,210                    // vaddps        %ymm10,%ymm12,%ymm10
  .byte  196,65,52,89,202                    // vmulps        %ymm10,%ymm9,%ymm9
  .byte  196,65,12,88,201                    // vaddps        %ymm9,%ymm14,%ymm9
  .byte  196,193,108,194,213,1               // vcmpltps      %ymm13,%ymm2,%ymm2
  .byte  196,195,53,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_avx
.globl _sk_to_srgb_avx
_sk_to_srgb_avx:
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,83,232                   // vrcpps        %ymm8,%ymm13
  .byte  196,65,124,82,240                   // vrsqrtps      %ymm8,%ymm14
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,224                       // vmulps        %ymm0,%ymm8,%ymm12
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  197,121,110,248                     // vmovd         %eax,%xmm15
  .byte  196,67,121,4,255,0                  // vpermilps     $0x0,%xmm15,%xmm15
  .byte  196,67,5,24,255,1                   // vinsertf128   $0x1,%xmm15,%ymm15,%ymm15
  .byte  196,65,20,89,235                    // vmulps        %ymm11,%ymm13,%ymm13
  .byte  196,65,20,88,239                    // vaddps        %ymm15,%ymm13,%ymm13
  .byte  196,65,12,89,242                    // vmulps        %ymm10,%ymm14,%ymm14
  .byte  196,65,12,88,237                    // vaddps        %ymm13,%ymm14,%ymm13
  .byte  196,65,52,93,237                    // vminps        %ymm13,%ymm9,%ymm13
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,193,124,194,198,1               // vcmpltps      %ymm14,%ymm0,%ymm0
  .byte  196,195,21,74,196,0                 // vblendvps     %ymm0,%ymm12,%ymm13,%ymm0
  .byte  197,124,82,225                      // vrsqrtps      %ymm1,%ymm12
  .byte  196,65,124,83,236                   // vrcpps        %ymm12,%ymm13
  .byte  196,65,124,82,228                   // vrsqrtps      %ymm12,%ymm12
  .byte  196,65,36,89,237                    // vmulps        %ymm13,%ymm11,%ymm13
  .byte  196,65,4,88,237                     // vaddps        %ymm13,%ymm15,%ymm13
  .byte  196,65,44,89,228                    // vmulps        %ymm12,%ymm10,%ymm12
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  197,60,89,233                       // vmulps        %ymm1,%ymm8,%ymm13
  .byte  196,65,52,93,228                    // vminps        %ymm12,%ymm9,%ymm12
  .byte  196,193,116,194,206,1               // vcmpltps      %ymm14,%ymm1,%ymm1
  .byte  196,195,29,74,205,16                // vblendvps     %ymm1,%ymm13,%ymm12,%ymm1
  .byte  197,124,82,226                      // vrsqrtps      %ymm2,%ymm12
  .byte  196,65,124,83,236                   // vrcpps        %ymm12,%ymm13
  .byte  196,65,36,89,221                    // vmulps        %ymm13,%ymm11,%ymm11
  .byte  196,65,4,88,219                     // vaddps        %ymm11,%ymm15,%ymm11
  .byte  196,65,124,82,228                   // vrsqrtps      %ymm12,%ymm12
  .byte  196,65,44,89,212                    // vmulps        %ymm12,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,93,202                    // vminps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,193,108,194,214,1               // vcmpltps      %ymm14,%ymm2,%ymm2
  .byte  196,195,53,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_2dot2_avx
.globl _sk_from_2dot2_avx
_sk_from_2dot2_avx:
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,200                   // vrsqrtps      %ymm8,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  197,252,89,192                      // vmulps        %ymm0,%ymm0,%ymm0
  .byte  196,65,60,89,208                    // vmulps        %ymm8,%ymm8,%ymm10
  .byte  196,65,60,89,194                    // vmulps        %ymm10,%ymm8,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  197,124,82,201                      // vrsqrtps      %ymm1,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  196,65,124,82,210                   // vrsqrtps      %ymm10,%ymm10
  .byte  197,244,89,201                      // vmulps        %ymm1,%ymm1,%ymm1
  .byte  196,65,52,89,217                    // vmulps        %ymm9,%ymm9,%ymm11
  .byte  196,65,52,89,203                    // vmulps        %ymm11,%ymm9,%ymm9
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  197,124,82,202                      // vrsqrtps      %ymm2,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  196,65,124,82,210                   // vrsqrtps      %ymm10,%ymm10
  .byte  197,236,89,210                      // vmulps        %ymm2,%ymm2,%ymm2
  .byte  196,65,52,89,217                    // vmulps        %ymm9,%ymm9,%ymm11
  .byte  196,65,52,89,203                    // vmulps        %ymm11,%ymm9,%ymm9
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_2dot2_avx
.globl _sk_to_2dot2_avx
_sk_to_2dot2_avx:
  .byte  197,252,82,192                      // vrsqrtps      %ymm0,%ymm0
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,192                   // vrsqrtps      %ymm8,%ymm8
  .byte  196,65,124,82,200                   // vrsqrtps      %ymm8,%ymm9
  .byte  197,252,83,192                      // vrcpps        %ymm0,%ymm0
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  196,65,124,83,193                   // vrcpps        %ymm9,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  197,252,82,201                      // vrsqrtps      %ymm1,%ymm1
  .byte  197,124,82,201                      // vrsqrtps      %ymm1,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  197,252,83,201                      // vrcpps        %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  196,65,124,83,202                   // vrcpps        %ymm10,%ymm9
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  197,252,82,210                      // vrsqrtps      %ymm2,%ymm2
  .byte  197,124,82,202                      // vrsqrtps      %ymm2,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,201                   // vrsqrtps      %ymm9,%ymm9
  .byte  196,65,124,82,209                   // vrsqrtps      %ymm9,%ymm10
  .byte  197,252,83,210                      // vrcpps        %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  196,65,124,83,202                   // vrcpps        %ymm10,%ymm9
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_avx
.globl _sk_rgb_to_hsl_avx
_sk_rgb_to_hsl_avx:
  .byte  197,124,95,193                      // vmaxps        %ymm1,%ymm0,%ymm8
  .byte  197,60,95,194                       // vmaxps        %ymm2,%ymm8,%ymm8
  .byte  197,124,93,201                      // vminps        %ymm1,%ymm0,%ymm9
  .byte  197,52,93,202                       // vminps        %ymm2,%ymm9,%ymm9
  .byte  196,65,60,92,209                    // vsubps        %ymm9,%ymm8,%ymm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,36,94,218                    // vdivps        %ymm10,%ymm11,%ymm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  197,116,92,226                      // vsubps        %ymm2,%ymm1,%ymm12
  .byte  196,65,28,89,227                    // vmulps        %ymm11,%ymm12,%ymm12
  .byte  65,185,0,0,192,64                   // mov           $0x40c00000,%r9d
  .byte  197,108,92,232                      // vsubps        %ymm0,%ymm2,%ymm13
  .byte  196,65,20,89,235                    // vmulps        %ymm11,%ymm13,%ymm13
  .byte  65,186,0,0,0,64                     // mov           $0x40000000,%r10d
  .byte  197,124,92,241                      // vsubps        %ymm1,%ymm0,%ymm14
  .byte  196,65,12,89,219                    // vmulps        %ymm11,%ymm14,%ymm11
  .byte  184,0,0,128,64                      // mov           $0x40800000,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,65,36,88,222                    // vaddps        %ymm14,%ymm11,%ymm11
  .byte  196,65,121,110,242                  // vmovd         %r10d,%xmm14
  .byte  197,244,194,210,1                   // vcmpltps      %ymm2,%ymm1,%ymm2
  .byte  197,188,194,201,0                   // vcmpeqps      %ymm1,%ymm8,%ymm1
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,65,20,88,238                    // vaddps        %ymm14,%ymm13,%ymm13
  .byte  196,67,37,74,221,16                 // vblendvps     %ymm1,%ymm13,%ymm11,%ymm11
  .byte  196,193,121,110,201                 // vmovd         %r9d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  196,65,20,87,237                    // vxorps        %ymm13,%ymm13,%ymm13
  .byte  196,227,21,74,201,32                // vblendvps     %ymm2,%ymm1,%ymm13,%ymm1
  .byte  196,193,116,88,204                  // vaddps        %ymm12,%ymm1,%ymm1
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,188,194,192,0                   // vcmpeqps      %ymm0,%ymm8,%ymm0
  .byte  196,227,37,74,193,0                 // vblendvps     %ymm0,%ymm1,%ymm11,%ymm0
  .byte  196,193,60,88,201                   // vaddps        %ymm9,%ymm8,%ymm1
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,99,109,24,218,1                 // vinsertf128   $0x1,%xmm2,%ymm2,%ymm11
  .byte  196,193,116,89,211                  // vmulps        %ymm11,%ymm1,%ymm2
  .byte  197,36,194,218,1                    // vcmpltps      %ymm2,%ymm11,%ymm11
  .byte  196,65,12,92,224                    // vsubps        %ymm8,%ymm14,%ymm12
  .byte  196,65,28,92,225                    // vsubps        %ymm9,%ymm12,%ymm12
  .byte  196,195,117,74,204,176              // vblendvps     %ymm11,%ymm12,%ymm1,%ymm1
  .byte  196,65,60,194,193,0                 // vcmpeqps      %ymm9,%ymm8,%ymm8
  .byte  197,172,94,201                      // vdivps        %ymm1,%ymm10,%ymm1
  .byte  196,67,125,74,205,128               // vblendvps     %ymm8,%ymm13,%ymm0,%ymm9
  .byte  196,195,117,74,205,128              // vblendvps     %ymm8,%ymm13,%ymm1,%ymm1
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_avx
.globl _sk_hsl_to_rgb_avx
_sk_hsl_to_rgb_avx:
  .byte  72,131,236,56                       // sub           $0x38,%rsp
  .byte  197,252,17,60,36                    // vmovups       %ymm7,(%rsp)
  .byte  197,252,17,116,36,224               // vmovups       %ymm6,-0x20(%rsp)
  .byte  197,252,17,108,36,192               // vmovups       %ymm5,-0x40(%rsp)
  .byte  197,252,17,100,36,160               // vmovups       %ymm4,-0x60(%rsp)
  .byte  197,252,17,92,36,128                // vmovups       %ymm3,-0x80(%rsp)
  .byte  197,252,40,226                      // vmovaps       %ymm2,%ymm4
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  197,252,40,216                      // vmovaps       %ymm0,%ymm3
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm8
  .byte  196,193,92,194,192,1                // vcmpltps      %ymm8,%ymm4,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,99,109,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm2,%ymm10
  .byte  197,172,88,213                      // vaddps        %ymm5,%ymm10,%ymm2
  .byte  197,236,89,212                      // vmulps        %ymm4,%ymm2,%ymm2
  .byte  197,84,88,204                       // vaddps        %ymm4,%ymm5,%ymm9
  .byte  197,84,89,220                       // vmulps        %ymm4,%ymm5,%ymm11
  .byte  196,65,52,92,203                    // vsubps        %ymm11,%ymm9,%ymm9
  .byte  196,99,53,74,202,0                  // vblendvps     %ymm0,%ymm2,%ymm9,%ymm9
  .byte  65,184,0,0,0,64                     // mov           $0x40000000,%r8d
  .byte  184,171,170,170,62                  // mov           $0x3eaaaaab,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,224,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm12
  .byte  197,28,88,251                       // vaddps        %ymm3,%ymm12,%ymm15
  .byte  184,0,0,0,0                         // mov           $0x0,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,232,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm13
  .byte  196,193,44,194,199,1                // vcmpltps      %ymm15,%ymm10,%ymm0
  .byte  196,193,4,92,210                    // vsubps        %ymm10,%ymm15,%ymm2
  .byte  196,227,5,74,194,0                  // vblendvps     %ymm0,%ymm2,%ymm15,%ymm0
  .byte  196,193,4,194,213,1                 // vcmpltps      %ymm13,%ymm15,%ymm2
  .byte  196,65,44,88,223                    // vaddps        %ymm15,%ymm10,%ymm11
  .byte  196,195,125,74,203,32               // vblendvps     %ymm2,%ymm11,%ymm0,%ymm1
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  196,65,124,92,217                   // vsubps        %ymm9,%ymm0,%ymm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  184,0,0,192,64                      // mov           $0x40c00000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,52,92,211                   // vsubps        %ymm11,%ymm9,%ymm2
  .byte  197,108,89,240                      // vmulps        %ymm0,%ymm2,%ymm14
  .byte  184,171,170,42,63                   // mov           $0x3f2aaaab,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,92,209                      // vsubps        %ymm1,%ymm0,%ymm2
  .byte  197,140,89,210                      // vmulps        %ymm2,%ymm14,%ymm2
  .byte  197,164,88,210                      // vaddps        %ymm2,%ymm11,%ymm2
  .byte  197,244,194,248,1                   // vcmpltps      %ymm0,%ymm1,%ymm7
  .byte  196,227,37,74,210,112               // vblendvps     %ymm7,%ymm2,%ymm11,%ymm2
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,109,74,249,112              // vblendvps     %ymm7,%ymm9,%ymm2,%ymm7
  .byte  196,193,121,110,208                 // vmovd         %r8d,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,244,194,202,1                   // vcmpltps      %ymm2,%ymm1,%ymm1
  .byte  196,65,4,89,254                     // vmulps        %ymm14,%ymm15,%ymm15
  .byte  196,65,36,88,255                    // vaddps        %ymm15,%ymm11,%ymm15
  .byte  196,67,69,74,255,16                 // vblendvps     %ymm1,%ymm15,%ymm7,%ymm15
  .byte  197,172,194,203,1                   // vcmpltps      %ymm3,%ymm10,%ymm1
  .byte  196,193,100,92,250                  // vsubps        %ymm10,%ymm3,%ymm7
  .byte  196,227,101,74,207,16               // vblendvps     %ymm1,%ymm7,%ymm3,%ymm1
  .byte  196,193,100,194,253,1               // vcmpltps      %ymm13,%ymm3,%ymm7
  .byte  197,172,88,243                      // vaddps        %ymm3,%ymm10,%ymm6
  .byte  196,227,117,74,206,112              // vblendvps     %ymm7,%ymm6,%ymm1,%ymm1
  .byte  197,252,92,241                      // vsubps        %ymm1,%ymm0,%ymm6
  .byte  197,140,89,246                      // vmulps        %ymm6,%ymm14,%ymm6
  .byte  197,164,88,246                      // vaddps        %ymm6,%ymm11,%ymm6
  .byte  197,244,194,248,1                   // vcmpltps      %ymm0,%ymm1,%ymm7
  .byte  196,227,37,74,246,112               // vblendvps     %ymm7,%ymm6,%ymm11,%ymm6
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,77,74,241,112               // vblendvps     %ymm7,%ymm9,%ymm6,%ymm6
  .byte  197,244,194,202,1                   // vcmpltps      %ymm2,%ymm1,%ymm1
  .byte  197,140,89,251                      // vmulps        %ymm3,%ymm14,%ymm7
  .byte  197,164,88,255                      // vaddps        %ymm7,%ymm11,%ymm7
  .byte  196,227,77,74,207,16                // vblendvps     %ymm1,%ymm7,%ymm6,%ymm1
  .byte  196,193,100,92,220                  // vsubps        %ymm12,%ymm3,%ymm3
  .byte  197,172,194,243,1                   // vcmpltps      %ymm3,%ymm10,%ymm6
  .byte  196,193,100,92,250                  // vsubps        %ymm10,%ymm3,%ymm7
  .byte  196,227,101,74,247,96               // vblendvps     %ymm6,%ymm7,%ymm3,%ymm6
  .byte  196,193,100,194,253,1               // vcmpltps      %ymm13,%ymm3,%ymm7
  .byte  197,44,88,211                       // vaddps        %ymm3,%ymm10,%ymm10
  .byte  196,195,77,74,242,112               // vblendvps     %ymm7,%ymm10,%ymm6,%ymm6
  .byte  197,204,194,248,1                   // vcmpltps      %ymm0,%ymm6,%ymm7
  .byte  197,252,92,198                      // vsubps        %ymm6,%ymm0,%ymm0
  .byte  197,140,89,192                      // vmulps        %ymm0,%ymm14,%ymm0
  .byte  197,164,88,192                      // vaddps        %ymm0,%ymm11,%ymm0
  .byte  196,227,37,74,192,112               // vblendvps     %ymm7,%ymm0,%ymm11,%ymm0
  .byte  196,193,76,194,248,1                // vcmpltps      %ymm8,%ymm6,%ymm7
  .byte  196,195,125,74,193,112              // vblendvps     %ymm7,%ymm9,%ymm0,%ymm0
  .byte  197,204,194,210,1                   // vcmpltps      %ymm2,%ymm6,%ymm2
  .byte  196,193,100,89,222                  // vmulps        %ymm14,%ymm3,%ymm3
  .byte  197,164,88,219                      // vaddps        %ymm3,%ymm11,%ymm3
  .byte  196,227,125,74,211,32               // vblendvps     %ymm2,%ymm3,%ymm0,%ymm2
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,212,194,216,0                   // vcmpeqps      %ymm0,%ymm5,%ymm3
  .byte  196,227,5,74,196,48                 // vblendvps     %ymm3,%ymm4,%ymm15,%ymm0
  .byte  196,227,117,74,204,48               // vblendvps     %ymm3,%ymm4,%ymm1,%ymm1
  .byte  196,227,109,74,212,48               // vblendvps     %ymm3,%ymm4,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,16,92,36,128                // vmovups       -0x80(%rsp),%ymm3
  .byte  197,252,16,100,36,160               // vmovups       -0x60(%rsp),%ymm4
  .byte  197,252,16,108,36,192               // vmovups       -0x40(%rsp),%ymm5
  .byte  197,252,16,116,36,224               // vmovups       -0x20(%rsp),%ymm6
  .byte  197,252,16,60,36                    // vmovups       (%rsp),%ymm7
  .byte  72,131,196,56                       // add           $0x38,%rsp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_avx
.globl _sk_scale_1_float_avx
_sk_scale_1_float_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_avx
.globl _sk_scale_u8_avx
_sk_scale_u8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,80                              // jne           1456 <_sk_scale_u8_avx+0x60>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,121,49,200                   // vpmovzxbd     %xmm8,%xmm9
  .byte  196,67,121,4,192,229                // vpermilps     $0xe5,%xmm8,%xmm8
  .byte  196,66,121,49,192                   // vpmovzxbd     %xmm8,%xmm8
  .byte  196,67,53,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm9,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           145e <_sk_scale_u8_avx+0x68>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  235,143                             // jmp           140a <_sk_scale_u8_avx+0x14>

HIDDEN _sk_lerp_1_float_avx
.globl _sk_lerp_1_float_avx
_sk_lerp_1_float_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_avx
.globl _sk_lerp_u8_avx
_sk_lerp_u8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,116                             // jne           153e <_sk_lerp_u8_avx+0x84>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,121,49,200                   // vpmovzxbd     %xmm8,%xmm9
  .byte  196,67,121,4,192,229                // vpermilps     $0xe5,%xmm8,%xmm8
  .byte  196,66,121,49,192                   // vpmovzxbd     %xmm8,%xmm8
  .byte  196,67,53,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm9,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           1546 <_sk_lerp_u8_avx+0x8c>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  233,104,255,255,255                 // jmpq          14ce <_sk_lerp_u8_avx+0x14>

HIDDEN _sk_lerp_565_avx
.globl _sk_lerp_565_avx
_sk_lerp_565_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,250,0,0,0                    // jne           166e <_sk_lerp_565_avx+0x108>
  .byte  196,65,122,111,4,122                // vmovdqu       (%r10,%rdi,2),%xmm8
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  197,185,105,219                     // vpunpckhwd    %xmm3,%xmm8,%xmm3
  .byte  196,66,121,51,192                   // vpmovzxwd     %xmm8,%xmm8
  .byte  196,99,61,24,195,1                  // vinsertf128   $0x1,%xmm3,%ymm8,%ymm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,216                  // vandps        %ymm8,%ymm3,%ymm3
  .byte  197,124,91,203                      // vcvtdq2ps     %ymm3,%ymm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,216                  // vandps        %ymm8,%ymm3,%ymm3
  .byte  197,124,91,211                      // vcvtdq2ps     %ymm3,%ymm10
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,44,89,211                       // vmulps        %ymm3,%ymm10,%ymm10
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,216                  // vandps        %ymm8,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,89,202                  // vmulps        %ymm10,%ymm1,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  196,65,57,239,192                   // vpxor         %xmm8,%xmm8,%xmm8
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,243,254,255,255              // ja            157a <_sk_lerp_565_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,74,0,0,0                  // lea           0x4a(%rip),%r9        # 16dc <_sk_lerp_565_avx+0x176>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  196,65,97,196,68,122,12,6           // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm3,%xmm8
  .byte  196,65,57,196,68,122,10,5           // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,8,4            // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,6,3            // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,4,2            // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,2,1            // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,4,122,0               // vpinsrw       $0x0,(%r10,%rdi,2),%xmm8,%xmm8
  .byte  233,159,254,255,255                 // jmpq          157a <_sk_lerp_565_avx+0x14>
  .byte  144                                 // nop
  .byte  243,255                             // repz          (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  235,255                             // jmp           16e1 <_sk_lerp_565_avx+0x17b>
  .byte  255                                 // (bad)
  .byte  255,227                             // jmpq          *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  219,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,211                             // callq         *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,203                             // dec           %ebx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  191                                 // .byte         0xbf
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_tables_avx
.globl _sk_load_tables_avx
_sk_load_tables_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,56,2,0,0                     // jne           1948 <_sk_load_tables_avx+0x250>
  .byte  196,65,124,16,4,184                 // vmovups       (%r8,%rdi,4),%ymm8
  .byte  187,255,0,0,0                       // mov           $0xff,%ebx
  .byte  197,249,110,195                     // vmovd         %ebx,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,200,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm9
  .byte  196,193,52,84,192                   // vandps        %ymm8,%ymm9,%ymm0
  .byte  196,193,249,126,193                 // vmovq         %xmm0,%r9
  .byte  69,137,203                          // mov           %r9d,%r11d
  .byte  196,195,249,22,194,1                // vpextrq       $0x1,%xmm0,%r10
  .byte  69,137,214                          // mov           %r10d,%r14d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  196,227,125,25,192,1                // vextractf128  $0x1,%ymm0,%xmm0
  .byte  196,193,249,126,196                 // vmovq         %xmm0,%r12
  .byte  69,137,231                          // mov           %r12d,%r15d
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  72,139,104,8                        // mov           0x8(%rax),%rbp
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  196,161,122,16,68,189,0             // vmovss        0x0(%rbp,%r15,4),%xmm0
  .byte  196,163,121,33,68,165,0,16          // vinsertps     $0x10,0x0(%rbp,%r12,4),%xmm0,%xmm0
  .byte  196,161,122,16,76,173,0             // vmovss        0x0(%rbp,%r13,4),%xmm1
  .byte  196,227,121,33,193,32               // vinsertps     $0x20,%xmm1,%xmm0,%xmm0
  .byte  197,250,16,76,157,0                 // vmovss        0x0(%rbp,%rbx,4),%xmm1
  .byte  196,227,121,33,193,48               // vinsertps     $0x30,%xmm1,%xmm0,%xmm0
  .byte  196,161,122,16,76,157,0             // vmovss        0x0(%rbp,%r11,4),%xmm1
  .byte  196,163,113,33,76,141,0,16          // vinsertps     $0x10,0x0(%rbp,%r9,4),%xmm1,%xmm1
  .byte  196,161,122,16,92,181,0             // vmovss        0x0(%rbp,%r14,4),%xmm3
  .byte  196,227,113,33,203,32               // vinsertps     $0x20,%xmm3,%xmm1,%xmm1
  .byte  196,161,122,16,92,149,0             // vmovss        0x0(%rbp,%r10,4),%xmm3
  .byte  196,227,113,33,203,48               // vinsertps     $0x30,%xmm3,%xmm1,%xmm1
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  196,193,113,114,208,8               // vpsrld        $0x8,%xmm8,%xmm1
  .byte  196,67,125,25,194,1                 // vextractf128  $0x1,%ymm8,%xmm10
  .byte  196,193,105,114,210,8               // vpsrld        $0x8,%xmm10,%xmm2
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  197,180,84,201                      // vandps        %ymm1,%ymm9,%ymm1
  .byte  196,193,249,126,201                 // vmovq         %xmm1,%r9
  .byte  69,137,203                          // mov           %r9d,%r11d
  .byte  196,195,249,22,202,1                // vpextrq       $0x1,%xmm1,%r10
  .byte  69,137,214                          // mov           %r10d,%r14d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,225,249,126,205                 // vmovq         %xmm1,%rbp
  .byte  65,137,239                          // mov           %ebp,%r15d
  .byte  196,227,249,22,203,1                // vpextrq       $0x1,%xmm1,%rbx
  .byte  65,137,220                          // mov           %ebx,%r12d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,129,122,16,12,184               // vmovss        (%r8,%r15,4),%xmm1
  .byte  196,195,113,33,12,168,16            // vinsertps     $0x10,(%r8,%rbp,4),%xmm1,%xmm1
  .byte  196,129,122,16,20,160               // vmovss        (%r8,%r12,4),%xmm2
  .byte  196,227,113,33,202,32               // vinsertps     $0x20,%xmm2,%xmm1,%xmm1
  .byte  196,193,122,16,20,152               // vmovss        (%r8,%rbx,4),%xmm2
  .byte  196,227,113,33,202,48               // vinsertps     $0x30,%xmm2,%xmm1,%xmm1
  .byte  196,129,122,16,20,152               // vmovss        (%r8,%r11,4),%xmm2
  .byte  196,131,105,33,20,136,16            // vinsertps     $0x10,(%r8,%r9,4),%xmm2,%xmm2
  .byte  196,129,122,16,28,176               // vmovss        (%r8,%r14,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  196,129,122,16,28,144               // vmovss        (%r8,%r10,4),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,227,109,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm2,%ymm1
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  196,193,105,114,208,16              // vpsrld        $0x10,%xmm8,%xmm2
  .byte  196,193,97,114,210,16               // vpsrld        $0x10,%xmm10,%xmm3
  .byte  196,227,109,24,211,1                // vinsertf128   $0x1,%xmm3,%ymm2,%ymm2
  .byte  197,180,84,210                      // vandps        %ymm2,%ymm9,%ymm2
  .byte  196,193,249,126,208                 // vmovq         %xmm2,%r8
  .byte  69,137,194                          // mov           %r8d,%r10d
  .byte  196,195,249,22,209,1                // vpextrq       $0x1,%xmm2,%r9
  .byte  69,137,203                          // mov           %r9d,%r11d
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  73,193,232,32                       // shr           $0x20,%r8
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,225,249,126,213                 // vmovq         %xmm2,%rbp
  .byte  65,137,238                          // mov           %ebp,%r14d
  .byte  196,227,249,22,211,1                // vpextrq       $0x1,%xmm2,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,161,122,16,20,176               // vmovss        (%rax,%r14,4),%xmm2
  .byte  196,227,105,33,20,168,16            // vinsertps     $0x10,(%rax,%rbp,4),%xmm2,%xmm2
  .byte  196,161,122,16,28,184               // vmovss        (%rax,%r15,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  197,250,16,28,152                   // vmovss        (%rax,%rbx,4),%xmm3
  .byte  196,99,105,33,203,48                // vinsertps     $0x30,%xmm3,%xmm2,%xmm9
  .byte  196,161,122,16,28,144               // vmovss        (%rax,%r10,4),%xmm3
  .byte  196,163,97,33,28,128,16             // vinsertps     $0x10,(%rax,%r8,4),%xmm3,%xmm3
  .byte  196,161,122,16,20,152               // vmovss        (%rax,%r11,4),%xmm2
  .byte  196,227,97,33,210,32                // vinsertps     $0x20,%xmm2,%xmm3,%xmm2
  .byte  196,161,122,16,28,136               // vmovss        (%rax,%r9,4),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,195,109,24,209,1                // vinsertf128   $0x1,%xmm9,%ymm2,%ymm2
  .byte  196,193,57,114,208,24               // vpsrld        $0x18,%xmm8,%xmm8
  .byte  196,193,97,114,210,24               // vpsrld        $0x18,%xmm10,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax
  .byte  137,203                             // mov           %ecx,%ebx
  .byte  128,227,7                           // and           $0x7,%bl
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  254,203                             // dec           %bl
  .byte  128,251,6                           // cmp           $0x6,%bl
  .byte  15,135,185,253,255,255              // ja            1716 <_sk_load_tables_avx+0x1e>
  .byte  15,182,219                          // movzbl        %bl,%ebx
  .byte  76,141,13,137,0,0,0                 // lea           0x89(%rip),%r9        # 19f0 <_sk_load_tables_avx+0x2f8>
  .byte  73,99,28,153                        // movslq        (%r9,%rbx,4),%rbx
  .byte  76,1,203                            // add           %r9,%rbx
  .byte  255,227                             // jmpq          *%rbx
  .byte  196,193,121,110,68,184,24           // vmovd         0x18(%r8,%rdi,4),%xmm0
  .byte  197,249,112,192,68                  // vpshufd       $0x44,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  196,99,117,12,192,64                // vblendps      $0x40,%ymm0,%ymm1,%ymm8
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,195,121,34,68,184,20,1          // vpinsrd       $0x1,0x14(%r8,%rdi,4),%xmm0,%xmm0
  .byte  196,99,61,24,192,1                  // vinsertf128   $0x1,%xmm0,%ymm8,%ymm8
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,195,121,34,68,184,16,0          // vpinsrd       $0x0,0x10(%r8,%rdi,4),%xmm0,%xmm0
  .byte  196,99,61,24,192,1                  // vinsertf128   $0x1,%xmm0,%ymm8,%ymm8
  .byte  196,195,57,34,68,184,12,3           // vpinsrd       $0x3,0xc(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  196,195,57,34,68,184,8,2            // vpinsrd       $0x2,0x8(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  196,195,57,34,68,184,4,1            // vpinsrd       $0x1,0x4(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  196,195,57,34,4,184,0               // vpinsrd       $0x0,(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  233,38,253,255,255                  // jmpq          1716 <_sk_load_tables_avx+0x1e>
  .byte  238                                 // out           %al,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,224                             // jmpq          *%rax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,210                             // callq         *%rdx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,196                             // inc           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,176,255,255,255,156             // pushq         -0x63000001(%rax)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff
  .byte  128,255,255                         // cmp           $0xff,%bh
  .byte  255                                 // .byte         0xff

HIDDEN _sk_byte_tables_avx
.globl _sk_byte_tables_avx
_sk_byte_tables_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,127,67                   // mov           $0x437f0000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,25,192,1                // vextractf128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,98,121,49,200                   // vpmovzxbd     %xmm0,%xmm9
  .byte  196,131,121,32,4,41,0               // vpinsrb       $0x0,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,53,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm9,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,200,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,98,121,49,209                   // vpmovzxbd     %xmm1,%xmm10
  .byte  196,131,121,32,12,32,0              // vpinsrb       $0x0,(%r8,%r12,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,56,1              // vpinsrb       $0x1,(%r8,%r15,1),%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,2                // vpinsrb       $0x2,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,45,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm10,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,211,1                // vpextrq       $0x1,%xmm2,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,215                 // vmovq         %xmm2,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,20,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm2
  .byte  196,195,105,32,20,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm2,%xmm2
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  196,98,121,49,210                   // vpmovzxbd     %xmm2,%xmm10
  .byte  196,131,121,32,20,32,0              // vpinsrb       $0x0,(%r8,%r12,1),%xmm0,%xmm2
  .byte  196,131,105,32,20,56,1              // vpinsrb       $0x1,(%r8,%r15,1),%xmm2,%xmm2
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,105,32,213,2                // vpinsrb       $0x2,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  196,226,121,49,210                  // vpmovzxbd     %xmm2,%xmm2
  .byte  196,227,45,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm10,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,253,91,219                      // vcvtps2dq     %ymm3,%ymm3
  .byte  196,227,249,22,221,1                // vpextrq       $0x1,%xmm3,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,219                 // vmovq         %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,219,1                // vextractf128  $0x1,%ymm3,%xmm3
  .byte  196,195,249,22,218,1                // vpextrq       $0x1,%xmm3,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,222                 // vmovq         %xmm3,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,28,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm3
  .byte  196,227,97,32,28,24,1               // vpinsrb       $0x1,(%rax,%rbx,1),%xmm3,%xmm3
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,97,32,219,2                 // vpinsrb       $0x2,%ebx,%xmm3,%xmm3
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,97,32,221,3                 // vpinsrb       $0x3,%ebp,%xmm3,%xmm3
  .byte  196,98,121,49,195                   // vpmovzxbd     %xmm3,%xmm8
  .byte  196,163,121,32,28,56,0              // vpinsrb       $0x0,(%rax,%r15,1),%xmm0,%xmm3
  .byte  196,163,97,32,28,48,1               // vpinsrb       $0x1,(%rax,%r14,1),%xmm3,%xmm3
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,97,32,221,2                 // vpinsrb       $0x2,%ebp,%xmm3,%xmm3
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,97,32,216,3                 // vpinsrb       $0x3,%eax,%xmm3,%xmm3
  .byte  196,226,121,49,219                  // vpmovzxbd     %xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_avx
.globl _sk_byte_tables_rgb_avx
_sk_byte_tables_rgb_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,139,64,24                        // mov           0x18(%rax),%r8d
  .byte  65,255,200                          // dec           %r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,65,121,112,192,0                // vpshufd       $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,25,192,1                // vextractf128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,98,121,49,200                   // vpmovzxbd     %xmm0,%xmm9
  .byte  196,131,121,32,4,41,0               // vpinsrb       $0x0,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,53,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm9,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,200,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,98,121,49,209                   // vpmovzxbd     %xmm1,%xmm10
  .byte  196,131,121,32,12,32,0              // vpinsrb       $0x0,(%r8,%r12,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,56,1              // vpinsrb       $0x1,(%r8,%r15,1),%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,2                // vpinsrb       $0x2,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,45,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm10,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,210,1                // vpextrq       $0x1,%xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,214                 // vmovq         %xmm2,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,20,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm2
  .byte  196,227,105,32,20,24,1              // vpinsrb       $0x1,(%rax,%rbx,1),%xmm2,%xmm2
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  196,98,121,49,194                   // vpmovzxbd     %xmm2,%xmm8
  .byte  196,163,121,32,20,56,0              // vpinsrb       $0x0,(%rax,%r15,1),%xmm0,%xmm2
  .byte  196,163,105,32,20,48,1              // vpinsrb       $0x1,(%rax,%r14,1),%xmm2,%xmm2
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,105,32,213,2                // vpinsrb       $0x2,%ebp,%xmm2,%xmm2
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,105,32,208,3                // vpinsrb       $0x3,%eax,%xmm2,%xmm2
  .byte  196,226,121,49,210                  // vpmovzxbd     %xmm2,%xmm2
  .byte  196,227,61,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm8,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_avx
.globl _sk_load_a8_avx
_sk_load_a8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,74                              // jne           1f84 <_sk_load_a8_avx+0x5a>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,121,49,200                  // vpmovzxbd     %xmm0,%xmm1
  .byte  196,227,121,4,192,229               // vpermilps     $0xe5,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           1f8c <_sk_load_a8_avx+0x62>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,149                             // jmp           1f3e <_sk_load_a8_avx+0x14>

HIDDEN _sk_gather_a8_avx
.globl _sk_gather_a8_avx
_sk_gather_a8_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,131,121,32,4,48,0               // vpinsrb       $0x0,(%r8,%r14,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,24,1               // vpinsrb       $0x1,(%r8,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,28,32                     // movzbl        (%r8,%r12,1),%ebx
  .byte  196,227,121,32,195,2                // vpinsrb       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,182,28,56                     // movzbl        (%r8,%r15,1),%ebx
  .byte  196,227,121,32,195,3                // vpinsrb       $0x3,%ebx,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,131,121,32,12,24,0              // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,16,1              // vpinsrb       $0x1,(%r8,%r10,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,113,32,200,3                // vpinsrb       $0x3,%eax,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_avx
.globl _sk_store_a8_avx
_sk_store_a8_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  196,65,57,103,192                   // vpackuswb     %xmm8,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           20e5 <_sk_store_a8_avx+0x42>
  .byte  196,65,123,17,4,57                  // vmovsd        %xmm8,(%r9,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            20e1 <_sk_store_a8_avx+0x3e>
  .byte  196,66,121,48,192                   // vpmovzxbw     %xmm8,%xmm8
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,67,0,0,0                   // lea           0x43(%rip),%r8        # 2148 <_sk_store_a8_avx+0xa5>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,20,68,57,6,12            // vpextrb       $0xc,%xmm8,0x6(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,5,10            // vpextrb       $0xa,%xmm8,0x5(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,4,8             // vpextrb       $0x8,%xmm8,0x4(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,3,6             // vpextrb       $0x6,%xmm8,0x3(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,2,4             // vpextrb       $0x4,%xmm8,0x2(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,1,2             // vpextrb       $0x2,%xmm8,0x1(%r9,%rdi,1)
  .byte  196,67,121,20,4,57,0                // vpextrb       $0x0,%xmm8,(%r9,%rdi,1)
  .byte  235,154                             // jmp           20e1 <_sk_store_a8_avx+0x3e>
  .byte  144                                 // nop
  .byte  246,255                             // idiv          %bh
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  238                                 // out           %al,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,230                             // jmpq          *%rsi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  222,255                             // fdivrp        %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,214                             // callq         *%rsi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,206                             // dec           %esi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,198                             // inc           %esi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_g8_avx
.globl _sk_load_g8_avx
_sk_load_g8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,91                              // jne           21cf <_sk_load_g8_avx+0x6b>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,121,49,200                  // vpmovzxbd     %xmm0,%xmm1
  .byte  196,227,121,4,192,229               // vpermilps     $0xe5,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,217,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           21d7 <_sk_load_g8_avx+0x73>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,132                             // jmp           2178 <_sk_load_g8_avx+0x14>

HIDDEN _sk_gather_g8_avx
.globl _sk_gather_g8_avx
_sk_gather_g8_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,131,121,32,4,48,0               // vpinsrb       $0x0,(%r8,%r14,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,24,1               // vpinsrb       $0x1,(%r8,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,28,32                     // movzbl        (%r8,%r12,1),%ebx
  .byte  196,227,121,32,195,2                // vpinsrb       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,182,28,56                     // movzbl        (%r8,%r15,1),%ebx
  .byte  196,227,121,32,195,3                // vpinsrb       $0x3,%ebx,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,131,121,32,12,24,0              // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,16,1              // vpinsrb       $0x1,(%r8,%r10,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,113,32,200,3                // vpinsrb       $0x3,%eax,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,217,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_avx
.globl _sk_gather_i8_avx
_sk_gather_i8_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            230e <_sk_gather_i8_avx+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           2310 <_sk_gather_i8_avx+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,194                          // mov           %eax,%r10d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,211                 // vmovq         %xmm2,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  196,195,249,22,196,1                // vpextrq       $0x1,%xmm0,%r12
  .byte  69,137,229                          // mov           %r12d,%r13d
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,131,121,32,4,49,0               // vpinsrb       $0x0,(%r9,%r14,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,17,2               // vpinsrb       $0x2,(%r9,%r10,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,1,3                // vpinsrb       $0x3,(%r9,%rax,1),%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,195,249,22,194,1                // vpextrq       $0x1,%xmm0,%r10
  .byte  196,193,249,126,195                 // vmovq         %xmm0,%r11
  .byte  196,131,121,32,4,57,0               // vpinsrb       $0x0,(%r9,%r15,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,41,2               // vpinsrb       $0x2,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,33,3               // vpinsrb       $0x3,(%r9,%r12,1),%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  73,139,88,8                         // mov           0x8(%r8),%rbx
  .byte  196,193,249,126,193                 // vmovq         %xmm0,%r9
  .byte  69,137,200                          // mov           %r9d,%r8d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,198                          // mov           %eax,%r14d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  69,137,223                          // mov           %r11d,%r15d
  .byte  73,193,235,30                       // shr           $0x1e,%r11
  .byte  69,137,212                          // mov           %r10d,%r12d
  .byte  73,193,234,30                       // shr           $0x1e,%r10
  .byte  196,161,121,110,4,131               // vmovd         (%rbx,%r8,4),%xmm0
  .byte  196,163,121,34,4,11,1               // vpinsrd       $0x1,(%rbx,%r9,1),%xmm0,%xmm0
  .byte  196,163,121,34,4,179,2              // vpinsrd       $0x2,(%rbx,%r14,4),%xmm0,%xmm0
  .byte  196,99,121,34,4,3,3                 // vpinsrd       $0x3,(%rbx,%rax,1),%xmm0,%xmm8
  .byte  196,161,121,110,4,187               // vmovd         (%rbx,%r15,4),%xmm0
  .byte  196,163,121,34,4,27,1               // vpinsrd       $0x1,(%rbx,%r11,1),%xmm0,%xmm0
  .byte  196,163,121,34,4,163,2              // vpinsrd       $0x2,(%rbx,%r12,4),%xmm0,%xmm0
  .byte  196,163,121,34,28,19,3              // vpinsrd       $0x3,(%rbx,%r10,1),%xmm0,%xmm3
  .byte  196,227,61,24,195,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm0
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,217,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm11
  .byte  197,164,84,192                      // vandps        %ymm0,%ymm11,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm9
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  196,193,41,114,208,8                // vpsrld        $0x8,%xmm8,%xmm10
  .byte  197,241,114,211,8                   // vpsrld        $0x8,%xmm3,%xmm1
  .byte  196,227,45,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm10,%ymm1
  .byte  197,164,84,201                      // vandps        %ymm1,%ymm11,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  196,193,41,114,208,16               // vpsrld        $0x10,%xmm8,%xmm10
  .byte  197,233,114,211,16                  // vpsrld        $0x10,%xmm3,%xmm2
  .byte  196,227,45,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm10,%ymm2
  .byte  197,164,84,210                      // vandps        %ymm2,%ymm11,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  196,193,57,114,208,24               // vpsrld        $0x18,%xmm8,%xmm8
  .byte  197,225,114,211,24                  // vpsrld        $0x18,%xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,217                  // vmulps        %ymm9,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_avx
.globl _sk_load_565_avx
_sk_load_565_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,209,0,0,0                    // jne           25aa <_sk_load_565_avx+0xdf>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,209,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,84,194                      // vandps        %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,84,202                      // vandps        %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,84,210                      // vandps        %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,29,255,255,255               // ja            24df <_sk_load_565_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,75,0,0,0                  // lea           0x4b(%rip),%r9        # 2618 <_sk_load_565_avx+0x14d>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,201,254,255,255                 // jmpq          24df <_sk_load_565_avx+0x14>
  .byte  102,144                             // xchg          %ax,%ax
  .byte  242,255                             // repnz         (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  234                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,226                             // jmpq          *%rdx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  218,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,210                             // callq         *%rdx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,202                             // dec           %edx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  190                                 // .byte         0xbe
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_565_avx
.globl _sk_gather_565_avx
_sk_gather_565_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  65,15,183,28,88                     // movzwl        (%r8,%rbx,2),%ebx
  .byte  67,15,183,44,112                    // movzwl        (%r8,%r14,2),%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  197,249,196,195,1                   // vpinsrw       $0x1,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,96                     // movzwl        (%r8,%r12,2),%ebx
  .byte  197,249,196,195,2                   // vpinsrw       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,120                    // movzwl        (%r8,%r15,2),%ebx
  .byte  197,249,196,195,3                   // vpinsrw       $0x3,%ebx,%xmm0,%xmm0
  .byte  67,15,183,44,88                     // movzwl        (%r8,%r11,2),%ebp
  .byte  197,249,196,197,4                   // vpinsrw       $0x4,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,80                     // movzwl        (%r8,%r10,2),%ebp
  .byte  197,249,196,197,5                   // vpinsrw       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,72                     // movzwl        (%r8,%r9,2),%ebp
  .byte  197,249,196,197,6                   // vpinsrw       $0x6,%ebp,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,209,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,84,194                      // vandps        %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,84,202                      // vandps        %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,84,210                      // vandps        %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_avx
.globl _sk_store_565_avx
_sk_store_565_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,248,65                      // mov           $0x41f80000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,41,114,241,11               // vpslld        $0xb,%xmm9,%xmm10
  .byte  196,67,125,25,201,1                 // vextractf128  $0x1,%ymm9,%xmm9
  .byte  196,193,49,114,241,11               // vpslld        $0xb,%xmm9,%xmm9
  .byte  196,67,45,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm9
  .byte  184,0,0,124,66                      // mov           $0x427c0000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,5                // vpslld        $0x5,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,5                // vpslld        $0x5,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  196,65,45,86,201                    // vorpd         %ymm9,%ymm10,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,53,86,192                    // vorpd         %ymm8,%ymm9,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           2863 <_sk_store_565_avx+0x9e>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            285f <_sk_store_565_avx+0x9a>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,66,0,0,0                   // lea           0x42(%rip),%r8        # 28c0 <_sk_store_565_avx+0xfb>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           285f <_sk_store_565_avx+0x9a>
  .byte  247,255                             // idiv          %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  239                                 // out           %eax,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,231                             // jmpq          *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  223,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,215                             // callq         *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,207                             // dec           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,199                             // inc           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_4444_avx
.globl _sk_load_4444_avx
_sk_load_4444_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,245,0,0,0                    // jne           29df <_sk_load_4444_avx+0x103>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,99,125,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,124,84,193                  // vandps        %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  196,193,116,84,201                  // vandps        %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,249,112,210,0                   // vpshufd       $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  196,193,108,84,209                  // vandps        %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,217                  // vandps        %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,249,254,255,255              // ja            28f0 <_sk_load_4444_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,74,0,0,0                  // lea           0x4a(%rip),%r9        # 2a4c <_sk_load_4444_avx+0x170>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,165,254,255,255                 // jmpq          28f0 <_sk_load_4444_avx+0x14>
  .byte  144                                 // nop
  .byte  243,255                             // repz          (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  235,255                             // jmp           2a51 <_sk_load_4444_avx+0x175>
  .byte  255                                 // (bad)
  .byte  255,227                             // jmpq          *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  219,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,211                             // callq         *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,203                             // dec           %ebx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  191                                 // .byte         0xbf
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_4444_avx
.globl _sk_gather_4444_avx
_sk_gather_4444_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  65,15,183,28,88                     // movzwl        (%r8,%rbx,2),%ebx
  .byte  67,15,183,44,112                    // movzwl        (%r8,%r14,2),%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  197,249,196,195,1                   // vpinsrw       $0x1,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,96                     // movzwl        (%r8,%r12,2),%ebx
  .byte  197,249,196,195,2                   // vpinsrw       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,120                    // movzwl        (%r8,%r15,2),%ebx
  .byte  197,249,196,195,3                   // vpinsrw       $0x3,%ebx,%xmm0,%xmm0
  .byte  67,15,183,44,88                     // movzwl        (%r8,%r11,2),%ebp
  .byte  197,249,196,197,4                   // vpinsrw       $0x4,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,80                     // movzwl        (%r8,%r10,2),%ebp
  .byte  197,249,196,197,5                   // vpinsrw       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,72                     // movzwl        (%r8,%r9,2),%ebp
  .byte  197,249,196,197,6                   // vpinsrw       $0x6,%ebp,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,99,125,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,124,84,193                  // vandps        %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  196,193,116,84,201                  // vandps        %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,249,112,210,0                   // vpshufd       $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  196,193,108,84,209                  // vandps        %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,217                  // vandps        %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_avx
.globl _sk_store_4444_avx
_sk_store_4444_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,112,65                      // mov           $0x41700000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,41,114,241,12               // vpslld        $0xc,%xmm9,%xmm10
  .byte  196,67,125,25,201,1                 // vextractf128  $0x1,%ymm9,%xmm9
  .byte  196,193,49,114,241,12               // vpslld        $0xc,%xmm9,%xmm9
  .byte  196,67,45,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,8                // vpslld        $0x8,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,8                // vpslld        $0x8,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  196,65,45,86,201                    // vorpd         %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,4                // vpslld        $0x4,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,4                // vpslld        $0x4,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,45,86,192                    // vorpd         %ymm8,%ymm10,%ymm8
  .byte  196,65,53,86,192                    // vorpd         %ymm8,%ymm9,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           2ccc <_sk_store_4444_avx+0xaf>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            2cc8 <_sk_store_4444_avx+0xab>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,69,0,0,0                   // lea           0x45(%rip),%r8        # 2d2c <_sk_store_4444_avx+0x10f>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           2cc8 <_sk_store_4444_avx+0xab>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  244                                 // hlt
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  236                                 // in            (%dx),%al
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,228                             // jmpq          *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  220,255                             // fdivr         %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,212                             // callq         *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,204                             // dec           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,196                             // inc           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_8888_avx
.globl _sk_load_8888_avx
_sk_load_8888_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,157,0,0,0                    // jne           2df3 <_sk_load_8888_avx+0xab>
  .byte  196,65,124,16,12,186                // vmovups       (%r10,%rdi,4),%ymm9
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,216,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm11
  .byte  196,193,36,84,193                   // vandps        %ymm9,%ymm11,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,193,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  196,193,41,114,209,8                // vpsrld        $0x8,%xmm9,%xmm10
  .byte  196,99,125,25,203,1                 // vextractf128  $0x1,%ymm9,%xmm3
  .byte  197,241,114,211,8                   // vpsrld        $0x8,%xmm3,%xmm1
  .byte  196,227,45,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm10,%ymm1
  .byte  197,164,84,201                      // vandps        %ymm1,%ymm11,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  196,193,41,114,209,16               // vpsrld        $0x10,%xmm9,%xmm10
  .byte  197,233,114,211,16                  // vpsrld        $0x10,%xmm3,%xmm2
  .byte  196,227,45,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm10,%ymm2
  .byte  197,164,84,210                      // vandps        %ymm2,%ymm11,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  196,193,49,114,209,24               // vpsrld        $0x18,%xmm9,%xmm9
  .byte  197,225,114,211,24                  // vpsrld        $0x18,%xmm3,%xmm3
  .byte  196,227,53,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm9,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,80,255,255,255               // ja            2d5c <_sk_load_8888_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,137,0,0,0                 // lea           0x89(%rip),%r9        # 2ea0 <_sk_load_8888_avx+0x158>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,193,121,110,68,186,24           // vmovd         0x18(%r10,%rdi,4),%xmm0
  .byte  197,249,112,192,68                  // vpshufd       $0x44,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  196,99,117,12,200,64                // vblendps      $0x40,%ymm0,%ymm1,%ymm9
  .byte  196,99,125,25,200,1                 // vextractf128  $0x1,%ymm9,%xmm0
  .byte  196,195,121,34,68,186,20,1          // vpinsrd       $0x1,0x14(%r10,%rdi,4),%xmm0,%xmm0
  .byte  196,99,53,24,200,1                  // vinsertf128   $0x1,%xmm0,%ymm9,%ymm9
  .byte  196,99,125,25,200,1                 // vextractf128  $0x1,%ymm9,%xmm0
  .byte  196,195,121,34,68,186,16,0          // vpinsrd       $0x0,0x10(%r10,%rdi,4),%xmm0,%xmm0
  .byte  196,99,53,24,200,1                  // vinsertf128   $0x1,%xmm0,%ymm9,%ymm9
  .byte  196,195,49,34,68,186,12,3           // vpinsrd       $0x3,0xc(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  196,195,49,34,68,186,8,2            // vpinsrd       $0x2,0x8(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  196,195,49,34,68,186,4,1            // vpinsrd       $0x1,0x4(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  196,195,49,34,4,186,0               // vpinsrd       $0x0,(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  233,188,254,255,255                 // jmpq          2d5c <_sk_load_8888_avx+0x14>
  .byte  238                                 // out           %al,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,224                             // jmpq          *%rax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,210                             // callq         *%rdx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,196                             // inc           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,176,255,255,255,156             // pushq         -0x63000001(%rax)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff
  .byte  128,255,255                         // cmp           $0xff,%bh
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_8888_avx
.globl _sk_gather_8888_avx
_sk_gather_8888_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  197,249,110,80,16                   // vmovd         0x10(%rax),%xmm2
  .byte  197,249,112,210,0                   // vpshufd       $0x0,%xmm2,%xmm2
  .byte  196,226,105,64,217                  // vpmulld       %xmm1,%xmm2,%xmm3
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,226,105,64,201                  // vpmulld       %xmm1,%xmm2,%xmm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,194,1                // vextractf128  $0x1,%ymm0,%xmm2
  .byte  197,241,254,202                     // vpaddd        %xmm2,%xmm1,%xmm1
  .byte  196,225,249,126,200                 // vmovq         %xmm1,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,195,249,22,202,1                // vpextrq       $0x1,%xmm1,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,225,254,192                     // vpaddd        %xmm0,%xmm3,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,129,121,110,4,176               // vmovd         (%r8,%r14,4),%xmm0
  .byte  196,195,121,34,4,152,1              // vpinsrd       $0x1,(%r8,%rbx,4),%xmm0,%xmm0
  .byte  196,131,121,34,4,160,2              // vpinsrd       $0x2,(%r8,%r12,4),%xmm0,%xmm0
  .byte  196,3,121,34,4,184,3                // vpinsrd       $0x3,(%r8,%r15,4),%xmm0,%xmm8
  .byte  196,129,121,110,4,136               // vmovd         (%r8,%r9,4),%xmm0
  .byte  196,195,121,34,4,128,1              // vpinsrd       $0x1,(%r8,%rax,4),%xmm0,%xmm0
  .byte  196,131,121,34,4,152,2              // vpinsrd       $0x2,(%r8,%r11,4),%xmm0,%xmm0
  .byte  196,131,121,34,28,144,3             // vpinsrd       $0x3,(%r8,%r10,4),%xmm0,%xmm3
  .byte  196,227,61,24,195,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm0
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,217,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm11
  .byte  197,164,84,192                      // vandps        %ymm0,%ymm11,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm9
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  196,193,41,114,208,8                // vpsrld        $0x8,%xmm8,%xmm10
  .byte  197,241,114,211,8                   // vpsrld        $0x8,%xmm3,%xmm1
  .byte  196,227,45,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm10,%ymm1
  .byte  197,164,84,201                      // vandps        %ymm1,%ymm11,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  196,193,41,114,208,16               // vpsrld        $0x10,%xmm8,%xmm10
  .byte  197,233,114,211,16                  // vpsrld        $0x10,%xmm3,%xmm2
  .byte  196,227,45,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm10,%ymm2
  .byte  197,164,84,210                      // vandps        %ymm2,%ymm11,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  196,193,57,114,208,24               // vpsrld        $0x18,%xmm8,%xmm8
  .byte  197,225,114,211,24                  // vpsrld        $0x18,%xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,217                  // vmulps        %ymm9,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_avx
.globl _sk_store_8888_avx
_sk_store_8888_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,8                // vpslld        $0x8,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,8                // vpslld        $0x8,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  196,65,45,86,201                    // vorpd         %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,16               // vpslld        $0x10,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,16               // vpslld        $0x10,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,193,33,114,240,24               // vpslld        $0x18,%xmm8,%xmm11
  .byte  196,67,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm8
  .byte  196,193,57,114,240,24               // vpslld        $0x18,%xmm8,%xmm8
  .byte  196,67,37,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm11,%ymm8
  .byte  196,65,45,86,192                    // vorpd         %ymm8,%ymm10,%ymm8
  .byte  196,65,53,86,192                    // vorpd         %ymm8,%ymm9,%ymm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           30a1 <_sk_store_8888_avx+0xa4>
  .byte  196,65,124,17,4,185                 // vmovups       %ymm8,(%r9,%rdi,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            309d <_sk_store_8888_avx+0xa0>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,84,0,0,0                   // lea           0x54(%rip),%r8        # 3110 <_sk_store_8888_avx+0x113>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,67,121,22,76,185,24,2           // vpextrd       $0x2,%xmm9,0x18(%r9,%rdi,4)
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,67,121,22,76,185,20,1           // vpextrd       $0x1,%xmm9,0x14(%r9,%rdi,4)
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,65,122,17,76,185,16             // vmovss        %xmm9,0x10(%r9,%rdi,4)
  .byte  196,67,121,22,68,185,12,3           // vpextrd       $0x3,%xmm8,0xc(%r9,%rdi,4)
  .byte  196,67,121,22,68,185,8,2            // vpextrd       $0x2,%xmm8,0x8(%r9,%rdi,4)
  .byte  196,67,121,22,68,185,4,1            // vpextrd       $0x1,%xmm8,0x4(%r9,%rdi,4)
  .byte  196,65,121,126,4,185                // vmovd         %xmm8,(%r9,%rdi,4)
  .byte  235,143                             // jmp           309d <_sk_store_8888_avx+0xa0>
  .byte  102,144                             // xchg          %ax,%ax
  .byte  246,255                             // idiv          %bh
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  238                                 // out           %al,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,230                             // jmpq          *%rsi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  222,255                             // fdivrp        %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,209                             // callq         *%rcx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,195                             // inc           %ebx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff
  .byte  181,255                             // mov           $0xff,%ch
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_f16_avx
.globl _sk_load_f16_avx
_sk_load_f16_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,17,1,0,0                     // jne           324b <_sk_load_f16_avx+0x11f>
  .byte  197,121,16,4,248                    // vmovupd       (%rax,%rdi,8),%xmm8
  .byte  197,249,16,84,248,16                // vmovupd       0x10(%rax,%rdi,8),%xmm2
  .byte  197,249,16,92,248,32                // vmovupd       0x20(%rax,%rdi,8),%xmm3
  .byte  197,122,111,76,248,48               // vmovdqu       0x30(%rax,%rdi,8),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,218                      // vpunpcklwd    %xmm2,%xmm0,%xmm11
  .byte  197,121,105,194                     // vpunpckhwd    %xmm2,%xmm0,%xmm8
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,113,105,203                     // vpunpckhwd    %xmm3,%xmm1,%xmm9
  .byte  197,161,108,194                     // vpunpcklqdq   %xmm2,%xmm11,%xmm0
  .byte  184,0,4,0,4                         // mov           $0x4000400,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,121,112,233,0                   // vpshufd       $0x0,%xmm1,%xmm13
  .byte  197,145,101,200                     // vpcmpgtw      %xmm0,%xmm13,%xmm1
  .byte  197,241,223,192                     // vpandn        %xmm0,%xmm1,%xmm0
  .byte  196,226,121,51,200                  // vpmovzxwd     %xmm0,%xmm1
  .byte  196,65,41,239,210                   // vpxor         %xmm10,%xmm10,%xmm10
  .byte  196,193,121,105,194                 // vpunpckhwd    %xmm10,%xmm0,%xmm0
  .byte  197,241,114,241,13                  // vpslld        $0xd,%xmm1,%xmm1
  .byte  197,249,114,240,13                  // vpslld        $0xd,%xmm0,%xmm0
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  184,0,0,128,119                     // mov           $0x77800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,225,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm12
  .byte  197,156,89,192                      // vmulps        %ymm0,%ymm12,%ymm0
  .byte  197,161,109,202                     // vpunpckhqdq   %xmm2,%xmm11,%xmm1
  .byte  197,145,101,209                     // vpcmpgtw      %xmm1,%xmm13,%xmm2
  .byte  197,233,223,201                     // vpandn        %xmm1,%xmm2,%xmm1
  .byte  196,226,121,51,209                  // vpmovzxwd     %xmm1,%xmm2
  .byte  196,193,113,105,202                 // vpunpckhwd    %xmm10,%xmm1,%xmm1
  .byte  197,233,114,242,13                  // vpslld        $0xd,%xmm2,%xmm2
  .byte  197,241,114,241,13                  // vpslld        $0xd,%xmm1,%xmm1
  .byte  196,227,109,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm2,%ymm1
  .byte  197,156,89,201                      // vmulps        %ymm1,%ymm12,%ymm1
  .byte  196,193,57,108,209                  // vpunpcklqdq   %xmm9,%xmm8,%xmm2
  .byte  197,145,101,218                     // vpcmpgtw      %xmm2,%xmm13,%xmm3
  .byte  197,225,223,210                     // vpandn        %xmm2,%xmm3,%xmm2
  .byte  196,226,121,51,218                  // vpmovzxwd     %xmm2,%xmm3
  .byte  196,193,105,105,210                 // vpunpckhwd    %xmm10,%xmm2,%xmm2
  .byte  197,225,114,243,13                  // vpslld        $0xd,%xmm3,%xmm3
  .byte  197,233,114,242,13                  // vpslld        $0xd,%xmm2,%xmm2
  .byte  196,227,101,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm3,%ymm2
  .byte  197,156,89,210                      // vmulps        %ymm2,%ymm12,%ymm2
  .byte  196,65,57,109,193                   // vpunpckhqdq   %xmm9,%xmm8,%xmm8
  .byte  196,193,17,101,216                  // vpcmpgtw      %xmm8,%xmm13,%xmm3
  .byte  196,193,97,223,216                  // vpandn        %xmm8,%xmm3,%xmm3
  .byte  196,98,121,51,195                   // vpmovzxwd     %xmm3,%xmm8
  .byte  196,193,97,105,218                  // vpunpckhwd    %xmm10,%xmm3,%xmm3
  .byte  196,193,57,114,240,13               // vpslld        $0xd,%xmm8,%xmm8
  .byte  197,225,114,243,13                  // vpslld        $0xd,%xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,156,89,219                      // vmulps        %ymm3,%ymm12,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,123,16,4,248                    // vmovsd        (%rax,%rdi,8),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,79                              // je            32aa <_sk_load_f16_avx+0x17e>
  .byte  197,57,22,68,248,8                  // vmovhpd       0x8(%rax,%rdi,8),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,67                              // jb            32aa <_sk_load_f16_avx+0x17e>
  .byte  197,251,16,84,248,16                // vmovsd        0x10(%rax,%rdi,8),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,68                              // je            32b7 <_sk_load_f16_avx+0x18b>
  .byte  197,233,22,84,248,24                // vmovhpd       0x18(%rax,%rdi,8),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,56                              // jb            32b7 <_sk_load_f16_avx+0x18b>
  .byte  197,251,16,92,248,32                // vmovsd        0x20(%rax,%rdi,8),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,194,254,255,255              // je            3151 <_sk_load_f16_avx+0x25>
  .byte  197,225,22,92,248,40                // vmovhpd       0x28(%rax,%rdi,8),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,178,254,255,255              // jb            3151 <_sk_load_f16_avx+0x25>
  .byte  197,122,126,76,248,48               // vmovq         0x30(%rax,%rdi,8),%xmm9
  .byte  233,167,254,255,255                 // jmpq          3151 <_sk_load_f16_avx+0x25>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,154,254,255,255                 // jmpq          3151 <_sk_load_f16_avx+0x25>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,145,254,255,255                 // jmpq          3151 <_sk_load_f16_avx+0x25>

HIDDEN _sk_gather_f16_avx
.globl _sk_gather_f16_avx
_sk_gather_f16_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,122,126,4,216               // vmovq         (%r8,%rbx,8),%xmm0
  .byte  196,129,122,126,12,240              // vmovq         (%r8,%r14,8),%xmm1
  .byte  197,113,108,200                     // vpunpcklqdq   %xmm0,%xmm1,%xmm9
  .byte  196,129,122,126,12,248              // vmovq         (%r8,%r15,8),%xmm1
  .byte  196,129,122,126,20,224              // vmovq         (%r8,%r12,8),%xmm2
  .byte  197,233,108,201                     // vpunpcklqdq   %xmm1,%xmm2,%xmm1
  .byte  196,129,122,126,20,208              // vmovq         (%r8,%r10,8),%xmm2
  .byte  196,129,122,126,28,216              // vmovq         (%r8,%r11,8),%xmm3
  .byte  197,97,108,210                      // vpunpcklqdq   %xmm2,%xmm3,%xmm10
  .byte  196,65,122,126,4,192                // vmovq         (%r8,%rax,8),%xmm8
  .byte  196,129,122,126,28,200              // vmovq         (%r8,%r9,8),%xmm3
  .byte  196,193,97,108,216                  // vpunpcklqdq   %xmm8,%xmm3,%xmm3
  .byte  197,177,97,193                      // vpunpcklwd    %xmm1,%xmm9,%xmm0
  .byte  197,177,105,201                     // vpunpckhwd    %xmm1,%xmm9,%xmm1
  .byte  197,169,97,211                      // vpunpcklwd    %xmm3,%xmm10,%xmm2
  .byte  197,169,105,219                     // vpunpckhwd    %xmm3,%xmm10,%xmm3
  .byte  197,121,97,217                      // vpunpcklwd    %xmm1,%xmm0,%xmm11
  .byte  197,121,105,193                     // vpunpckhwd    %xmm1,%xmm0,%xmm8
  .byte  197,233,97,203                      // vpunpcklwd    %xmm3,%xmm2,%xmm1
  .byte  197,105,105,203                     // vpunpckhwd    %xmm3,%xmm2,%xmm9
  .byte  197,161,108,193                     // vpunpcklqdq   %xmm1,%xmm11,%xmm0
  .byte  184,0,4,0,4                         // mov           $0x4000400,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,121,112,234,0                   // vpshufd       $0x0,%xmm2,%xmm13
  .byte  197,145,101,208                     // vpcmpgtw      %xmm0,%xmm13,%xmm2
  .byte  197,233,223,192                     // vpandn        %xmm0,%xmm2,%xmm0
  .byte  196,226,121,51,208                  // vpmovzxwd     %xmm0,%xmm2
  .byte  196,65,41,239,210                   // vpxor         %xmm10,%xmm10,%xmm10
  .byte  196,193,121,105,194                 // vpunpckhwd    %xmm10,%xmm0,%xmm0
  .byte  197,233,114,242,13                  // vpslld        $0xd,%xmm2,%xmm2
  .byte  197,249,114,240,13                  // vpslld        $0xd,%xmm0,%xmm0
  .byte  196,227,109,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm2,%ymm0
  .byte  184,0,0,128,119                     // mov           $0x77800000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,249,112,210,0                   // vpshufd       $0x0,%xmm2,%xmm2
  .byte  196,99,109,24,226,1                 // vinsertf128   $0x1,%xmm2,%ymm2,%ymm12
  .byte  197,156,89,192                      // vmulps        %ymm0,%ymm12,%ymm0
  .byte  197,161,109,201                     // vpunpckhqdq   %xmm1,%xmm11,%xmm1
  .byte  197,145,101,209                     // vpcmpgtw      %xmm1,%xmm13,%xmm2
  .byte  197,233,223,201                     // vpandn        %xmm1,%xmm2,%xmm1
  .byte  196,226,121,51,209                  // vpmovzxwd     %xmm1,%xmm2
  .byte  196,193,113,105,202                 // vpunpckhwd    %xmm10,%xmm1,%xmm1
  .byte  197,233,114,242,13                  // vpslld        $0xd,%xmm2,%xmm2
  .byte  197,241,114,241,13                  // vpslld        $0xd,%xmm1,%xmm1
  .byte  196,227,109,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm2,%ymm1
  .byte  197,156,89,201                      // vmulps        %ymm1,%ymm12,%ymm1
  .byte  196,193,57,108,209                  // vpunpcklqdq   %xmm9,%xmm8,%xmm2
  .byte  197,145,101,218                     // vpcmpgtw      %xmm2,%xmm13,%xmm3
  .byte  197,225,223,210                     // vpandn        %xmm2,%xmm3,%xmm2
  .byte  196,226,121,51,218                  // vpmovzxwd     %xmm2,%xmm3
  .byte  196,193,105,105,210                 // vpunpckhwd    %xmm10,%xmm2,%xmm2
  .byte  197,225,114,243,13                  // vpslld        $0xd,%xmm3,%xmm3
  .byte  197,233,114,242,13                  // vpslld        $0xd,%xmm2,%xmm2
  .byte  196,227,101,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm3,%ymm2
  .byte  197,156,89,210                      // vmulps        %ymm2,%ymm12,%ymm2
  .byte  196,65,57,109,193                   // vpunpckhqdq   %xmm9,%xmm8,%xmm8
  .byte  196,193,17,101,216                  // vpcmpgtw      %xmm8,%xmm13,%xmm3
  .byte  196,193,97,223,216                  // vpandn        %xmm8,%xmm3,%xmm3
  .byte  196,98,121,51,195                   // vpmovzxwd     %xmm3,%xmm8
  .byte  196,193,97,105,218                  // vpunpckhwd    %xmm10,%xmm3,%xmm3
  .byte  196,193,57,114,240,13               // vpslld        $0xd,%xmm8,%xmm8
  .byte  197,225,114,243,13                  // vpslld        $0xd,%xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,156,89,219                      // vmulps        %ymm3,%ymm12,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_avx
.globl _sk_store_f16_avx
_sk_store_f16_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  184,0,0,128,7                       // mov           $0x7800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,65,121,112,192,0                // vpshufd       $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,67,125,25,202,1                 // vextractf128  $0x1,%ymm9,%xmm10
  .byte  196,193,41,114,210,13               // vpsrld        $0xd,%xmm10,%xmm10
  .byte  196,193,49,114,209,13               // vpsrld        $0xd,%xmm9,%xmm9
  .byte  196,66,49,43,202                    // vpackusdw     %xmm10,%xmm9,%xmm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,67,125,25,211,1                 // vextractf128  $0x1,%ymm10,%xmm11
  .byte  196,193,33,114,211,13               // vpsrld        $0xd,%xmm11,%xmm11
  .byte  196,193,41,114,210,13               // vpsrld        $0xd,%xmm10,%xmm10
  .byte  196,66,41,43,211                    // vpackusdw     %xmm11,%xmm10,%xmm10
  .byte  197,60,89,218                       // vmulps        %ymm2,%ymm8,%ymm11
  .byte  196,67,125,25,220,1                 // vextractf128  $0x1,%ymm11,%xmm12
  .byte  196,193,25,114,212,13               // vpsrld        $0xd,%xmm12,%xmm12
  .byte  196,193,33,114,211,13               // vpsrld        $0xd,%xmm11,%xmm11
  .byte  196,66,33,43,220                    // vpackusdw     %xmm12,%xmm11,%xmm11
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,67,125,25,196,1                 // vextractf128  $0x1,%ymm8,%xmm12
  .byte  196,193,25,114,212,13               // vpsrld        $0xd,%xmm12,%xmm12
  .byte  196,193,57,114,208,13               // vpsrld        $0xd,%xmm8,%xmm8
  .byte  196,66,57,43,196                    // vpackusdw     %xmm12,%xmm8,%xmm8
  .byte  196,65,49,97,226                    // vpunpcklwd    %xmm10,%xmm9,%xmm12
  .byte  196,65,49,105,234                   // vpunpckhwd    %xmm10,%xmm9,%xmm13
  .byte  196,65,33,97,200                    // vpunpcklwd    %xmm8,%xmm11,%xmm9
  .byte  196,65,33,105,192                   // vpunpckhwd    %xmm8,%xmm11,%xmm8
  .byte  196,65,25,98,217                    // vpunpckldq    %xmm9,%xmm12,%xmm11
  .byte  196,65,25,106,209                   // vpunpckhdq    %xmm9,%xmm12,%xmm10
  .byte  196,65,17,98,200                    // vpunpckldq    %xmm8,%xmm13,%xmm9
  .byte  196,65,17,106,192                   // vpunpckhdq    %xmm8,%xmm13,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,31                              // jne           3540 <_sk_store_f16_avx+0xd2>
  .byte  196,65,120,17,28,248                // vmovups       %xmm11,(%r8,%rdi,8)
  .byte  196,65,120,17,84,248,16             // vmovups       %xmm10,0x10(%r8,%rdi,8)
  .byte  196,65,120,17,76,248,32             // vmovups       %xmm9,0x20(%r8,%rdi,8)
  .byte  196,65,122,127,68,248,48            // vmovdqu       %xmm8,0x30(%r8,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,121,214,28,248               // vmovq         %xmm11,(%r8,%rdi,8)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            353c <_sk_store_f16_avx+0xce>
  .byte  196,65,121,23,92,248,8              // vmovhpd       %xmm11,0x8(%r8,%rdi,8)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            353c <_sk_store_f16_avx+0xce>
  .byte  196,65,121,214,84,248,16            // vmovq         %xmm10,0x10(%r8,%rdi,8)
  .byte  116,218                             // je            353c <_sk_store_f16_avx+0xce>
  .byte  196,65,121,23,84,248,24             // vmovhpd       %xmm10,0x18(%r8,%rdi,8)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            353c <_sk_store_f16_avx+0xce>
  .byte  196,65,121,214,76,248,32            // vmovq         %xmm9,0x20(%r8,%rdi,8)
  .byte  116,196                             // je            353c <_sk_store_f16_avx+0xce>
  .byte  196,65,121,23,76,248,40             // vmovhpd       %xmm9,0x28(%r8,%rdi,8)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,183                             // jb            353c <_sk_store_f16_avx+0xce>
  .byte  196,65,121,214,68,248,48            // vmovq         %xmm8,0x30(%r8,%rdi,8)
  .byte  235,174                             // jmp           353c <_sk_store_f16_avx+0xce>

HIDDEN _sk_load_u16_be_avx
.globl _sk_load_u16_be_avx
_sk_load_u16_be_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,1,1,0,0                      // jne           369d <_sk_load_u16_be_avx+0x10f>
  .byte  197,121,16,4,248                    // vmovupd       (%rax,%rdi,8),%xmm8
  .byte  197,249,16,84,248,16                // vmovupd       0x10(%rax,%rdi,8),%xmm2
  .byte  197,249,16,92,248,32                // vmovupd       0x20(%rax,%rdi,8),%xmm3
  .byte  197,122,111,76,248,48               // vmovdqu       0x30(%rax,%rdi,8),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,210                      // vpunpcklwd    %xmm2,%xmm0,%xmm10
  .byte  197,121,105,194                     // vpunpckhwd    %xmm2,%xmm0,%xmm8
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,113,105,203                     // vpunpckhwd    %xmm3,%xmm1,%xmm9
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,224,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm12
  .byte  197,169,108,194                     // vpunpcklqdq   %xmm2,%xmm10,%xmm0
  .byte  197,241,113,240,8                   // vpsllw        $0x8,%xmm0,%xmm1
  .byte  197,249,113,208,8                   // vpsrlw        $0x8,%xmm0,%xmm0
  .byte  197,241,235,192                     // vpor          %xmm0,%xmm1,%xmm0
  .byte  196,65,33,239,219                   // vpxor         %xmm11,%xmm11,%xmm11
  .byte  196,193,121,105,203                 // vpunpckhwd    %xmm11,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  197,156,89,192                      // vmulps        %ymm0,%ymm12,%ymm0
  .byte  197,169,109,202                     // vpunpckhqdq   %xmm2,%xmm10,%xmm1
  .byte  197,233,113,241,8                   // vpsllw        $0x8,%xmm1,%xmm2
  .byte  197,241,113,209,8                   // vpsrlw        $0x8,%xmm1,%xmm1
  .byte  197,233,235,201                     // vpor          %xmm1,%xmm2,%xmm1
  .byte  196,193,113,105,211                 // vpunpckhwd    %xmm11,%xmm1,%xmm2
  .byte  196,226,121,51,201                  // vpmovzxwd     %xmm1,%xmm1
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,156,89,201                      // vmulps        %ymm1,%ymm12,%ymm1
  .byte  196,193,57,108,209                  // vpunpcklqdq   %xmm9,%xmm8,%xmm2
  .byte  197,169,113,242,8                   // vpsllw        $0x8,%xmm2,%xmm10
  .byte  197,233,113,210,8                   // vpsrlw        $0x8,%xmm2,%xmm2
  .byte  197,169,235,210                     // vpor          %xmm2,%xmm10,%xmm2
  .byte  196,65,105,105,211                  // vpunpckhwd    %xmm11,%xmm2,%xmm10
  .byte  196,226,121,51,210                  // vpmovzxwd     %xmm2,%xmm2
  .byte  196,195,109,24,210,1                // vinsertf128   $0x1,%xmm10,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,156,89,210                      // vmulps        %ymm2,%ymm12,%ymm2
  .byte  196,193,57,109,217                  // vpunpckhqdq   %xmm9,%xmm8,%xmm3
  .byte  197,185,113,243,8                   // vpsllw        $0x8,%xmm3,%xmm8
  .byte  197,225,113,211,8                   // vpsrlw        $0x8,%xmm3,%xmm3
  .byte  197,185,235,219                     // vpor          %xmm3,%xmm8,%xmm3
  .byte  196,65,97,105,195                   // vpunpckhwd    %xmm11,%xmm3,%xmm8
  .byte  196,226,121,51,219                  // vpmovzxwd     %xmm3,%xmm3
  .byte  196,195,101,24,216,1                // vinsertf128   $0x1,%xmm8,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,156,89,219                      // vmulps        %ymm3,%ymm12,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,123,16,4,248                    // vmovsd        (%rax,%rdi,8),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,79                              // je            36fc <_sk_load_u16_be_avx+0x16e>
  .byte  197,57,22,68,248,8                  // vmovhpd       0x8(%rax,%rdi,8),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,67                              // jb            36fc <_sk_load_u16_be_avx+0x16e>
  .byte  197,251,16,84,248,16                // vmovsd        0x10(%rax,%rdi,8),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,68                              // je            3709 <_sk_load_u16_be_avx+0x17b>
  .byte  197,233,22,84,248,24                // vmovhpd       0x18(%rax,%rdi,8),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,56                              // jb            3709 <_sk_load_u16_be_avx+0x17b>
  .byte  197,251,16,92,248,32                // vmovsd        0x20(%rax,%rdi,8),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,210,254,255,255              // je            35b3 <_sk_load_u16_be_avx+0x25>
  .byte  197,225,22,92,248,40                // vmovhpd       0x28(%rax,%rdi,8),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,194,254,255,255              // jb            35b3 <_sk_load_u16_be_avx+0x25>
  .byte  197,122,126,76,248,48               // vmovq         0x30(%rax,%rdi,8),%xmm9
  .byte  233,183,254,255,255                 // jmpq          35b3 <_sk_load_u16_be_avx+0x25>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,170,254,255,255                 // jmpq          35b3 <_sk_load_u16_be_avx+0x25>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,161,254,255,255                 // jmpq          35b3 <_sk_load_u16_be_avx+0x25>

HIDDEN _sk_store_u16_be_avx
.globl _sk_store_u16_be_avx
_sk_store_u16_be_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  184,0,255,127,71                    // mov           $0x477fff00,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,67,125,25,202,1                 // vextractf128  $0x1,%ymm9,%xmm10
  .byte  196,66,49,43,202                    // vpackusdw     %xmm10,%xmm9,%xmm9
  .byte  196,193,41,113,241,8                // vpsllw        $0x8,%xmm9,%xmm10
  .byte  196,193,49,113,209,8                // vpsrlw        $0x8,%xmm9,%xmm9
  .byte  196,65,41,235,201                   // vpor          %xmm9,%xmm10,%xmm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,67,125,25,211,1                 // vextractf128  $0x1,%ymm10,%xmm11
  .byte  196,66,41,43,211                    // vpackusdw     %xmm11,%xmm10,%xmm10
  .byte  196,193,33,113,242,8                // vpsllw        $0x8,%xmm10,%xmm11
  .byte  196,193,41,113,210,8                // vpsrlw        $0x8,%xmm10,%xmm10
  .byte  196,65,33,235,210                   // vpor          %xmm10,%xmm11,%xmm10
  .byte  197,60,89,218                       // vmulps        %ymm2,%ymm8,%ymm11
  .byte  196,65,125,91,219                   // vcvtps2dq     %ymm11,%ymm11
  .byte  196,67,125,25,220,1                 // vextractf128  $0x1,%ymm11,%xmm12
  .byte  196,66,33,43,220                    // vpackusdw     %xmm12,%xmm11,%xmm11
  .byte  196,193,25,113,243,8                // vpsllw        $0x8,%xmm11,%xmm12
  .byte  196,193,33,113,211,8                // vpsrlw        $0x8,%xmm11,%xmm11
  .byte  196,65,25,235,219                   // vpor          %xmm11,%xmm12,%xmm11
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,196,1                 // vextractf128  $0x1,%ymm8,%xmm12
  .byte  196,66,57,43,196                    // vpackusdw     %xmm12,%xmm8,%xmm8
  .byte  196,193,25,113,240,8                // vpsllw        $0x8,%xmm8,%xmm12
  .byte  196,193,57,113,208,8                // vpsrlw        $0x8,%xmm8,%xmm8
  .byte  196,65,25,235,192                   // vpor          %xmm8,%xmm12,%xmm8
  .byte  196,65,49,97,226                    // vpunpcklwd    %xmm10,%xmm9,%xmm12
  .byte  196,65,49,105,234                   // vpunpckhwd    %xmm10,%xmm9,%xmm13
  .byte  196,65,33,97,200                    // vpunpcklwd    %xmm8,%xmm11,%xmm9
  .byte  196,65,33,105,192                   // vpunpckhwd    %xmm8,%xmm11,%xmm8
  .byte  196,65,25,98,217                    // vpunpckldq    %xmm9,%xmm12,%xmm11
  .byte  196,65,25,106,209                   // vpunpckhdq    %xmm9,%xmm12,%xmm10
  .byte  196,65,17,98,200                    // vpunpckldq    %xmm8,%xmm13,%xmm9
  .byte  196,65,17,106,192                   // vpunpckhdq    %xmm8,%xmm13,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,31                              // jne           380c <_sk_store_u16_be_avx+0xfa>
  .byte  196,65,120,17,28,248                // vmovups       %xmm11,(%r8,%rdi,8)
  .byte  196,65,120,17,84,248,16             // vmovups       %xmm10,0x10(%r8,%rdi,8)
  .byte  196,65,120,17,76,248,32             // vmovups       %xmm9,0x20(%r8,%rdi,8)
  .byte  196,65,122,127,68,248,48            // vmovdqu       %xmm8,0x30(%r8,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,121,214,28,248               // vmovq         %xmm11,(%r8,%rdi,8)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            3808 <_sk_store_u16_be_avx+0xf6>
  .byte  196,65,121,23,92,248,8              // vmovhpd       %xmm11,0x8(%r8,%rdi,8)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            3808 <_sk_store_u16_be_avx+0xf6>
  .byte  196,65,121,214,84,248,16            // vmovq         %xmm10,0x10(%r8,%rdi,8)
  .byte  116,218                             // je            3808 <_sk_store_u16_be_avx+0xf6>
  .byte  196,65,121,23,84,248,24             // vmovhpd       %xmm10,0x18(%r8,%rdi,8)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            3808 <_sk_store_u16_be_avx+0xf6>
  .byte  196,65,121,214,76,248,32            // vmovq         %xmm9,0x20(%r8,%rdi,8)
  .byte  116,196                             // je            3808 <_sk_store_u16_be_avx+0xf6>
  .byte  196,65,121,23,76,248,40             // vmovhpd       %xmm9,0x28(%r8,%rdi,8)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,183                             // jb            3808 <_sk_store_u16_be_avx+0xf6>
  .byte  196,65,121,214,68,248,48            // vmovq         %xmm8,0x30(%r8,%rdi,8)
  .byte  235,174                             // jmp           3808 <_sk_store_u16_be_avx+0xf6>

HIDDEN _sk_load_f32_avx
.globl _sk_load_f32_avx
_sk_load_f32_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  119,110                             // ja            38d0 <_sk_load_f32_avx+0x76>
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,141,21,132,0,0,0                 // lea           0x84(%rip),%r10        # 38f8 <_sk_load_f32_avx+0x9e>
  .byte  73,99,4,138                         // movslq        (%r10,%rcx,4),%rax
  .byte  76,1,208                            // add           %r10,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,3,125,24,68,136,112,1           // vinsertf128   $0x1,0x70(%r8,%r9,4),%ymm0,%ymm8
  .byte  196,131,125,24,92,136,96,1          // vinsertf128   $0x1,0x60(%r8,%r9,4),%ymm0,%ymm3
  .byte  196,131,125,24,76,136,80,1          // vinsertf128   $0x1,0x50(%r8,%r9,4),%ymm0,%ymm1
  .byte  196,131,125,24,84,136,64,1          // vinsertf128   $0x1,0x40(%r8,%r9,4),%ymm0,%ymm2
  .byte  196,129,121,16,68,136,48            // vmovupd       0x30(%r8,%r9,4),%xmm0
  .byte  196,195,125,13,192,12               // vblendpd      $0xc,%ymm8,%ymm0,%ymm0
  .byte  196,1,121,16,68,136,32              // vmovupd       0x20(%r8,%r9,4),%xmm8
  .byte  196,99,61,13,203,12                 // vblendpd      $0xc,%ymm3,%ymm8,%ymm9
  .byte  196,129,121,16,92,136,16            // vmovupd       0x10(%r8,%r9,4),%xmm3
  .byte  196,99,101,13,209,12                // vblendpd      $0xc,%ymm1,%ymm3,%ymm10
  .byte  196,129,121,16,12,136               // vmovupd       (%r8,%r9,4),%xmm1
  .byte  196,227,117,13,202,12               // vblendpd      $0xc,%ymm2,%ymm1,%ymm1
  .byte  196,193,116,20,210                  // vunpcklps     %ymm10,%ymm1,%ymm2
  .byte  196,193,116,21,218                  // vunpckhps     %ymm10,%ymm1,%ymm3
  .byte  197,180,20,200                      // vunpcklps     %ymm0,%ymm9,%ymm1
  .byte  197,52,21,192                       // vunpckhps     %ymm0,%ymm9,%ymm8
  .byte  197,237,20,193                      // vunpcklpd     %ymm1,%ymm2,%ymm0
  .byte  197,237,21,201                      // vunpckhpd     %ymm1,%ymm2,%ymm1
  .byte  196,193,101,20,208                  // vunpcklpd     %ymm8,%ymm3,%ymm2
  .byte  196,193,101,21,216                  // vunpckhpd     %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  133,255                             // test          %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,204                             // dec           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  191,255,255,255,178                 // mov           $0xb2ffffff,%edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,165,255,255,255,157             // jmpq          *-0x62000001(%rbp)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,149,255,255,255,141             // callq         *-0x72000001(%rbp)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_store_f32_avx
.globl _sk_store_f32_avx
_sk_store_f32_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,189,0,0,0,0                // lea           0x0(,%rdi,4),%rax
  .byte  197,124,20,193                      // vunpcklps     %ymm1,%ymm0,%ymm8
  .byte  197,124,21,217                      // vunpckhps     %ymm1,%ymm0,%ymm11
  .byte  197,108,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm9
  .byte  197,108,21,227                      // vunpckhps     %ymm3,%ymm2,%ymm12
  .byte  196,65,61,20,209                    // vunpcklpd     %ymm9,%ymm8,%ymm10
  .byte  196,65,61,21,201                    // vunpckhpd     %ymm9,%ymm8,%ymm9
  .byte  196,65,37,20,196                    // vunpcklpd     %ymm12,%ymm11,%ymm8
  .byte  196,65,37,21,220                    // vunpckhpd     %ymm12,%ymm11,%ymm11
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,55                              // jne           3985 <_sk_store_f32_avx+0x6d>
  .byte  196,67,45,24,225,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm12
  .byte  196,67,61,24,235,1                  // vinsertf128   $0x1,%xmm11,%ymm8,%ymm13
  .byte  196,67,45,6,201,49                  // vperm2f128    $0x31,%ymm9,%ymm10,%ymm9
  .byte  196,67,61,6,195,49                  // vperm2f128    $0x31,%ymm11,%ymm8,%ymm8
  .byte  196,65,125,17,36,128                // vmovupd       %ymm12,(%r8,%rax,4)
  .byte  196,65,125,17,108,128,32            // vmovupd       %ymm13,0x20(%r8,%rax,4)
  .byte  196,65,125,17,76,128,64             // vmovupd       %ymm9,0x40(%r8,%rax,4)
  .byte  196,65,125,17,68,128,96             // vmovupd       %ymm8,0x60(%r8,%rax,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,121,17,20,128                // vmovupd       %xmm10,(%r8,%rax,4)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            3981 <_sk_store_f32_avx+0x69>
  .byte  196,65,121,17,76,128,16             // vmovupd       %xmm9,0x10(%r8,%rax,4)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            3981 <_sk_store_f32_avx+0x69>
  .byte  196,65,121,17,68,128,32             // vmovupd       %xmm8,0x20(%r8,%rax,4)
  .byte  116,218                             // je            3981 <_sk_store_f32_avx+0x69>
  .byte  196,65,121,17,92,128,48             // vmovupd       %xmm11,0x30(%r8,%rax,4)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            3981 <_sk_store_f32_avx+0x69>
  .byte  196,67,125,25,84,128,64,1           // vextractf128  $0x1,%ymm10,0x40(%r8,%rax,4)
  .byte  116,195                             // je            3981 <_sk_store_f32_avx+0x69>
  .byte  196,67,125,25,76,128,80,1           // vextractf128  $0x1,%ymm9,0x50(%r8,%rax,4)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,181                             // jb            3981 <_sk_store_f32_avx+0x69>
  .byte  196,67,125,25,68,128,96,1           // vextractf128  $0x1,%ymm8,0x60(%r8,%rax,4)
  .byte  235,171                             // jmp           3981 <_sk_store_f32_avx+0x69>

HIDDEN _sk_clamp_x_avx
.globl _sk_clamp_x_avx
_sk_clamp_x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,95,200                       // vmaxps        %ymm0,%ymm8,%ymm9
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,121,254,194                 // vpaddd        %xmm10,%xmm0,%xmm0
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm8,%ymm0
  .byte  197,180,93,192                      // vminps        %ymm0,%ymm9,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_avx
.globl _sk_clamp_y_avx
_sk_clamp_y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,95,201                       // vmaxps        %ymm1,%ymm8,%ymm9
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,99,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm1
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,113,254,202                 // vpaddd        %xmm10,%xmm1,%xmm1
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm8,%ymm1
  .byte  197,180,93,201                      // vminps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_avx
.globl _sk_repeat_x_avx
_sk_repeat_x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,124,94,200                   // vdivps        %ymm8,%ymm0,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,124,92,201                   // vsubps        %ymm9,%ymm0,%ymm9
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,121,254,194                 // vpaddd        %xmm10,%xmm0,%xmm0
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm8,%ymm0
  .byte  197,180,93,192                      // vminps        %ymm0,%ymm9,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_avx
.globl _sk_repeat_y_avx
_sk_repeat_y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,116,94,200                   // vdivps        %ymm8,%ymm1,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,116,92,201                   // vsubps        %ymm9,%ymm1,%ymm9
  .byte  196,99,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm1
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,113,254,202                 // vpaddd        %xmm10,%xmm1,%xmm1
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm8,%ymm1
  .byte  197,180,93,201                      // vminps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_avx
.globl _sk_mirror_x_avx
_sk_mirror_x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,121,110,0                       // vmovd         (%rax),%xmm8
  .byte  196,65,121,112,200,0                // vpshufd       $0x0,%xmm8,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,124,92,209                   // vsubps        %ymm9,%ymm0,%ymm10
  .byte  196,193,58,88,192                   // vaddss        %xmm8,%xmm8,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,44,94,192                       // vdivps        %ymm0,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,172,92,192                      // vsubps        %ymm0,%ymm10,%ymm0
  .byte  196,193,124,92,193                  // vsubps        %ymm9,%ymm0,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,192                       // vsubps        %ymm0,%ymm8,%ymm8
  .byte  197,60,84,192                       // vandps        %ymm0,%ymm8,%ymm8
  .byte  196,99,125,25,200,1                 // vextractf128  $0x1,%ymm9,%xmm0
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,121,254,194                 // vpaddd        %xmm10,%xmm0,%xmm0
  .byte  196,65,49,254,202                   // vpaddd        %xmm10,%xmm9,%xmm9
  .byte  196,227,53,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm9,%ymm0
  .byte  197,188,93,192                      // vminps        %ymm0,%ymm8,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_avx
.globl _sk_mirror_y_avx
_sk_mirror_y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,121,110,0                       // vmovd         (%rax),%xmm8
  .byte  196,65,121,112,200,0                // vpshufd       $0x0,%xmm8,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,116,92,209                   // vsubps        %ymm9,%ymm1,%ymm10
  .byte  196,193,58,88,200                   // vaddss        %xmm8,%xmm8,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,44,94,193                       // vdivps        %ymm1,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,172,92,201                      // vsubps        %ymm1,%ymm10,%ymm1
  .byte  196,193,116,92,201                  // vsubps        %ymm9,%ymm1,%ymm1
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,193                       // vsubps        %ymm1,%ymm8,%ymm8
  .byte  197,60,84,193                       // vandps        %ymm1,%ymm8,%ymm8
  .byte  196,99,125,25,201,1                 // vextractf128  $0x1,%ymm9,%xmm1
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,113,254,202                 // vpaddd        %xmm10,%xmm1,%xmm1
  .byte  196,65,49,254,202                   // vpaddd        %xmm10,%xmm9,%xmm9
  .byte  196,227,53,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm9,%ymm1
  .byte  197,188,93,201                      // vminps        %ymm1,%ymm8,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_avx
.globl _sk_luminance_to_alpha_avx
_sk_luminance_to_alpha_avx:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,89,192                      // vmulps        %ymm0,%ymm3,%ymm0
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,89,201                      // vmulps        %ymm1,%ymm3,%ymm1
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  197,252,88,217                      // vaddps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_avx
.globl _sk_matrix_2x3_avx
_sk_matrix_2x3_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,8                  // vbroadcastss  0x8(%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,12                 // vbroadcastss  0xc(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,252,88,201                      // vaddps        %ymm1,%ymm0,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_avx
.globl _sk_matrix_3x4_avx
_sk_matrix_3x4_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,98,125,24,88,36                 // vbroadcastss  0x24(%rax),%ymm11
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  196,98,125,24,88,28                 // vbroadcastss  0x1c(%rax),%ymm11
  .byte  196,98,125,24,96,40                 // vbroadcastss  0x28(%rax),%ymm12
  .byte  197,36,89,218                       // vmulps        %ymm2,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,200                       // vmulps        %ymm0,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,98,125,24,96,32                 // vbroadcastss  0x20(%rax),%ymm12
  .byte  196,98,125,24,104,44                // vbroadcastss  0x2c(%rax),%ymm13
  .byte  197,156,89,210                      // vmulps        %ymm2,%ymm12,%ymm2
  .byte  196,193,108,88,213                  // vaddps        %ymm13,%ymm2,%ymm2
  .byte  197,164,89,201                      // vmulps        %ymm1,%ymm11,%ymm1
  .byte  197,244,88,202                      // vaddps        %ymm2,%ymm1,%ymm1
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,252,88,209                      // vaddps        %ymm1,%ymm0,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_avx
.globl _sk_matrix_4x5_avx
_sk_matrix_4x5_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,16                 // vbroadcastss  0x10(%rax),%ymm9
  .byte  196,98,125,24,80,32                 // vbroadcastss  0x20(%rax),%ymm10
  .byte  196,98,125,24,88,48                 // vbroadcastss  0x30(%rax),%ymm11
  .byte  196,98,125,24,96,64                 // vbroadcastss  0x40(%rax),%ymm12
  .byte  197,36,89,219                       // vmulps        %ymm3,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,98,125,24,88,36                 // vbroadcastss  0x24(%rax),%ymm11
  .byte  196,98,125,24,96,52                 // vbroadcastss  0x34(%rax),%ymm12
  .byte  196,98,125,24,104,68                // vbroadcastss  0x44(%rax),%ymm13
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  197,36,89,218                       // vmulps        %ymm2,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,200                       // vmulps        %ymm0,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,98,125,24,88,24                 // vbroadcastss  0x18(%rax),%ymm11
  .byte  196,98,125,24,96,40                 // vbroadcastss  0x28(%rax),%ymm12
  .byte  196,98,125,24,104,56                // vbroadcastss  0x38(%rax),%ymm13
  .byte  196,98,125,24,112,72                // vbroadcastss  0x48(%rax),%ymm14
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  196,65,20,88,238                    // vaddps        %ymm14,%ymm13,%ymm13
  .byte  197,28,89,226                       // vmulps        %ymm2,%ymm12,%ymm12
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  197,36,89,217                       // vmulps        %ymm1,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,208                       // vmulps        %ymm0,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,98,125,24,88,12                 // vbroadcastss  0xc(%rax),%ymm11
  .byte  196,98,125,24,96,28                 // vbroadcastss  0x1c(%rax),%ymm12
  .byte  196,98,125,24,104,44                // vbroadcastss  0x2c(%rax),%ymm13
  .byte  196,98,125,24,112,60                // vbroadcastss  0x3c(%rax),%ymm14
  .byte  196,98,125,24,120,76                // vbroadcastss  0x4c(%rax),%ymm15
  .byte  197,140,89,219                      // vmulps        %ymm3,%ymm14,%ymm3
  .byte  196,193,100,88,223                  // vaddps        %ymm15,%ymm3,%ymm3
  .byte  197,148,89,210                      // vmulps        %ymm2,%ymm13,%ymm2
  .byte  197,236,88,211                      // vaddps        %ymm3,%ymm2,%ymm2
  .byte  197,156,89,201                      // vmulps        %ymm1,%ymm12,%ymm1
  .byte  197,244,88,202                      // vaddps        %ymm2,%ymm1,%ymm1
  .byte  197,164,89,192                      // vmulps        %ymm0,%ymm11,%ymm0
  .byte  197,252,88,217                      // vaddps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  197,124,41,210                      // vmovaps       %ymm10,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_avx
.globl _sk_matrix_perspective_avx
_sk_matrix_perspective_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,200                       // vmulps        %ymm0,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,98,125,24,88,28                 // vbroadcastss  0x1c(%rax),%ymm11
  .byte  196,98,125,24,96,32                 // vbroadcastss  0x20(%rax),%ymm12
  .byte  197,164,89,201                      // vmulps        %ymm1,%ymm11,%ymm1
  .byte  196,193,116,88,204                  // vaddps        %ymm12,%ymm1,%ymm1
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  197,252,83,200                      // vrcpps        %ymm0,%ymm1
  .byte  197,188,89,193                      // vmulps        %ymm1,%ymm8,%ymm0
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_avx
.globl _sk_linear_gradient_avx
_sk_linear_gradient_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,226,125,24,72,20                // vbroadcastss  0x14(%rax),%ymm1
  .byte  196,226,125,24,80,24                // vbroadcastss  0x18(%rax),%ymm2
  .byte  196,226,125,24,88,28                // vbroadcastss  0x1c(%rax),%ymm3
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  15,132,146,0,0,0                    // je            3f39 <_sk_linear_gradient_avx+0xb8>
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  196,65,36,87,219                    // vxorps        %ymm11,%ymm11,%ymm11
  .byte  196,98,125,24,104,224               // vbroadcastss  -0x20(%rax),%ymm13
  .byte  196,65,124,194,237,1                // vcmpltps      %ymm13,%ymm0,%ymm13
  .byte  196,98,125,24,112,228               // vbroadcastss  -0x1c(%rax),%ymm14
  .byte  196,67,13,74,228,208                // vblendvps     %ymm13,%ymm12,%ymm14,%ymm12
  .byte  196,98,125,24,112,232               // vbroadcastss  -0x18(%rax),%ymm14
  .byte  196,67,13,74,219,208                // vblendvps     %ymm13,%ymm11,%ymm14,%ymm11
  .byte  196,98,125,24,112,236               // vbroadcastss  -0x14(%rax),%ymm14
  .byte  196,67,13,74,210,208                // vblendvps     %ymm13,%ymm10,%ymm14,%ymm10
  .byte  196,98,125,24,112,240               // vbroadcastss  -0x10(%rax),%ymm14
  .byte  196,67,13,74,201,208                // vblendvps     %ymm13,%ymm9,%ymm14,%ymm9
  .byte  196,98,125,24,112,244               // vbroadcastss  -0xc(%rax),%ymm14
  .byte  196,67,13,74,192,208                // vblendvps     %ymm13,%ymm8,%ymm14,%ymm8
  .byte  196,98,125,24,112,248               // vbroadcastss  -0x8(%rax),%ymm14
  .byte  196,227,13,74,201,208               // vblendvps     %ymm13,%ymm1,%ymm14,%ymm1
  .byte  196,98,125,24,112,252               // vbroadcastss  -0x4(%rax),%ymm14
  .byte  196,227,13,74,210,208               // vblendvps     %ymm13,%ymm2,%ymm14,%ymm2
  .byte  196,98,125,24,48                    // vbroadcastss  (%rax),%ymm14
  .byte  196,227,13,74,219,208               // vblendvps     %ymm13,%ymm3,%ymm14,%ymm3
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  73,255,200                          // dec           %r8
  .byte  117,140                             // jne           3ec3 <_sk_linear_gradient_avx+0x42>
  .byte  235,20                              // jmp           3f4d <_sk_linear_gradient_avx+0xcc>
  .byte  196,65,36,87,219                    // vxorps        %ymm11,%ymm11,%ymm11
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  197,28,89,224                       // vmulps        %ymm0,%ymm12,%ymm12
  .byte  196,65,60,88,196                    // vaddps        %ymm12,%ymm8,%ymm8
  .byte  197,36,89,216                       // vmulps        %ymm0,%ymm11,%ymm11
  .byte  197,164,88,201                      // vaddps        %ymm1,%ymm11,%ymm1
  .byte  197,44,89,208                       // vmulps        %ymm0,%ymm10,%ymm10
  .byte  197,172,88,210                      // vaddps        %ymm2,%ymm10,%ymm2
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,252,88,219                      // vaddps        %ymm3,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_avx
.globl _sk_linear_gradient_2stops_avx
_sk_linear_gradient_2stops_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,8                    // vbroadcastss  (%rax),%ymm1
  .byte  196,226,125,24,80,16                // vbroadcastss  0x10(%rax),%ymm2
  .byte  197,244,89,200                      // vmulps        %ymm0,%ymm1,%ymm1
  .byte  197,116,88,194                      // vaddps        %ymm2,%ymm1,%ymm8
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,20                // vbroadcastss  0x14(%rax),%ymm2
  .byte  197,244,89,200                      // vmulps        %ymm0,%ymm1,%ymm1
  .byte  197,244,88,202                      // vaddps        %ymm2,%ymm1,%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  196,226,125,24,88,24                // vbroadcastss  0x18(%rax),%ymm3
  .byte  197,236,89,208                      // vmulps        %ymm0,%ymm2,%ymm2
  .byte  197,236,88,211                      // vaddps        %ymm3,%ymm2,%ymm2
  .byte  196,226,125,24,88,12                // vbroadcastss  0xc(%rax),%ymm3
  .byte  196,98,125,24,72,28                 // vbroadcastss  0x1c(%rax),%ymm9
  .byte  197,228,89,192                      // vmulps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,88,217                  // vaddps        %ymm9,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_avx
.globl _sk_save_xy_avx
_sk_save_xy_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,88,200                       // vaddps        %ymm0,%ymm8,%ymm9
  .byte  196,67,125,8,209,1                  // vroundps      $0x1,%ymm9,%ymm10
  .byte  196,65,52,92,202                    // vsubps        %ymm10,%ymm9,%ymm9
  .byte  197,60,88,193                       // vaddps        %ymm1,%ymm8,%ymm8
  .byte  196,67,125,8,208,1                  // vroundps      $0x1,%ymm8,%ymm10
  .byte  196,65,60,92,194                    // vsubps        %ymm10,%ymm8,%ymm8
  .byte  197,252,17,0                        // vmovups       %ymm0,(%rax)
  .byte  197,252,17,72,32                    // vmovups       %ymm1,0x20(%rax)
  .byte  197,124,17,72,64                    // vmovups       %ymm9,0x40(%rax)
  .byte  197,124,17,64,96                    // vmovups       %ymm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_avx
.globl _sk_accumulate_avx
_sk_accumulate_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,16,128,128,0,0,0            // vmovups       0x80(%rax),%ymm8
  .byte  197,60,89,128,160,0,0,0             // vmulps        0xa0(%rax),%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  197,180,88,228                      // vaddps        %ymm4,%ymm9,%ymm4
  .byte  197,60,89,201                       // vmulps        %ymm1,%ymm8,%ymm9
  .byte  197,180,88,237                      // vaddps        %ymm5,%ymm9,%ymm5
  .byte  197,60,89,202                       // vmulps        %ymm2,%ymm8,%ymm9
  .byte  197,180,88,246                      // vaddps        %ymm6,%ymm9,%ymm6
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  197,188,88,255                      // vaddps        %ymm7,%ymm8,%ymm7
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_avx
.globl _sk_bilinear_nx_avx
_sk_bilinear_nx_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_avx
.globl _sk_bilinear_px_avx
_sk_bilinear_px_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_avx
.globl _sk_bilinear_ny_avx
_sk_bilinear_ny_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_avx
.globl _sk_bilinear_py_avx
_sk_bilinear_py_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_avx
.globl _sk_bicubic_n3x_avx
_sk_bicubic_n3x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,44,89,192                    // vmulps        %ymm8,%ymm10,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_avx
.globl _sk_bicubic_n1x_avx
_sk_bicubic_n1x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,201                    // vmulps        %ymm9,%ymm8,%ymm9
  .byte  196,65,44,88,201                    // vaddps        %ymm9,%ymm10,%ymm9
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_avx
.globl _sk_bicubic_p1x_avx
_sk_bicubic_p1x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm8
  .byte  197,188,88,0                        // vaddps        (%rax),%ymm8,%ymm0
  .byte  197,124,16,72,64                    // vmovups       0x40(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,60,88,194                    // vaddps        %ymm10,%ymm8,%ymm8
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_avx
.globl _sk_bicubic_p3x_avx
_sk_bicubic_p3x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,60,89,194                    // vmulps        %ymm10,%ymm8,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_avx
.globl _sk_bicubic_n3y_avx
_sk_bicubic_n3y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,44,89,192                    // vmulps        %ymm8,%ymm10,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_avx
.globl _sk_bicubic_n1y_avx
_sk_bicubic_n1y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,201                    // vmulps        %ymm9,%ymm8,%ymm9
  .byte  196,65,44,88,201                    // vaddps        %ymm9,%ymm10,%ymm9
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_avx
.globl _sk_bicubic_p1y_avx
_sk_bicubic_p1y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,193,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm8
  .byte  197,188,88,72,32                    // vaddps        0x20(%rax),%ymm8,%ymm1
  .byte  197,124,16,72,96                    // vmovups       0x60(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,60,88,194                    // vaddps        %ymm10,%ymm8,%ymm8
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_avx
.globl _sk_bicubic_p3y_avx
_sk_bicubic_p3y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,60,89,194                    // vmulps        %ymm10,%ymm8,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_start_pipeline_sse41
.globl _sk_start_pipeline_sse41
_sk_start_pipeline_sse41:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,207                          // mov           %rcx,%r15
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,196                          // mov           %rax,%r12
  .byte  73,137,245                          // mov           %rsi,%r13
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  76,57,248                           // cmp           %r15,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_sse41+0x28>
  .byte  72,137,216                          // mov           %rbx,%rax
  .byte  235,52                              // jmp           5c <_sk_start_pipeline_sse41+0x5c>
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,238                          // mov           %r13,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,212                          // callq         *%r12
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  72,131,195,8                        // add           $0x8,%rbx
  .byte  76,57,251                           // cmp           %r15,%rbx
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  118,204                             // jbe           28 <_sk_start_pipeline_sse41+0x28>
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  195                                 // retq

HIDDEN _sk_just_return_sse41
.globl _sk_just_return_sse41
_sk_just_return_sse41:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_sse41
.globl _sk_seed_shader_sse41
_sk_seed_shader_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  102,15,110,199                      // movd          %edi,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,15,110,209                      // movd          %ecx,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  15,16,2                             // movups        (%rdx),%xmm0
  .byte  15,88,193                           // addps         %xmm1,%xmm0
  .byte  102,15,110,8                        // movd          (%rax),%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_sse41
.globl _sk_constant_color_sse41
_sk_constant_color_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_sse41
.globl _sk_clear_sse41
_sk_clear_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_sse41
.globl _sk_srcatop_sse41
_sk_srcatop_sse41:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_sse41
.globl _sk_dstatop_sse41
_sk_dstatop_sse41:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,198                        // mulps         %xmm6,%xmm8
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_sse41
.globl _sk_srcin_sse41
_sk_srcin_sse41:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_sse41
.globl _sk_dstin_sse41
_sk_dstin_sse41:
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_sse41
.globl _sk_srcout_sse41
_sk_srcout_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_sse41
.globl _sk_dstout_sse41
_sk_dstout_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_sse41
.globl _sk_srcover_sse41
_sk_srcover_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_sse41
.globl _sk_dstover_sse41
_sk_dstover_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_sse41
.globl _sk_modulate_sse41
_sk_modulate_sse41:
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_sse41
.globl _sk_multiply_sse41
_sk_multiply_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,220                        // mulps         %xmm4,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,88,195                        // addps         %xmm11,%xmm0
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,221                        // mulps         %xmm5,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,222                        // mulps         %xmm6,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__sse41
.globl _sk_plus__sse41
_sk_plus__sse41:
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_sse41
.globl _sk_screen_sse41
_sk_screen_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,88,196                        // addps         %xmm4,%xmm8
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,88,205                        // addps         %xmm5,%xmm9
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,88,214                        // addps         %xmm6,%xmm10
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,92,210                        // subps         %xmm2,%xmm10
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,88,223                        // addps         %xmm7,%xmm11
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__sse41
.globl _sk_xor__sse41
_sk_xor__sse41:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,92,216                        // subps         %xmm8,%xmm3
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,212                        // mulps         %xmm4,%xmm10
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,213                        // mulps         %xmm5,%xmm10
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_sse41
.globl _sk_darken_sse41
_sk_darken_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,95,201                        // maxps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,95,193                        // maxps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,95,209                        // maxps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_sse41
.globl _sk_lighten_sse41
_sk_lighten_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_sse41
.globl _sk_difference_sse41
_sk_difference_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_sse41
.globl _sk_exclusion_sse41
_sk_exclusion_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_sse41
.globl _sk_colorburn_sse41
_sk_colorburn_sse41:
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  65,15,94,193                        // divps         %xmm9,%xmm0
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,93,232                        // minps         %xmm0,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,194,192,0                     // cmpeqps       %xmm8,%xmm0
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,244                        // addps         %xmm12,%xmm14
  .byte  102,69,15,56,20,241                 // blendvps      %xmm0,%xmm9,%xmm14
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  68,15,88,228                        // addps         %xmm4,%xmm12
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,194,199,0                        // cmpeqps       %xmm7,%xmm0
  .byte  69,15,88,206                        // addps         %xmm14,%xmm9
  .byte  102,69,15,56,20,204                 // blendvps      %xmm0,%xmm12,%xmm9
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  68,15,89,225                        // mulps         %xmm1,%xmm12
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,197                           // subps         %xmm5,%xmm0
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,94,193                           // divps         %xmm1,%xmm0
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,93,232                        // minps         %xmm0,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  65,15,194,192,0                     // cmpeqps       %xmm8,%xmm0
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,244                        // addps         %xmm12,%xmm14
  .byte  102,68,15,56,20,241                 // blendvps      %xmm0,%xmm1,%xmm14
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,88,229                        // addps         %xmm5,%xmm12
  .byte  65,15,88,206                        // addps         %xmm14,%xmm1
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,194,199,0                        // cmpeqps       %xmm7,%xmm0
  .byte  102,65,15,56,20,204                 // blendvps      %xmm0,%xmm12,%xmm1
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,198                           // subps         %xmm6,%xmm0
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,94,194                           // divps         %xmm2,%xmm0
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,93,224                        // minps         %xmm0,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  69,15,92,236                        // subps         %xmm12,%xmm13
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  68,15,194,194,0                     // cmpeqps       %xmm2,%xmm8
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  102,68,15,56,20,234                 // blendvps      %xmm0,%xmm2,%xmm13
  .byte  68,15,88,222                        // addps         %xmm6,%xmm11
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,213                        // addps         %xmm13,%xmm2
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,194,199,0                        // cmpeqps       %xmm7,%xmm0
  .byte  102,65,15,56,20,211                 // blendvps      %xmm0,%xmm11,%xmm2
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_sse41
.globl _sk_colordodge_sse41
_sk_colordodge_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  69,15,89,224                        // mulps         %xmm8,%xmm12
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  65,15,92,192                        // subps         %xmm8,%xmm0
  .byte  68,15,94,200                        // divps         %xmm0,%xmm9
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,93,241                        // minps         %xmm9,%xmm14
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,194,195,0                        // cmpeqps       %xmm3,%xmm0
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,244                        // addps         %xmm12,%xmm14
  .byte  102,69,15,56,20,240                 // blendvps      %xmm0,%xmm8,%xmm14
  .byte  69,15,87,201                        // xorps         %xmm9,%xmm9
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  68,15,88,228                        // addps         %xmm4,%xmm12
  .byte  69,15,88,198                        // addps         %xmm14,%xmm8
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  65,15,194,193,0                     // cmpeqps       %xmm9,%xmm0
  .byte  102,69,15,56,20,196                 // blendvps      %xmm0,%xmm12,%xmm8
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,229                        // mulps         %xmm5,%xmm12
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  68,15,94,224                        // divps         %xmm0,%xmm12
  .byte  69,15,40,243                        // movaps        %xmm11,%xmm14
  .byte  68,15,89,241                        // mulps         %xmm1,%xmm14
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  15,194,195,0                        // cmpeqps       %xmm3,%xmm0
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  102,68,15,56,20,233                 // blendvps      %xmm0,%xmm1,%xmm13
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,88,245                        // addps         %xmm5,%xmm14
  .byte  65,15,88,205                        // addps         %xmm13,%xmm1
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  65,15,194,193,0                     // cmpeqps       %xmm9,%xmm0
  .byte  102,65,15,56,20,206                 // blendvps      %xmm0,%xmm14,%xmm1
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,230                        // mulps         %xmm6,%xmm12
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,194                           // subps         %xmm2,%xmm0
  .byte  68,15,94,224                        // divps         %xmm0,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,194,195,0                        // cmpeqps       %xmm3,%xmm0
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  102,68,15,56,20,234                 // blendvps      %xmm0,%xmm2,%xmm13
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,213                        // addps         %xmm13,%xmm2
  .byte  68,15,194,206,0                     // cmpeqps       %xmm6,%xmm9
  .byte  68,15,88,222                        // addps         %xmm6,%xmm11
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  102,65,15,56,20,211                 // blendvps      %xmm0,%xmm11,%xmm2
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_sse41
.globl _sk_hardlight_sse41
_sk_hardlight_sse41:
  .byte  15,41,116,36,232                    // movaps        %xmm6,-0x18(%rsp)
  .byte  68,15,40,229                        // movaps        %xmm5,%xmm12
  .byte  15,40,244                           // movaps        %xmm4,%xmm6
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,40,234                           // movaps        %xmm2,%xmm5
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,92,215                           // subps         %xmm7,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  68,15,92,212                        // subps         %xmm4,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,198                        // mulps         %xmm6,%xmm8
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  68,15,40,252                        // movaps        %xmm4,%xmm15
  .byte  69,15,92,249                        // subps         %xmm9,%xmm15
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,198                           // subps         %xmm6,%xmm0
  .byte  65,15,89,199                        // mulps         %xmm15,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  68,15,40,251                        // movaps        %xmm3,%xmm15
  .byte  68,15,92,248                        // subps         %xmm0,%xmm15
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,196,2                        // cmpleps       %xmm4,%xmm0
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  102,69,15,56,20,249                 // blendvps      %xmm0,%xmm9,%xmm15
  .byte  68,15,40,218                        // movaps        %xmm2,%xmm11
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  69,15,40,204                        // movaps        %xmm12,%xmm9
  .byte  69,15,92,233                        // subps         %xmm9,%xmm13
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,196,2                        // cmpleps       %xmm4,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  69,15,40,233                        // movaps        %xmm9,%xmm13
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  102,68,15,56,20,225                 // blendvps      %xmm0,%xmm1,%xmm12
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  69,15,88,199                        // addps         %xmm15,%xmm8
  .byte  65,15,89,205                        // mulps         %xmm13,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  65,15,88,204                        // addps         %xmm12,%xmm1
  .byte  15,89,213                           // mulps         %xmm5,%xmm2
  .byte  68,15,40,92,36,232                  // movaps        -0x18(%rsp),%xmm11
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  68,15,88,202                        // addps         %xmm2,%xmm9
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,196,2                        // cmpleps       %xmm4,%xmm0
  .byte  15,40,212                           // movaps        %xmm4,%xmm2
  .byte  15,92,213                           // subps         %xmm5,%xmm2
  .byte  65,15,89,235                        // mulps         %xmm11,%xmm5
  .byte  15,88,237                           // addps         %xmm5,%xmm5
  .byte  69,15,92,243                        // subps         %xmm11,%xmm14
  .byte  68,15,89,242                        // mulps         %xmm2,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  65,15,92,222                        // subps         %xmm14,%xmm3
  .byte  102,15,56,20,221                    // blendvps      %xmm0,%xmm5,%xmm3
  .byte  68,15,88,203                        // addps         %xmm3,%xmm9
  .byte  65,15,88,226                        // addps         %xmm10,%xmm4
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,40,220                           // movaps        %xmm4,%xmm3
  .byte  15,40,230                           // movaps        %xmm6,%xmm4
  .byte  65,15,40,237                        // movaps        %xmm13,%xmm5
  .byte  65,15,40,243                        // movaps        %xmm11,%xmm6
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_sse41
.globl _sk_overlay_sse41
_sk_overlay_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,240                        // movaps        %xmm0,%xmm14
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,198                        // mulps         %xmm14,%xmm0
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  68,15,40,235                        // movaps        %xmm3,%xmm13
  .byte  69,15,92,238                        // subps         %xmm14,%xmm13
  .byte  68,15,89,244                        // mulps         %xmm4,%xmm14
  .byte  15,40,207                           // movaps        %xmm7,%xmm1
  .byte  15,92,204                           // subps         %xmm4,%xmm1
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,231                        // mulps         %xmm7,%xmm12
  .byte  65,15,89,205                        // mulps         %xmm13,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  69,15,40,236                        // movaps        %xmm12,%xmm13
  .byte  68,15,92,233                        // subps         %xmm1,%xmm13
  .byte  102,69,15,56,20,238                 // blendvps      %xmm0,%xmm14,%xmm13
  .byte  69,15,88,197                        // addps         %xmm13,%xmm8
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,88,200                           // addps         %xmm0,%xmm1
  .byte  68,15,40,235                        // movaps        %xmm3,%xmm13
  .byte  69,15,92,233                        // subps         %xmm9,%xmm13
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  68,15,92,245                        // subps         %xmm5,%xmm14
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  69,15,89,245                        // mulps         %xmm13,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  69,15,40,236                        // movaps        %xmm12,%xmm13
  .byte  69,15,92,238                        // subps         %xmm14,%xmm13
  .byte  102,69,15,56,20,233                 // blendvps      %xmm0,%xmm9,%xmm13
  .byte  65,15,88,205                        // addps         %xmm13,%xmm1
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  69,15,88,203                        // addps         %xmm11,%xmm9
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,92,218                        // subps         %xmm2,%xmm11
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,92,238                        // subps         %xmm6,%xmm13
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  69,15,89,235                        // mulps         %xmm11,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  102,68,15,56,20,226                 // blendvps      %xmm0,%xmm2,%xmm12
  .byte  69,15,88,204                        // addps         %xmm12,%xmm9
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_sse41
.globl _sk_softlight_sse41
_sk_softlight_sse41:
  .byte  15,41,116,36,216                    // movaps        %xmm6,-0x28(%rsp)
  .byte  15,40,244                           // movaps        %xmm4,%xmm6
  .byte  15,41,84,36,232                     // movaps        %xmm2,-0x18(%rsp)
  .byte  68,15,40,225                        // movaps        %xmm1,%xmm12
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,194,231,1                        // cmpltps       %xmm7,%xmm4
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,94,199                           // divps         %xmm7,%xmm0
  .byte  15,84,196                           // andps         %xmm4,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  68,15,92,208                        // subps         %xmm0,%xmm10
  .byte  68,15,40,240                        // movaps        %xmm0,%xmm14
  .byte  68,15,40,248                        // movaps        %xmm0,%xmm15
  .byte  15,82,208                           // rsqrtps       %xmm0,%xmm2
  .byte  68,15,83,218                        // rcpps         %xmm2,%xmm11
  .byte  68,15,92,216                        // subps         %xmm0,%xmm11
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,89,210                           // mulps         %xmm2,%xmm2
  .byte  15,88,208                           // addps         %xmm0,%xmm2
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  68,15,92,241                        // subps         %xmm1,%xmm14
  .byte  68,15,89,242                        // mulps         %xmm2,%xmm14
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,89,253                        // mulps         %xmm13,%xmm15
  .byte  69,15,88,254                        // addps         %xmm14,%xmm15
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  102,69,15,56,20,223                 // blendvps      %xmm0,%xmm15,%xmm11
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,92,195                           // subps         %xmm3,%xmm0
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,88,211                        // addps         %xmm3,%xmm10
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  68,15,89,216                        // mulps         %xmm0,%xmm11
  .byte  68,15,88,218                        // addps         %xmm2,%xmm11
  .byte  68,15,194,203,2                     // cmpleps       %xmm3,%xmm9
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  102,69,15,56,20,218                 // blendvps      %xmm0,%xmm10,%xmm11
  .byte  68,15,40,213                        // movaps        %xmm5,%xmm10
  .byte  68,15,94,215                        // divps         %xmm7,%xmm10
  .byte  68,15,84,212                        // andps         %xmm4,%xmm10
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,92,202                        // subps         %xmm10,%xmm9
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,92,209                           // subps         %xmm1,%xmm2
  .byte  15,89,208                           // mulps         %xmm0,%xmm2
  .byte  65,15,82,194                        // rsqrtps       %xmm10,%xmm0
  .byte  68,15,83,240                        // rcpps         %xmm0,%xmm14
  .byte  69,15,92,242                        // subps         %xmm10,%xmm14
  .byte  69,15,89,213                        // mulps         %xmm13,%xmm10
  .byte  68,15,88,210                        // addps         %xmm2,%xmm10
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  102,69,15,56,20,242                 // blendvps      %xmm0,%xmm10,%xmm14
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  68,15,88,203                        // addps         %xmm3,%xmm9
  .byte  15,41,108,36,200                    // movaps        %xmm5,-0x38(%rsp)
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,89,242                        // mulps         %xmm2,%xmm14
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,213                           // mulps         %xmm5,%xmm2
  .byte  68,15,88,242                        // addps         %xmm2,%xmm14
  .byte  68,15,40,249                        // movaps        %xmm1,%xmm15
  .byte  15,194,195,2                        // cmpleps       %xmm3,%xmm0
  .byte  102,69,15,56,20,241                 // blendvps      %xmm0,%xmm9,%xmm14
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  15,40,108,36,216                    // movaps        -0x28(%rsp),%xmm5
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,94,199                           // divps         %xmm7,%xmm0
  .byte  15,84,196                           // andps         %xmm4,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,92,209                           // subps         %xmm1,%xmm2
  .byte  15,92,200                           // subps         %xmm0,%xmm1
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  15,82,224                           // rsqrtps       %xmm0,%xmm4
  .byte  68,15,83,204                        // rcpps         %xmm4,%xmm9
  .byte  68,15,92,200                        // subps         %xmm0,%xmm9
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,89,228                           // mulps         %xmm4,%xmm4
  .byte  15,88,224                           // addps         %xmm0,%xmm4
  .byte  15,89,226                           // mulps         %xmm2,%xmm4
  .byte  68,15,88,236                        // addps         %xmm4,%xmm13
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  102,69,15,56,20,205                 // blendvps      %xmm0,%xmm13,%xmm9
  .byte  68,15,40,108,36,232                 // movaps        -0x18(%rsp),%xmm13
  .byte  65,15,40,197                        // movaps        %xmm13,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,213                           // mulps         %xmm5,%xmm2
  .byte  68,15,88,202                        // addps         %xmm2,%xmm9
  .byte  15,88,203                           // addps         %xmm3,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,40,213                           // movaps        %xmm5,%xmm2
  .byte  15,194,195,2                        // cmpleps       %xmm3,%xmm0
  .byte  102,68,15,56,20,201                 // blendvps      %xmm0,%xmm1,%xmm9
  .byte  68,15,92,255                        // subps         %xmm7,%xmm15
  .byte  69,15,89,199                        // mulps         %xmm15,%xmm8
  .byte  69,15,89,231                        // mulps         %xmm15,%xmm12
  .byte  69,15,89,253                        // mulps         %xmm13,%xmm15
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,198                           // mulps         %xmm6,%xmm0
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  69,15,88,195                        // addps         %xmm11,%xmm8
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,40,108,36,200                    // movaps        -0x38(%rsp),%xmm5
  .byte  15,89,197                           // mulps         %xmm5,%xmm0
  .byte  68,15,88,224                        // addps         %xmm0,%xmm12
  .byte  69,15,88,230                        // addps         %xmm14,%xmm12
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,194                           // mulps         %xmm2,%xmm0
  .byte  65,15,88,199                        // addps         %xmm15,%xmm0
  .byte  68,15,88,200                        // addps         %xmm0,%xmm9
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,230                           // movaps        %xmm6,%xmm4
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,204                        // movaps        %xmm12,%xmm1
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_sse41
.globl _sk_clamp_0_sse41
_sk_clamp_0_sse41:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  65,15,95,192                        // maxps         %xmm8,%xmm0
  .byte  65,15,95,200                        // maxps         %xmm8,%xmm1
  .byte  65,15,95,208                        // maxps         %xmm8,%xmm2
  .byte  65,15,95,216                        // maxps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_sse41
.globl _sk_clamp_1_sse41
_sk_clamp_1_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  65,15,93,208                        // minps         %xmm8,%xmm2
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_sse41
.globl _sk_clamp_a_sse41
_sk_clamp_a_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  15,93,195                           // minps         %xmm3,%xmm0
  .byte  15,93,203                           // minps         %xmm3,%xmm1
  .byte  15,93,211                           // minps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_sse41
.globl _sk_set_rgb_sse41
_sk_set_rgb_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_sse41
.globl _sk_swap_rb_sse41
_sk_swap_rb_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_sse41
.globl _sk_swap_sse41
_sk_swap_sse41:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,40,202                        // movaps        %xmm2,%xmm9
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  68,15,40,216                        // movaps        %xmm0,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  65,15,40,234                        // movaps        %xmm10,%xmm5
  .byte  65,15,40,241                        // movaps        %xmm9,%xmm6
  .byte  65,15,40,248                        // movaps        %xmm8,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_sse41
.globl _sk_move_src_dst_sse41
_sk_move_src_dst_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  15,40,251                           // movaps        %xmm3,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_sse41
.globl _sk_move_dst_src_sse41
_sk_move_dst_src_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_sse41
.globl _sk_premul_sse41
_sk_premul_sse41:
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_sse41
.globl _sk_unpremul_sse41
_sk_unpremul_sse41:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,94,203                        // divps         %xmm3,%xmm9
  .byte  68,15,194,195,4                     // cmpneqps      %xmm3,%xmm8
  .byte  69,15,84,193                        // andps         %xmm9,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_sse41
.globl _sk_from_srgb_sse41
_sk_from_srgb_sse41:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,40,240                        // movaps        %xmm0,%xmm14
  .byte  69,15,89,246                        // mulps         %xmm14,%xmm14
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  69,15,88,204                        // addps         %xmm12,%xmm9
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,89,206                        // mulps         %xmm14,%xmm9
  .byte  69,15,88,205                        // addps         %xmm13,%xmm9
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  102,68,15,110,240                   // movd          %eax,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  102,69,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm9
  .byte  69,15,40,251                        // movaps        %xmm11,%xmm15
  .byte  68,15,89,249                        // mulps         %xmm1,%xmm15
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,88,212                        // addps         %xmm12,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  69,15,88,213                        // addps         %xmm13,%xmm10
  .byte  65,15,194,206,1                     // cmpltps       %xmm14,%xmm1
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  102,69,15,56,20,215                 // blendvps      %xmm0,%xmm15,%xmm10
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  69,15,88,196                        // addps         %xmm12,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  69,15,88,197                        // addps         %xmm13,%xmm8
  .byte  65,15,194,214,1                     // cmpltps       %xmm14,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,69,15,56,20,195                 // blendvps      %xmm0,%xmm11,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_sse41
.globl _sk_to_srgb_sse41
_sk_to_srgb_sse41:
  .byte  15,41,124,36,232                    // movaps        %xmm7,-0x18(%rsp)
  .byte  15,40,254                           // movaps        %xmm6,%xmm7
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  68,15,82,192                        // rsqrtps       %xmm0,%xmm8
  .byte  69,15,83,200                        // rcpps         %xmm8,%xmm9
  .byte  69,15,82,248                        // rsqrtps       %xmm8,%xmm15
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  102,68,15,110,240                   // movd          %eax,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  69,15,89,205                        // mulps         %xmm13,%xmm9
  .byte  69,15,88,206                        // addps         %xmm14,%xmm9
  .byte  69,15,89,252                        // mulps         %xmm12,%xmm15
  .byte  69,15,88,249                        // addps         %xmm9,%xmm15
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,93,207                        // minps         %xmm15,%xmm9
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  102,68,15,110,248                   // movd          %eax,%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  65,15,194,199,1                     // cmpltps       %xmm15,%xmm0
  .byte  102,69,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm9
  .byte  68,15,82,210                        // rsqrtps       %xmm2,%xmm10
  .byte  65,15,83,194                        // rcpps         %xmm10,%xmm0
  .byte  69,15,82,210                        // rsqrtps       %xmm10,%xmm10
  .byte  65,15,89,197                        // mulps         %xmm13,%xmm0
  .byte  65,15,88,198                        // addps         %xmm14,%xmm0
  .byte  69,15,89,212                        // mulps         %xmm12,%xmm10
  .byte  68,15,88,208                        // addps         %xmm0,%xmm10
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  65,15,93,202                        // minps         %xmm10,%xmm1
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  65,15,194,215,1                     // cmpltps       %xmm15,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,65,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm1
  .byte  15,82,195                           // rsqrtps       %xmm3,%xmm0
  .byte  15,83,208                           // rcpps         %xmm0,%xmm2
  .byte  65,15,89,213                        // mulps         %xmm13,%xmm2
  .byte  65,15,88,214                        // addps         %xmm14,%xmm2
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  65,15,89,196                        // mulps         %xmm12,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  68,15,93,192                        // minps         %xmm0,%xmm8
  .byte  68,15,89,219                        // mulps         %xmm3,%xmm11
  .byte  65,15,194,223,1                     // cmpltps       %xmm15,%xmm3
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  102,69,15,56,20,195                 // blendvps      %xmm0,%xmm11,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,40,220                           // movaps        %xmm4,%xmm3
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,40,238                           // movaps        %xmm6,%xmm5
  .byte  15,40,247                           // movaps        %xmm7,%xmm6
  .byte  15,40,124,36,232                    // movaps        -0x18(%rsp),%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_2dot2_sse41
.globl _sk_from_2dot2_sse41
_sk_from_2dot2_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  65,15,82,192                        // rsqrtps       %xmm8,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  68,15,82,200                        // rsqrtps       %xmm0,%xmm9
  .byte  65,15,82,193                        // rsqrtps       %xmm9,%xmm0
  .byte  68,15,82,208                        // rsqrtps       %xmm0,%xmm10
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  65,15,95,194                        // maxps         %xmm10,%xmm0
  .byte  68,15,82,193                        // rsqrtps       %xmm1,%xmm8
  .byte  69,15,82,192                        // rsqrtps       %xmm8,%xmm8
  .byte  69,15,82,192                        // rsqrtps       %xmm8,%xmm8
  .byte  69,15,82,200                        // rsqrtps       %xmm8,%xmm9
  .byte  69,15,82,193                        // rsqrtps       %xmm9,%xmm8
  .byte  69,15,82,216                        // rsqrtps       %xmm8,%xmm11
  .byte  15,89,201                           // mulps         %xmm1,%xmm1
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  69,15,89,195                        // mulps         %xmm11,%xmm8
  .byte  69,15,95,194                        // maxps         %xmm10,%xmm8
  .byte  15,82,202                           // rsqrtps       %xmm2,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  68,15,82,217                        // rsqrtps       %xmm1,%xmm11
  .byte  65,15,82,203                        // rsqrtps       %xmm11,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,89,210                           // mulps         %xmm2,%xmm2
  .byte  69,15,40,203                        // movaps        %xmm11,%xmm9
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,95,202                        // maxps         %xmm10,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_2dot2_sse41
.globl _sk_to_2dot2_sse41
_sk_to_2dot2_sse41:
  .byte  68,15,82,192                        // rsqrtps       %xmm0,%xmm8
  .byte  65,15,82,192                        // rsqrtps       %xmm8,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  68,15,82,200                        // rsqrtps       %xmm0,%xmm9
  .byte  69,15,83,192                        // rcpps         %xmm8,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,83,193                        // rcpps         %xmm9,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  65,15,95,192                        // maxps         %xmm8,%xmm0
  .byte  68,15,82,201                        // rsqrtps       %xmm1,%xmm9
  .byte  65,15,82,201                        // rsqrtps       %xmm9,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  68,15,82,209                        // rsqrtps       %xmm1,%xmm10
  .byte  69,15,83,201                        // rcpps         %xmm9,%xmm9
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  65,15,83,202                        // rcpps         %xmm10,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,95,200                        // maxps         %xmm8,%xmm1
  .byte  68,15,82,202                        // rsqrtps       %xmm2,%xmm9
  .byte  65,15,82,209                        // rsqrtps       %xmm9,%xmm2
  .byte  15,82,210                           // rsqrtps       %xmm2,%xmm2
  .byte  15,82,210                           // rsqrtps       %xmm2,%xmm2
  .byte  15,82,210                           // rsqrtps       %xmm2,%xmm2
  .byte  68,15,82,210                        // rsqrtps       %xmm2,%xmm10
  .byte  69,15,83,201                        // rcpps         %xmm9,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  65,15,83,210                        // rcpps         %xmm10,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,95,208                        // maxps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_sse41
.globl _sk_rgb_to_hsl_sse41
_sk_rgb_to_hsl_sse41:
  .byte  15,41,124,36,232                    // movaps        %xmm7,-0x18(%rsp)
  .byte  15,40,254                           // movaps        %xmm6,%xmm7
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  65,185,0,0,192,64                   // mov           $0x40c00000,%r9d
  .byte  184,0,0,0,64                        // mov           $0x40000000,%eax
  .byte  185,0,0,128,64                      // mov           $0x40800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  68,15,95,225                        // maxps         %xmm1,%xmm12
  .byte  68,15,95,227                        // maxps         %xmm3,%xmm12
  .byte  68,15,40,232                        // movaps        %xmm0,%xmm13
  .byte  68,15,93,233                        // minps         %xmm1,%xmm13
  .byte  68,15,93,235                        // minps         %xmm3,%xmm13
  .byte  69,15,40,204                        // movaps        %xmm12,%xmm9
  .byte  68,15,194,200,0                     // cmpeqps       %xmm0,%xmm9
  .byte  68,15,40,241                        // movaps        %xmm1,%xmm14
  .byte  68,15,92,243                        // subps         %xmm3,%xmm14
  .byte  68,15,40,249                        // movaps        %xmm1,%xmm15
  .byte  68,15,194,251,1                     // cmpltps       %xmm3,%xmm15
  .byte  69,15,40,212                        // movaps        %xmm12,%xmm10
  .byte  68,15,194,209,0                     // cmpeqps       %xmm1,%xmm10
  .byte  15,92,216                           // subps         %xmm0,%xmm3
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  65,15,40,212                        // movaps        %xmm12,%xmm2
  .byte  65,15,92,213                        // subps         %xmm13,%xmm2
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,94,218                        // divps         %xmm2,%xmm11
  .byte  65,15,89,195                        // mulps         %xmm11,%xmm0
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  65,15,89,219                        // mulps         %xmm11,%xmm3
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,88,217                           // addps         %xmm1,%xmm3
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  102,68,15,56,20,195                 // blendvps      %xmm0,%xmm3,%xmm8
  .byte  69,15,89,243                        // mulps         %xmm11,%xmm14
  .byte  102,65,15,110,217                   // movd          %r9d,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,84,223                        // andps         %xmm15,%xmm3
  .byte  65,15,88,222                        // addps         %xmm14,%xmm3
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  102,68,15,56,20,195                 // blendvps      %xmm0,%xmm3,%xmm8
  .byte  65,15,40,220                        // movaps        %xmm12,%xmm3
  .byte  65,15,92,204                        // subps         %xmm12,%xmm1
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,204                        // movaps        %xmm12,%xmm9
  .byte  69,15,89,202                        // mulps         %xmm10,%xmm9
  .byte  69,15,194,209,1                     // cmpltps       %xmm9,%xmm10
  .byte  65,15,92,205                        // subps         %xmm13,%xmm1
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  102,68,15,56,20,225                 // blendvps      %xmm0,%xmm1,%xmm12
  .byte  65,15,194,221,4                     // cmpneqps      %xmm13,%xmm3
  .byte  102,65,15,110,192                   // movd          %r8d,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  68,15,84,195                        // andps         %xmm3,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,94,212                        // divps         %xmm12,%xmm2
  .byte  15,84,211                           // andps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,40,202                           // movaps        %xmm2,%xmm1
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,40,220                           // movaps        %xmm4,%xmm3
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,40,238                           // movaps        %xmm6,%xmm5
  .byte  15,40,247                           // movaps        %xmm7,%xmm6
  .byte  15,40,124,36,232                    // movaps        -0x18(%rsp),%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_sse41
.globl _sk_hsl_to_rgb_sse41
_sk_hsl_to_rgb_sse41:
  .byte  72,131,236,24                       // sub           $0x18,%rsp
  .byte  15,41,60,36                         // movaps        %xmm7,(%rsp)
  .byte  15,41,116,36,240                    // movaps        %xmm6,-0x10(%rsp)
  .byte  15,41,108,36,224                    // movaps        %xmm5,-0x20(%rsp)
  .byte  15,41,100,36,208                    // movaps        %xmm4,-0x30(%rsp)
  .byte  15,41,92,36,192                     // movaps        %xmm3,-0x40(%rsp)
  .byte  68,15,40,208                        // movaps        %xmm0,%xmm10
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,41,92,36,128                     // movaps        %xmm3,-0x80(%rsp)
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,194,195,1                        // cmpltps       %xmm3,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,40,224                        // movaps        %xmm8,%xmm4
  .byte  15,88,225                           // addps         %xmm1,%xmm4
  .byte  15,89,226                           // mulps         %xmm2,%xmm4
  .byte  15,40,217                           // movaps        %xmm1,%xmm3
  .byte  15,40,249                           // movaps        %xmm1,%xmm7
  .byte  15,88,250                           // addps         %xmm2,%xmm7
  .byte  15,89,218                           // mulps         %xmm2,%xmm3
  .byte  15,40,234                           // movaps        %xmm2,%xmm5
  .byte  15,92,251                           // subps         %xmm3,%xmm7
  .byte  102,15,56,20,252                    // blendvps      %xmm0,%xmm4,%xmm7
  .byte  184,0,0,0,64                        // mov           $0x40000000,%eax
  .byte  185,171,170,170,62                  // mov           $0x3eaaaaab,%ecx
  .byte  102,15,110,209                      // movd          %ecx,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,41,84,36,176                     // movaps        %xmm2,-0x50(%rsp)
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,194,194,1                        // cmpltps       %xmm2,%xmm0
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  65,15,92,216                        // subps         %xmm8,%xmm3
  .byte  68,15,40,226                        // movaps        %xmm2,%xmm12
  .byte  102,68,15,56,20,227                 // blendvps      %xmm0,%xmm3,%xmm12
  .byte  102,68,15,110,241                   // movd          %ecx,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  68,15,41,116,36,160                 // movaps        %xmm14,-0x60(%rsp)
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  102,68,15,56,20,227                 // blendvps      %xmm0,%xmm3,%xmm12
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,41,100,36,144                    // movaps        %xmm4,-0x70(%rsp)
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  184,171,170,42,62                   // mov           $0x3e2aaaab,%eax
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  185,0,0,192,64                      // mov           $0x40c00000,%ecx
  .byte  102,15,110,241                      // movd          %ecx,%xmm6
  .byte  15,198,246,0                        // shufps        $0x0,%xmm6,%xmm6
  .byte  15,89,240                           // mulps         %xmm0,%xmm6
  .byte  185,171,170,42,63                   // mov           $0x3f2aaaab,%ecx
  .byte  102,15,110,217                      // movd          %ecx,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,40,235                           // movaps        %xmm3,%xmm5
  .byte  65,15,92,236                        // subps         %xmm12,%xmm5
  .byte  69,15,40,236                        // movaps        %xmm12,%xmm13
  .byte  69,15,40,252                        // movaps        %xmm12,%xmm15
  .byte  68,15,194,227,1                     // cmpltps       %xmm3,%xmm12
  .byte  15,89,238                           // mulps         %xmm6,%xmm5
  .byte  65,15,88,233                        // addps         %xmm9,%xmm5
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  102,68,15,56,20,221                 // blendvps      %xmm0,%xmm5,%xmm11
  .byte  68,15,194,124,36,128,1              // cmpltps       -0x80(%rsp),%xmm15
  .byte  65,15,40,199                        // movaps        %xmm15,%xmm0
  .byte  102,68,15,56,20,223                 // blendvps      %xmm0,%xmm7,%xmm11
  .byte  102,15,110,232                      // movd          %eax,%xmm5
  .byte  15,198,237,0                        // shufps        $0x0,%xmm5,%xmm5
  .byte  68,15,194,237,1                     // cmpltps       %xmm5,%xmm13
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  65,15,40,197                        // movaps        %xmm13,%xmm0
  .byte  102,68,15,56,20,218                 // blendvps      %xmm0,%xmm2,%xmm11
  .byte  69,15,87,228                        // xorps         %xmm12,%xmm12
  .byte  68,15,194,225,0                     // cmpeqps       %xmm1,%xmm12
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  102,68,15,56,20,220                 // blendvps      %xmm0,%xmm4,%xmm11
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,194,194,1                     // cmpltps       %xmm10,%xmm0
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  69,15,40,234                        // movaps        %xmm10,%xmm13
  .byte  102,68,15,56,20,233                 // blendvps      %xmm0,%xmm1,%xmm13
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  102,68,15,56,20,233                 // blendvps      %xmm0,%xmm1,%xmm13
  .byte  68,15,40,243                        // movaps        %xmm3,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  65,15,40,229                        // movaps        %xmm13,%xmm4
  .byte  69,15,40,253                        // movaps        %xmm13,%xmm15
  .byte  68,15,194,235,1                     // cmpltps       %xmm3,%xmm13
  .byte  68,15,89,246                        // mulps         %xmm6,%xmm14
  .byte  69,15,88,241                        // addps         %xmm9,%xmm14
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,197                        // movaps        %xmm13,%xmm0
  .byte  102,65,15,56,20,206                 // blendvps      %xmm0,%xmm14,%xmm1
  .byte  68,15,40,116,36,128                 // movaps        -0x80(%rsp),%xmm14
  .byte  69,15,194,254,1                     // cmpltps       %xmm14,%xmm15
  .byte  65,15,40,199                        // movaps        %xmm15,%xmm0
  .byte  102,15,56,20,207                    // blendvps      %xmm0,%xmm7,%xmm1
  .byte  15,194,229,1                        // cmpltps       %xmm5,%xmm4
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  102,15,56,20,202                    // blendvps      %xmm0,%xmm2,%xmm1
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  68,15,40,124,36,144                 // movaps        -0x70(%rsp),%xmm15
  .byte  102,65,15,56,20,207                 // blendvps      %xmm0,%xmm15,%xmm1
  .byte  68,15,92,84,36,176                  // subps         -0x50(%rsp),%xmm10
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,92,208                        // subps         %xmm8,%xmm2
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  69,15,194,194,1                     // cmpltps       %xmm10,%xmm8
  .byte  65,15,40,226                        // movaps        %xmm10,%xmm4
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  102,15,56,20,226                    // blendvps      %xmm0,%xmm2,%xmm4
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,194,68,36,160,1                  // cmpltps       -0x60(%rsp),%xmm0
  .byte  69,15,88,234                        // addps         %xmm10,%xmm13
  .byte  102,65,15,56,20,229                 // blendvps      %xmm0,%xmm13,%xmm4
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,194,195,1                        // cmpltps       %xmm3,%xmm0
  .byte  15,92,220                           // subps         %xmm4,%xmm3
  .byte  15,89,222                           // mulps         %xmm6,%xmm3
  .byte  69,15,88,209                        // addps         %xmm9,%xmm10
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  102,68,15,56,20,203                 // blendvps      %xmm0,%xmm3,%xmm9
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  102,68,15,56,20,207                 // blendvps      %xmm0,%xmm7,%xmm9
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,194,197,1                        // cmpltps       %xmm5,%xmm0
  .byte  102,69,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm9
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  102,69,15,56,20,207                 // blendvps      %xmm0,%xmm15,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,40,92,36,192                     // movaps        -0x40(%rsp),%xmm3
  .byte  15,40,100,36,208                    // movaps        -0x30(%rsp),%xmm4
  .byte  15,40,108,36,224                    // movaps        -0x20(%rsp),%xmm5
  .byte  15,40,116,36,240                    // movaps        -0x10(%rsp),%xmm6
  .byte  15,40,60,36                         // movaps        (%rsp),%xmm7
  .byte  72,131,196,24                       // add           $0x18,%rsp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_sse41
.globl _sk_scale_1_float_sse41
_sk_scale_1_float_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_sse41
.globl _sk_scale_u8_sse41
_sk_scale_u8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,49,4,56                // pmovzxbd      (%rax,%rdi,1),%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_1_float_sse41
.globl _sk_lerp_1_float_sse41
_sk_lerp_1_float_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_sse41
.globl _sk_lerp_u8_sse41
_sk_lerp_u8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,49,4,56                // pmovzxbd      (%rax,%rdi,1),%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_565_sse41
.globl _sk_lerp_565_sse41
_sk_lerp_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,51,4,120               // pmovzxwd      (%rax,%rdi,2),%xmm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,203                        // mulps         %xmm11,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_sse41
.globl _sk_load_tables_sse41
_sk_load_tables_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  243,68,15,111,4,185                 // movdqu        (%rcx,%rdi,4),%xmm8
  .byte  185,255,0,0,0                       // mov           $0xff,%ecx
  .byte  102,15,110,193                      // movd          %ecx,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,111,200                   // movdqa        %xmm8,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,200                      // pand          %xmm0,%xmm1
  .byte  102,65,15,111,208                   // movdqa        %xmm8,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,15,219,208                      // pand          %xmm0,%xmm2
  .byte  102,65,15,219,192                   // pand          %xmm8,%xmm0
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,201                          // mov           %ecx,%r9d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,194                   // movq          %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  243,67,15,16,4,152                  // movss         (%r8,%r11,4),%xmm0
  .byte  102,67,15,58,33,4,144,16            // insertps      $0x10,(%r8,%r10,4),%xmm0
  .byte  102,67,15,58,33,4,136,32            // insertps      $0x20,(%r8,%r9,4),%xmm0
  .byte  102,65,15,58,33,4,136,48            // insertps      $0x30,(%r8,%rcx,4),%xmm0
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  102,73,15,58,22,202,1               // pextrq        $0x1,%xmm1,%r10
  .byte  77,137,209                          // mov           %r10,%r9
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  65,137,203                          // mov           %ecx,%r11d
  .byte  65,129,227,255,255,255,0            // and           $0xffffff,%r11d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  65,129,226,255,255,255,0            // and           $0xffffff,%r10d
  .byte  243,67,15,16,12,152                 // movss         (%r8,%r11,4),%xmm1
  .byte  102,65,15,58,33,12,8,16             // insertps      $0x10,(%r8,%rcx,1),%xmm1
  .byte  243,67,15,16,28,144                 // movss         (%r8,%r10,4),%xmm3
  .byte  102,15,58,33,203,32                 // insertps      $0x20,%xmm3,%xmm1
  .byte  243,67,15,16,28,136                 // movss         (%r8,%r9,4),%xmm3
  .byte  102,15,58,33,203,48                 // insertps      $0x30,%xmm3,%xmm1
  .byte  76,139,72,24                        // mov           0x18(%rax),%r9
  .byte  102,72,15,58,22,209,1               // pextrq        $0x1,%xmm2,%rcx
  .byte  68,15,183,193                       // movzwl        %cx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,208                   // movq          %xmm2,%rax
  .byte  68,15,183,208                       // movzwl        %ax,%r10d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  243,67,15,16,20,145                 // movss         (%r9,%r10,4),%xmm2
  .byte  102,65,15,58,33,20,1,16             // insertps      $0x10,(%r9,%rax,1),%xmm2
  .byte  243,67,15,16,28,129                 // movss         (%r9,%r8,4),%xmm3
  .byte  102,15,58,33,211,32                 // insertps      $0x20,%xmm3,%xmm2
  .byte  243,65,15,16,28,137                 // movss         (%r9,%rcx,4),%xmm3
  .byte  102,15,58,33,211,48                 // insertps      $0x30,%xmm3,%xmm2
  .byte  102,65,15,114,208,24                // psrld         $0x18,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_sse41
.globl _sk_byte_tables_sse41
_sk_byte_tables_sse41:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  102,67,15,58,32,4,22,0              // pinsrb        $0x0,(%r14,%r10,1),%xmm0
  .byte  102,67,15,58,32,4,30,1              // pinsrb        $0x1,(%r14,%r11,1),%xmm0
  .byte  67,15,182,28,6                      // movzbl        (%r14,%r8,1),%ebx
  .byte  102,15,58,32,195,2                  // pinsrb        $0x2,%ebx,%xmm0
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  102,15,58,32,193,3                  // pinsrb        $0x3,%ecx,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,58,22,201,1               // pextrq        $0x1,%xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,67,15,58,32,12,17,0             // pinsrb        $0x0,(%r9,%r10,1),%xmm1
  .byte  102,65,15,58,32,12,25,1             // pinsrb        $0x1,(%r9,%rbx,1),%xmm1
  .byte  67,15,182,28,1                      // movzbl        (%r9,%r8,1),%ebx
  .byte  102,15,58,32,203,2                  // pinsrb        $0x2,%ebx,%xmm1
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  102,15,58,32,201,3                  // pinsrb        $0x3,%ecx,%xmm1
  .byte  102,15,56,49,201                    // pmovzxbd      %xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,58,22,211,1               // pextrq        $0x1,%xmm2,%rbx
  .byte  65,137,216                          // mov           %ebx,%r8d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,20,17,0             // pinsrb        $0x0,(%r9,%r10,1),%xmm2
  .byte  102,65,15,58,32,20,9,1              // pinsrb        $0x1,(%r9,%rcx,1),%xmm2
  .byte  67,15,182,12,1                      // movzbl        (%r9,%r8,1),%ecx
  .byte  102,15,58,32,209,2                  // pinsrb        $0x2,%ecx,%xmm2
  .byte  65,15,182,12,25                     // movzbl        (%r9,%rbx,1),%ecx
  .byte  102,15,58,32,209,3                  // pinsrb        $0x3,%ecx,%xmm2
  .byte  102,15,56,49,210                    // pmovzxbd      %xmm2,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,65,15,91,216                    // cvtps2dq      %xmm8,%xmm3
  .byte  102,72,15,58,22,217,1               // pextrq        $0x1,%xmm3,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,219                   // movq          %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,66,15,58,32,28,8,0              // pinsrb        $0x0,(%rax,%r9,1),%xmm3
  .byte  102,15,58,32,28,24,1                // pinsrb        $0x1,(%rax,%rbx,1),%xmm3
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  102,15,58,32,219,2                  // pinsrb        $0x2,%ebx,%xmm3
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  102,15,58,32,216,3                  // pinsrb        $0x3,%eax,%xmm3
  .byte  102,15,56,49,219                    // pmovzxbd      %xmm3,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_sse41
.globl _sk_byte_tables_rgb_sse41
_sk_byte_tables_rgb_sse41:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  139,72,24                           // mov           0x18(%rax),%ecx
  .byte  255,201                             // dec           %ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  102,67,15,58,32,4,22,0              // pinsrb        $0x0,(%r14,%r10,1),%xmm0
  .byte  102,67,15,58,32,4,30,1              // pinsrb        $0x1,(%r14,%r11,1),%xmm0
  .byte  67,15,182,28,6                      // movzbl        (%r14,%r8,1),%ebx
  .byte  102,15,58,32,195,2                  // pinsrb        $0x2,%ebx,%xmm0
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  102,15,58,32,193,3                  // pinsrb        $0x3,%ecx,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,58,22,201,1               // pextrq        $0x1,%xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,67,15,58,32,12,17,0             // pinsrb        $0x0,(%r9,%r10,1),%xmm1
  .byte  102,65,15,58,32,12,25,1             // pinsrb        $0x1,(%r9,%rbx,1),%xmm1
  .byte  67,15,182,28,1                      // movzbl        (%r9,%r8,1),%ebx
  .byte  102,15,58,32,203,2                  // pinsrb        $0x2,%ebx,%xmm1
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  102,15,58,32,201,3                  // pinsrb        $0x3,%ecx,%xmm1
  .byte  102,15,56,49,201                    // pmovzxbd      %xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,58,22,209,1               // pextrq        $0x1,%xmm2,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,211                   // movq          %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,66,15,58,32,20,8,0              // pinsrb        $0x0,(%rax,%r9,1),%xmm2
  .byte  102,15,58,32,20,24,1                // pinsrb        $0x1,(%rax,%rbx,1),%xmm2
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  102,15,58,32,211,2                  // pinsrb        $0x2,%ebx,%xmm2
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  102,15,58,32,208,3                  // pinsrb        $0x3,%eax,%xmm2
  .byte  102,15,56,49,210                    // pmovzxbd      %xmm2,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_sse41
.globl _sk_load_a8_sse41
_sk_load_a8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,56,49,4,56                   // pmovzxbd      (%rax,%rdi,1),%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_a8_sse41
.globl _sk_gather_a8_sse41
_sk_gather_a8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,4,17,0              // pinsrb        $0x0,(%r9,%r10,1),%xmm0
  .byte  102,65,15,58,32,4,9,1               // pinsrb        $0x1,(%r9,%rcx,1),%xmm0
  .byte  67,15,182,12,1                      // movzbl        (%r9,%r8,1),%ecx
  .byte  102,15,58,32,193,2                  // pinsrb        $0x2,%ecx,%xmm0
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  102,15,58,32,192,3                  // pinsrb        $0x3,%eax,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,239,210                      // pxor          %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_sse41
.globl _sk_store_a8_sse41
_sk_store_a8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,69,15,103,192                   // packuswb      %xmm8,%xmm8
  .byte  102,68,15,126,4,56                  // movd          %xmm8,(%rax,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_g8_sse41
.globl _sk_load_g8_sse41
_sk_load_g8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,56,49,4,56                   // pmovzxbd      (%rax,%rdi,1),%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_g8_sse41
.globl _sk_gather_g8_sse41
_sk_gather_g8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,4,17,0              // pinsrb        $0x0,(%r9,%r10,1),%xmm0
  .byte  102,65,15,58,32,4,9,1               // pinsrb        $0x1,(%r9,%rcx,1),%xmm0
  .byte  67,15,182,12,1                      // movzbl        (%r9,%r8,1),%ecx
  .byte  102,15,58,32,193,2                  // pinsrb        $0x2,%ecx,%xmm0
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  102,15,58,32,192,3                  // pinsrb        $0x3,%eax,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_sse41
.globl _sk_gather_i8_sse41
_sk_gather_i8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            1c27 <_sk_gather_i8_sse41+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           1c29 <_sk_gather_i8_sse41+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,203                          // mov           %ecx,%r11d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,4,26,0              // pinsrb        $0x0,(%r10,%r11,1),%xmm0
  .byte  102,65,15,58,32,4,10,1              // pinsrb        $0x1,(%r10,%rcx,1),%xmm0
  .byte  102,67,15,58,32,4,10,2              // pinsrb        $0x2,(%r10,%r9,1),%xmm0
  .byte  102,65,15,58,32,4,2,3               // pinsrb        $0x3,(%r10,%rax,1),%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  102,73,15,58,22,193,1               // pextrq        $0x1,%xmm0,%r9
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  73,139,64,8                         // mov           0x8(%r8),%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  102,66,15,110,28,128                // movd          (%rax,%r8,4),%xmm3
  .byte  102,15,58,34,28,8,1                 // pinsrd        $0x1,(%rax,%rcx,1),%xmm3
  .byte  102,66,15,58,34,28,144,2            // pinsrd        $0x2,(%rax,%r10,4),%xmm3
  .byte  102,66,15,58,34,28,8,3              // pinsrd        $0x3,(%rax,%r9,1),%xmm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,200                      // pand          %xmm0,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,15,219,208                      // pand          %xmm0,%xmm2
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_sse41
.globl _sk_load_565_sse41
_sk_load_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,56,51,20,120                 // pmovzxwd      (%rax,%rdi,2),%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_565_sse41
.globl _sk_gather_565_sse41
_sk_gather_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,196,4,81,0                // pinsrw        $0x0,(%r9,%r10,2),%xmm0
  .byte  102,65,15,196,4,73,1                // pinsrw        $0x1,(%r9,%rcx,2),%xmm0
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,15,196,193,2                    // pinsrw        $0x2,%ecx,%xmm0
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,15,196,192,3                    // pinsrw        $0x3,%eax,%xmm0
  .byte  102,15,56,51,208                    // pmovzxwd      %xmm0,%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_sse41
.globl _sk_store_565_sse41
_sk_store_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,248,65                      // mov           $0x41f80000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,11                // pslld         $0xb,%xmm9
  .byte  185,0,0,124,66                      // mov           $0x427c0000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,5                 // pslld         $0x5,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_4444_sse41
.globl _sk_load_4444_sse41
_sk_load_4444_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,51,12,120              // pmovzxwd      (%rax,%rdi,2),%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_4444_sse41
.globl _sk_gather_4444_sse41
_sk_gather_4444_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,196,4,81,0                // pinsrw        $0x0,(%r9,%r10,2),%xmm0
  .byte  102,65,15,196,4,73,1                // pinsrw        $0x1,(%r9,%rcx,2),%xmm0
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,15,196,193,2                    // pinsrw        $0x2,%ecx,%xmm0
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,15,196,192,3                    // pinsrw        $0x3,%eax,%xmm0
  .byte  102,68,15,56,51,200                 // pmovzxwd      %xmm0,%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_sse41
.globl _sk_store_4444_sse41
_sk_store_4444_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,112,65                      // mov           $0x41700000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,12                // pslld         $0xc,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,4                 // pslld         $0x4,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,193                    // orpd          %xmm9,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_8888_sse41
.globl _sk_load_8888_sse41
_sk_load_8888_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,28,184                   // movdqu        (%rax,%rdi,4),%xmm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,200                      // pand          %xmm0,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,15,219,208                      // pand          %xmm0,%xmm2
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_8888_sse41
.globl _sk_gather_8888_sse41
_sk_gather_8888_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,110,28,129                // movd          (%r9,%r8,4),%xmm3
  .byte  102,65,15,58,34,28,129,1            // pinsrd        $0x1,(%r9,%rax,4),%xmm3
  .byte  102,67,15,58,34,28,145,2            // pinsrd        $0x2,(%r9,%r10,4),%xmm3
  .byte  102,65,15,58,34,28,137,3            // pinsrd        $0x3,(%r9,%rcx,4),%xmm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,200                      // pand          %xmm0,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,15,219,208                      // pand          %xmm0,%xmm2
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_sse41
.globl _sk_store_8888_sse41
_sk_store_8888_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,24                // pslld         $0x18,%xmm8
  .byte  102,69,15,235,193                   // por           %xmm9,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  243,68,15,127,4,184                 // movdqu        %xmm8,(%rax,%rdi,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f16_sse41
.globl _sk_load_f16_sse41
_sk_load_f16_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,68,15,111,192                   // movdqa        %xmm0,%xmm8
  .byte  102,68,15,97,193                    // punpcklwd     %xmm1,%xmm8
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,65,15,111,200                   // movdqa        %xmm8,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,68,15,105,192                   // punpckhwd     %xmm0,%xmm8
  .byte  184,0,4,0,4                         // mov           $0x4000400,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,216,0                    // pshufd        $0x0,%xmm0,%xmm3
  .byte  102,15,111,195                      // movdqa        %xmm3,%xmm0
  .byte  102,15,101,193                      // pcmpgtw       %xmm1,%xmm0
  .byte  102,15,223,193                      // pandn         %xmm1,%xmm0
  .byte  102,15,56,51,192                    // pmovzxwd      %xmm0,%xmm0
  .byte  102,15,114,240,13                   // pslld         $0xd,%xmm0
  .byte  184,0,0,128,119                     // mov           $0x77800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,68,15,112,202,0                 // pshufd        $0x0,%xmm2,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  102,15,112,201,78                   // pshufd        $0x4e,%xmm1,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,101,209                      // pcmpgtw       %xmm1,%xmm2
  .byte  102,15,223,209                      // pandn         %xmm1,%xmm2
  .byte  102,15,56,51,202                    // pmovzxwd      %xmm2,%xmm1
  .byte  102,15,114,241,13                   // pslld         $0xd,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,65,15,101,208                   // pcmpgtw       %xmm8,%xmm2
  .byte  102,65,15,223,208                   // pandn         %xmm8,%xmm2
  .byte  102,15,56,51,210                    // pmovzxwd      %xmm2,%xmm2
  .byte  102,15,114,242,13                   // pslld         $0xd,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  102,69,15,112,192,78                // pshufd        $0x4e,%xmm8,%xmm8
  .byte  102,65,15,101,216                   // pcmpgtw       %xmm8,%xmm3
  .byte  102,65,15,223,216                   // pandn         %xmm8,%xmm3
  .byte  102,15,56,51,219                    // pmovzxwd      %xmm3,%xmm3
  .byte  102,15,114,243,13                   // pslld         $0xd,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_f16_sse41
.globl _sk_gather_f16_sse41
_sk_gather_f16_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,65,15,126,4,201                 // movq          (%r9,%rcx,8),%xmm0
  .byte  243,67,15,126,12,209                // movq          (%r9,%r10,8),%xmm1
  .byte  102,15,108,200                      // punpcklqdq    %xmm0,%xmm1
  .byte  243,65,15,126,4,193                 // movq          (%r9,%rax,8),%xmm0
  .byte  243,67,15,126,20,193                // movq          (%r9,%r8,8),%xmm2
  .byte  102,15,108,208                      // punpcklqdq    %xmm0,%xmm2
  .byte  102,68,15,111,194                   // movdqa        %xmm2,%xmm8
  .byte  102,68,15,97,193                    // punpcklwd     %xmm1,%xmm8
  .byte  102,15,105,209                      // punpckhwd     %xmm1,%xmm2
  .byte  102,65,15,111,200                   // movdqa        %xmm8,%xmm1
  .byte  102,15,97,202                       // punpcklwd     %xmm2,%xmm1
  .byte  102,68,15,105,194                   // punpckhwd     %xmm2,%xmm8
  .byte  184,0,4,0,4                         // mov           $0x4000400,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,216,0                    // pshufd        $0x0,%xmm0,%xmm3
  .byte  102,15,111,195                      // movdqa        %xmm3,%xmm0
  .byte  102,15,101,193                      // pcmpgtw       %xmm1,%xmm0
  .byte  102,15,223,193                      // pandn         %xmm1,%xmm0
  .byte  102,15,56,51,192                    // pmovzxwd      %xmm0,%xmm0
  .byte  102,15,114,240,13                   // pslld         $0xd,%xmm0
  .byte  184,0,0,128,119                     // mov           $0x77800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,68,15,112,202,0                 // pshufd        $0x0,%xmm2,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  102,15,112,201,78                   // pshufd        $0x4e,%xmm1,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,101,209                      // pcmpgtw       %xmm1,%xmm2
  .byte  102,15,223,209                      // pandn         %xmm1,%xmm2
  .byte  102,15,56,51,202                    // pmovzxwd      %xmm2,%xmm1
  .byte  102,15,114,241,13                   // pslld         $0xd,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,65,15,101,208                   // pcmpgtw       %xmm8,%xmm2
  .byte  102,65,15,223,208                   // pandn         %xmm8,%xmm2
  .byte  102,15,56,51,210                    // pmovzxwd      %xmm2,%xmm2
  .byte  102,15,114,242,13                   // pslld         $0xd,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  102,69,15,112,192,78                // pshufd        $0x4e,%xmm8,%xmm8
  .byte  102,65,15,101,216                   // pcmpgtw       %xmm8,%xmm3
  .byte  102,65,15,223,216                   // pandn         %xmm8,%xmm3
  .byte  102,15,56,51,219                    // pmovzxwd      %xmm3,%xmm3
  .byte  102,15,114,243,13                   // pslld         $0xd,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_sse41
.globl _sk_store_f16_sse41
_sk_store_f16_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,128,7                       // mov           $0x7800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  102,69,15,112,200,0                 // pshufd        $0x0,%xmm8,%xmm9
  .byte  102,69,15,111,193                   // movdqa        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,65,15,114,208,13                // psrld         $0xd,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,69,15,111,209                   // movdqa        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,65,15,114,210,13                // psrld         $0xd,%xmm10
  .byte  102,69,15,56,43,210                 // packusdw      %xmm10,%xmm10
  .byte  102,69,15,111,217                   // movdqa        %xmm9,%xmm11
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  102,65,15,114,211,13                // psrld         $0xd,%xmm11
  .byte  102,69,15,56,43,219                 // packusdw      %xmm11,%xmm11
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  102,65,15,114,209,13                // psrld         $0xd,%xmm9
  .byte  102,69,15,56,43,201                 // packusdw      %xmm9,%xmm9
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,97,217                    // punpcklwd     %xmm9,%xmm11
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,203                    // punpckldq     %xmm11,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,195                   // punpckhdq     %xmm11,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_u16_be_sse41
.globl _sk_load_u16_be_sse41
_sk_load_u16_be_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,15,111,208                      // movdqa        %xmm0,%xmm2
  .byte  102,15,97,209                       // punpcklwd     %xmm1,%xmm2
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,15,111,202                      // movdqa        %xmm2,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,15,105,208                      // punpckhwd     %xmm0,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,15,113,240,8                    // psllw         $0x8,%xmm0
  .byte  102,15,112,217,78                   // pshufd        $0x4e,%xmm1,%xmm3
  .byte  102,15,113,209,8                    // psrlw         $0x8,%xmm1
  .byte  102,15,235,200                      // por           %xmm0,%xmm1
  .byte  102,15,56,51,193                    // pmovzxwd      %xmm1,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,15,235,217                      // por           %xmm1,%xmm3
  .byte  102,15,56,51,203                    // pmovzxwd      %xmm3,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,68,15,111,202                   // movdqa        %xmm2,%xmm9
  .byte  102,65,15,113,241,8                 // psllw         $0x8,%xmm9
  .byte  102,15,112,218,78                   // pshufd        $0x4e,%xmm2,%xmm3
  .byte  102,15,113,210,8                    // psrlw         $0x8,%xmm2
  .byte  102,65,15,235,209                   // por           %xmm9,%xmm2
  .byte  102,15,56,51,210                    // pmovzxwd      %xmm2,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,68,15,111,203                   // movdqa        %xmm3,%xmm9
  .byte  102,65,15,113,241,8                 // psllw         $0x8,%xmm9
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,65,15,235,217                   // por           %xmm9,%xmm3
  .byte  102,15,56,51,219                    // pmovzxwd      %xmm3,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_u16_be_sse41
.globl _sk_store_u16_be_sse41
_sk_store_u16_be_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,255,127,71                    // mov           $0x477fff00,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,69,15,111,208                   // movdqa        %xmm8,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,65,15,113,208,8                 // psrlw         $0x8,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,69,15,56,43,210                 // packusdw      %xmm10,%xmm10
  .byte  102,69,15,111,218                   // movdqa        %xmm10,%xmm11
  .byte  102,65,15,113,243,8                 // psllw         $0x8,%xmm11
  .byte  102,65,15,113,210,8                 // psrlw         $0x8,%xmm10
  .byte  102,69,15,235,211                   // por           %xmm11,%xmm10
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  102,69,15,91,219                    // cvtps2dq      %xmm11,%xmm11
  .byte  102,69,15,56,43,219                 // packusdw      %xmm11,%xmm11
  .byte  102,69,15,111,227                   // movdqa        %xmm11,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,211,8                 // psrlw         $0x8,%xmm11
  .byte  102,69,15,235,220                   // por           %xmm12,%xmm11
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,69,15,56,43,201                 // packusdw      %xmm9,%xmm9
  .byte  102,69,15,111,225                   // movdqa        %xmm9,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,209,8                 // psrlw         $0x8,%xmm9
  .byte  102,69,15,235,204                   // por           %xmm12,%xmm9
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,97,217                    // punpcklwd     %xmm9,%xmm11
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,203                    // punpckldq     %xmm11,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,195                   // punpckhdq     %xmm11,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f32_sse41
.globl _sk_load_f32_sse41
_sk_load_f32_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,16,4,8                        // movups        (%rax,%rcx,1),%xmm8
  .byte  15,16,68,8,16                       // movups        0x10(%rax,%rcx,1),%xmm0
  .byte  15,16,92,8,32                       // movups        0x20(%rax,%rcx,1),%xmm3
  .byte  68,15,16,76,8,48                    // movups        0x30(%rax,%rcx,1),%xmm9
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,20,208                           // unpcklps      %xmm0,%xmm2
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  65,15,20,201                        // unpcklps      %xmm9,%xmm1
  .byte  68,15,21,192                        // unpckhps      %xmm0,%xmm8
  .byte  65,15,21,217                        // unpckhps      %xmm9,%xmm3
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,15,20,193                       // unpcklpd      %xmm1,%xmm0
  .byte  15,18,202                           // movhlps       %xmm2,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  102,15,20,211                       // unpcklpd      %xmm3,%xmm2
  .byte  65,15,18,216                        // movhlps       %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f32_sse41
.globl _sk_store_f32_sse41
_sk_store_f32_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  68,15,20,201                        // unpcklps      %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,40,218                        // movaps        %xmm2,%xmm11
  .byte  68,15,20,219                        // unpcklps      %xmm3,%xmm11
  .byte  68,15,21,193                        // unpckhps      %xmm1,%xmm8
  .byte  68,15,21,211                        // unpckhps      %xmm3,%xmm10
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  102,69,15,20,227                    // unpcklpd      %xmm11,%xmm12
  .byte  69,15,18,217                        // movhlps       %xmm9,%xmm11
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  102,69,15,20,202                    // unpcklpd      %xmm10,%xmm9
  .byte  69,15,18,208                        // movhlps       %xmm8,%xmm10
  .byte  102,68,15,17,36,8                   // movupd        %xmm12,(%rax,%rcx,1)
  .byte  68,15,17,92,8,16                    // movups        %xmm11,0x10(%rax,%rcx,1)
  .byte  102,68,15,17,76,8,32                // movupd        %xmm9,0x20(%rax,%rcx,1)
  .byte  68,15,17,84,8,48                    // movups        %xmm10,0x30(%rax,%rcx,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_x_sse41
.globl _sk_clamp_x_sse41
_sk_clamp_x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,192                        // maxps         %xmm0,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,192                      // pcmpeqd       %xmm0,%xmm0
  .byte  102,65,15,254,193                   // paddd         %xmm9,%xmm0
  .byte  68,15,93,192                        // minps         %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_sse41
.globl _sk_clamp_y_sse41
_sk_clamp_y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,193                        // maxps         %xmm1,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,201                      // pcmpeqd       %xmm1,%xmm1
  .byte  102,65,15,254,201                   // paddd         %xmm9,%xmm1
  .byte  68,15,93,193                        // minps         %xmm1,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_sse41
.globl _sk_repeat_x_sse41
_sk_repeat_x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  102,69,15,58,8,201,1                // roundps       $0x1,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,193                        // minps         %xmm9,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_sse41
.globl _sk_repeat_y_sse41
_sk_repeat_y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  102,69,15,58,8,201,1                // roundps       $0x1,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,201                        // minps         %xmm9,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_sse41
.globl _sk_mirror_x_sse41
_sk_mirror_x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  243,69,15,88,192                    // addss         %xmm8,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,208                        // movaps        %xmm0,%xmm10
  .byte  69,15,94,208                        // divps         %xmm8,%xmm10
  .byte  102,69,15,58,8,210,1                // roundps       $0x1,%xmm10,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,194                        // subps         %xmm10,%xmm0
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  65,15,84,192                        // andps         %xmm8,%xmm0
  .byte  102,69,15,118,192                   // pcmpeqd       %xmm8,%xmm8
  .byte  102,69,15,254,193                   // paddd         %xmm9,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_sse41
.globl _sk_mirror_y_sse41
_sk_mirror_y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  243,69,15,88,192                    // addss         %xmm8,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  69,15,94,208                        // divps         %xmm8,%xmm10
  .byte  102,69,15,58,8,210,1                // roundps       $0x1,%xmm10,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,202                        // subps         %xmm10,%xmm1
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,92,193                        // subps         %xmm1,%xmm8
  .byte  65,15,84,200                        // andps         %xmm8,%xmm1
  .byte  102,69,15,118,192                   // pcmpeqd       %xmm8,%xmm8
  .byte  102,69,15,254,193                   // paddd         %xmm9,%xmm8
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_sse41
.globl _sk_luminance_to_alpha_sse41
_sk_luminance_to_alpha_sse41:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  15,88,195                           // addps         %xmm3,%xmm0
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,218                           // mulps         %xmm2,%xmm3
  .byte  15,88,216                           // addps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_sse41
.globl _sk_matrix_2x3_sse41
_sk_matrix_2x3_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,16                  // movss         0x10(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_sse41
.globl _sk_matrix_3x4_sse41
_sk_matrix_3x4_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,36                  // movss         0x24(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_sse41
.globl _sk_matrix_4x5_sse41
_sk_matrix_4x5_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,32                  // movss         0x20(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,48                  // movss         0x30(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,64                 // movss         0x40(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,20                  // movss         0x14(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,36                  // movss         0x24(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,52                  // movss         0x34(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,68                 // movss         0x44(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,56                 // movss         0x38(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,72                 // movss         0x48(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  243,68,15,16,88,12                  // movss         0xc(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,28                  // movss         0x1c(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,60                 // movss         0x3c(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  243,68,15,16,120,76                 // movss         0x4c(%rax),%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,247                        // addps         %xmm15,%xmm14
  .byte  68,15,89,234                        // mulps         %xmm2,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,216                        // mulps         %xmm8,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_sse41
.globl _sk_matrix_perspective_sse41
_sk_matrix_perspective_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,68,15,16,72,4                   // movss         0x4(%rax),%xmm9
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  243,68,15,16,80,24                  // movss         0x18(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,83,202                        // rcpps         %xmm10,%xmm1
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_sse41
.globl _sk_linear_gradient_sse41
_sk_linear_gradient_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,24                  // movss         0x18(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,28                 // movss         0x1c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,132,254,0,0,0                    // je            2d95 <_sk_linear_gradient_sse41+0x138>
  .byte  15,41,100,36,168                    // movaps        %xmm4,-0x58(%rsp)
  .byte  15,41,108,36,184                    // movaps        %xmm5,-0x48(%rsp)
  .byte  15,41,116,36,200                    // movaps        %xmm6,-0x38(%rsp)
  .byte  15,41,124,36,216                    // movaps        %xmm7,-0x28(%rsp)
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  69,15,87,201                        // xorps         %xmm9,%xmm9
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  15,40,251                           // movaps        %xmm3,%xmm7
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  69,15,40,243                        // movaps        %xmm11,%xmm14
  .byte  69,15,40,252                        // movaps        %xmm12,%xmm15
  .byte  68,15,41,108,36,232                 // movaps        %xmm13,-0x18(%rsp)
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  243,15,16,80,224                    // movss         -0x20(%rax),%xmm2
  .byte  243,68,15,16,72,228                 // movss         -0x1c(%rax),%xmm9
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,194,194,1                        // cmpltps       %xmm2,%xmm0
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,68,15,56,20,201                 // blendvps      %xmm0,%xmm1,%xmm9
  .byte  243,15,16,72,232                    // movss         -0x18(%rax),%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  102,15,56,20,205                    // blendvps      %xmm0,%xmm5,%xmm1
  .byte  243,15,16,80,236                    // movss         -0x14(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  102,15,56,20,214                    // blendvps      %xmm0,%xmm6,%xmm2
  .byte  243,15,16,88,240                    // movss         -0x10(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  102,15,56,20,223                    // blendvps      %xmm0,%xmm7,%xmm3
  .byte  243,68,15,16,80,244                 // movss         -0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  102,69,15,56,20,208                 // blendvps      %xmm0,%xmm8,%xmm10
  .byte  243,68,15,16,88,248                 // movss         -0x8(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  102,69,15,56,20,222                 // blendvps      %xmm0,%xmm14,%xmm11
  .byte  243,68,15,16,96,252                 // movss         -0x4(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  102,69,15,56,20,231                 // blendvps      %xmm0,%xmm15,%xmm12
  .byte  243,68,15,16,40                     // movss         (%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  102,68,15,56,20,108,36,232          // blendvps      %xmm0,-0x18(%rsp),%xmm13
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  72,255,201                          // dec           %rcx
  .byte  15,133,65,255,255,255               // jne           2cc0 <_sk_linear_gradient_sse41+0x63>
  .byte  15,40,124,36,216                    // movaps        -0x28(%rsp),%xmm7
  .byte  15,40,116,36,200                    // movaps        -0x38(%rsp),%xmm6
  .byte  15,40,108,36,184                    // movaps        -0x48(%rsp),%xmm5
  .byte  15,40,100,36,168                    // movaps        -0x58(%rsp),%xmm4
  .byte  235,13                              // jmp           2da2 <_sk_linear_gradient_sse41+0x145>
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  69,15,87,201                        // xorps         %xmm9,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  15,89,200                           // mulps         %xmm0,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  15,89,208                           // mulps         %xmm0,%xmm2
  .byte  65,15,88,212                        // addps         %xmm12,%xmm2
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  65,15,88,221                        // addps         %xmm13,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_sse41
.globl _sk_linear_gradient_2stops_sse41
_sk_linear_gradient_2stops_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,15,16,80,16                     // movss         0x10(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,20                     // movss         0x14(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,24                     // movss         0x18(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,211                           // addps         %xmm3,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  243,68,15,16,72,28                  // movss         0x1c(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_sse41
.globl _sk_save_xy_sse41
_sk_save_xy_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,88,200                        // addps         %xmm0,%xmm9
  .byte  102,69,15,58,8,209,1                // roundps       $0x1,%xmm9,%xmm10
  .byte  69,15,92,202                        // subps         %xmm10,%xmm9
  .byte  68,15,88,193                        // addps         %xmm1,%xmm8
  .byte  102,69,15,58,8,208,1                // roundps       $0x1,%xmm8,%xmm10
  .byte  69,15,92,194                        // subps         %xmm10,%xmm8
  .byte  15,17,0                             // movups        %xmm0,(%rax)
  .byte  15,17,72,32                         // movups        %xmm1,0x20(%rax)
  .byte  68,15,17,72,64                      // movups        %xmm9,0x40(%rax)
  .byte  68,15,17,64,96                      // movups        %xmm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_sse41
.globl _sk_accumulate_sse41
_sk_accumulate_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,15,16,128,128,0,0,0              // movups        0x80(%rax),%xmm8
  .byte  68,15,16,136,160,0,0,0              // movups        0xa0(%rax),%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,88,224                        // addps         %xmm8,%xmm4
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  65,15,88,232                        // addps         %xmm8,%xmm5
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  65,15,88,240                        // addps         %xmm8,%xmm6
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  65,15,88,249                        // addps         %xmm9,%xmm7
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_sse41
.globl _sk_bilinear_nx_sse41
_sk_bilinear_nx_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_sse41
.globl _sk_bilinear_px_sse41
_sk_bilinear_px_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_sse41
.globl _sk_bilinear_ny_sse41
_sk_bilinear_ny_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_sse41
.globl _sk_bilinear_py_sse41
_sk_bilinear_py_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_sse41
.globl _sk_bicubic_n3x_sse41
_sk_bicubic_n3x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_sse41
.globl _sk_bicubic_n1x_sse41
_sk_bicubic_n1x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_sse41
.globl _sk_bicubic_p1x_sse41
_sk_bicubic_p1x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,128,0,0,0              // movups        %xmm10,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_sse41
.globl _sk_bicubic_p3x_sse41
_sk_bicubic_p3x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_sse41
.globl _sk_bicubic_n3y_sse41
_sk_bicubic_n3y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_sse41
.globl _sk_bicubic_n1y_sse41
_sk_bicubic_n1y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_sse41
.globl _sk_bicubic_p1y_sse41
_sk_bicubic_p1y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,160,0,0,0              // movups        %xmm10,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_sse41
.globl _sk_bicubic_p3y_sse41
_sk_bicubic_p3y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_start_pipeline_sse2
.globl _sk_start_pipeline_sse2
_sk_start_pipeline_sse2:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,207                          // mov           %rcx,%r15
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,196                          // mov           %rax,%r12
  .byte  73,137,245                          // mov           %rsi,%r13
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  76,57,248                           // cmp           %r15,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_sse2+0x28>
  .byte  72,137,216                          // mov           %rbx,%rax
  .byte  235,52                              // jmp           5c <_sk_start_pipeline_sse2+0x5c>
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,238                          // mov           %r13,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,212                          // callq         *%r12
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  72,131,195,8                        // add           $0x8,%rbx
  .byte  76,57,251                           // cmp           %r15,%rbx
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  118,204                             // jbe           28 <_sk_start_pipeline_sse2+0x28>
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  195                                 // retq

HIDDEN _sk_just_return_sse2
.globl _sk_just_return_sse2
_sk_just_return_sse2:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_sse2
.globl _sk_seed_shader_sse2
_sk_seed_shader_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  102,15,110,199                      // movd          %edi,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,15,110,209                      // movd          %ecx,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  15,16,2                             // movups        (%rdx),%xmm0
  .byte  15,88,193                           // addps         %xmm1,%xmm0
  .byte  102,15,110,8                        // movd          (%rax),%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_sse2
.globl _sk_constant_color_sse2
_sk_constant_color_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_sse2
.globl _sk_clear_sse2
_sk_clear_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_sse2
.globl _sk_srcatop_sse2
_sk_srcatop_sse2:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_sse2
.globl _sk_dstatop_sse2
_sk_dstatop_sse2:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,198                        // mulps         %xmm6,%xmm8
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_sse2
.globl _sk_srcin_sse2
_sk_srcin_sse2:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_sse2
.globl _sk_dstin_sse2
_sk_dstin_sse2:
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_sse2
.globl _sk_srcout_sse2
_sk_srcout_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_sse2
.globl _sk_dstout_sse2
_sk_dstout_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_sse2
.globl _sk_srcover_sse2
_sk_srcover_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_sse2
.globl _sk_dstover_sse2
_sk_dstover_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_sse2
.globl _sk_modulate_sse2
_sk_modulate_sse2:
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_sse2
.globl _sk_multiply_sse2
_sk_multiply_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,220                        // mulps         %xmm4,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,88,195                        // addps         %xmm11,%xmm0
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,221                        // mulps         %xmm5,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,222                        // mulps         %xmm6,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__sse2
.globl _sk_plus__sse2
_sk_plus__sse2:
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_sse2
.globl _sk_screen_sse2
_sk_screen_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,88,196                        // addps         %xmm4,%xmm8
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,88,205                        // addps         %xmm5,%xmm9
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,88,214                        // addps         %xmm6,%xmm10
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,92,210                        // subps         %xmm2,%xmm10
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,88,223                        // addps         %xmm7,%xmm11
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__sse2
.globl _sk_xor__sse2
_sk_xor__sse2:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,92,216                        // subps         %xmm8,%xmm3
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,212                        // mulps         %xmm4,%xmm10
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,213                        // mulps         %xmm5,%xmm10
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_sse2
.globl _sk_darken_sse2
_sk_darken_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,95,201                        // maxps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,95,193                        // maxps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,95,209                        // maxps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_sse2
.globl _sk_lighten_sse2
_sk_lighten_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_sse2
.globl _sk_difference_sse2
_sk_difference_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_sse2
.globl _sk_exclusion_sse2
_sk_exclusion_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_sse2
.globl _sk_colorburn_sse2
_sk_colorburn_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,196                        // mulps         %xmm12,%xmm0
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  15,40,207                           // movaps        %xmm7,%xmm1
  .byte  15,92,204                           // subps         %xmm4,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  65,15,94,204                        // divps         %xmm12,%xmm1
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,93,233                        // minps         %xmm1,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  65,15,40,204                        // movaps        %xmm12,%xmm1
  .byte  65,15,194,202,0                     // cmpeqps       %xmm10,%xmm1
  .byte  68,15,92,203                        // subps         %xmm3,%xmm9
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  68,15,88,240                        // addps         %xmm0,%xmm14
  .byte  68,15,84,225                        // andps         %xmm1,%xmm12
  .byte  65,15,85,206                        // andnps        %xmm14,%xmm1
  .byte  69,15,40,233                        // movaps        %xmm9,%xmm13
  .byte  68,15,89,236                        // mulps         %xmm4,%xmm13
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  65,15,86,204                        // orps          %xmm12,%xmm1
  .byte  68,15,40,228                        // movaps        %xmm4,%xmm12
  .byte  68,15,194,231,0                     // cmpeqps       %xmm7,%xmm12
  .byte  65,15,88,205                        // addps         %xmm13,%xmm1
  .byte  65,15,84,196                        // andps         %xmm12,%xmm0
  .byte  68,15,85,225                        // andnps        %xmm1,%xmm12
  .byte  65,15,86,196                        // orps          %xmm12,%xmm0
  .byte  65,15,40,203                        // movaps        %xmm11,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,92,229                        // subps         %xmm5,%xmm12
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,94,224                        // divps         %xmm8,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  69,15,194,234,0                     // cmpeqps       %xmm10,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  68,15,88,225                        // addps         %xmm1,%xmm12
  .byte  69,15,84,197                        // andps         %xmm13,%xmm8
  .byte  69,15,85,236                        // andnps        %xmm12,%xmm13
  .byte  69,15,86,232                        // orps          %xmm8,%xmm13
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  69,15,88,232                        // addps         %xmm8,%xmm13
  .byte  68,15,40,197                        // movaps        %xmm5,%xmm8
  .byte  68,15,194,199,0                     // cmpeqps       %xmm7,%xmm8
  .byte  65,15,84,200                        // andps         %xmm8,%xmm1
  .byte  69,15,85,197                        // andnps        %xmm13,%xmm8
  .byte  65,15,86,200                        // orps          %xmm8,%xmm1
  .byte  68,15,40,199                        // movaps        %xmm7,%xmm8
  .byte  68,15,92,198                        // subps         %xmm6,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  68,15,94,194                        // divps         %xmm2,%xmm8
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  69,15,93,224                        // minps         %xmm8,%xmm12
  .byte  68,15,40,199                        // movaps        %xmm7,%xmm8
  .byte  69,15,92,196                        // subps         %xmm12,%xmm8
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  68,15,194,210,0                     // cmpeqps       %xmm2,%xmm10
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  69,15,88,195                        // addps         %xmm11,%xmm8
  .byte  65,15,84,210                        // andps         %xmm10,%xmm2
  .byte  69,15,85,208                        // andnps        %xmm8,%xmm10
  .byte  69,15,40,195                        // movaps        %xmm11,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  68,15,86,210                        // orps          %xmm2,%xmm10
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,88,210                        // addps         %xmm2,%xmm10
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,194,215,0                        // cmpeqps       %xmm7,%xmm2
  .byte  68,15,84,194                        // andps         %xmm2,%xmm8
  .byte  65,15,85,210                        // andnps        %xmm10,%xmm2
  .byte  68,15,86,194                        // orps          %xmm2,%xmm8
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_sse2
.globl _sk_colordodge_sse2
_sk_colordodge_sse2:
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  69,15,92,225                        // subps         %xmm9,%xmm12
  .byte  69,15,94,196                        // divps         %xmm12,%xmm8
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  69,15,93,232                        // minps         %xmm8,%xmm13
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,194,243,0                     // cmpeqps       %xmm3,%xmm14
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  68,15,88,232                        // addps         %xmm0,%xmm13
  .byte  69,15,84,206                        // andps         %xmm14,%xmm9
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  69,15,86,241                        // orps          %xmm9,%xmm14
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  69,15,88,241                        // addps         %xmm9,%xmm14
  .byte  68,15,40,204                        // movaps        %xmm4,%xmm9
  .byte  69,15,194,200,0                     // cmpeqps       %xmm8,%xmm9
  .byte  65,15,84,193                        // andps         %xmm9,%xmm0
  .byte  69,15,85,206                        // andnps        %xmm14,%xmm9
  .byte  65,15,86,193                        // orps          %xmm9,%xmm0
  .byte  68,15,40,235                        // movaps        %xmm3,%xmm13
  .byte  68,15,89,237                        // mulps         %xmm5,%xmm13
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  69,15,94,233                        // divps         %xmm9,%xmm13
  .byte  69,15,40,203                        // movaps        %xmm11,%xmm9
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,93,229                        // minps         %xmm13,%xmm12
  .byte  68,15,40,233                        // movaps        %xmm1,%xmm13
  .byte  68,15,194,235,0                     // cmpeqps       %xmm3,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,225                        // addps         %xmm9,%xmm12
  .byte  65,15,84,205                        // andps         %xmm13,%xmm1
  .byte  69,15,85,236                        // andnps        %xmm12,%xmm13
  .byte  68,15,86,233                        // orps          %xmm1,%xmm13
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,88,205                        // addps         %xmm5,%xmm9
  .byte  68,15,88,233                        // addps         %xmm1,%xmm13
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  65,15,194,200,0                     // cmpeqps       %xmm8,%xmm1
  .byte  68,15,84,201                        // andps         %xmm1,%xmm9
  .byte  65,15,85,205                        // andnps        %xmm13,%xmm1
  .byte  68,15,86,201                        // orps          %xmm1,%xmm9
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,230                        // mulps         %xmm6,%xmm12
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,92,202                           // subps         %xmm2,%xmm1
  .byte  68,15,94,225                        // divps         %xmm1,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  15,40,202                           // movaps        %xmm2,%xmm1
  .byte  15,194,203,0                        // cmpeqps       %xmm3,%xmm1
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  15,84,209                           // andps         %xmm1,%xmm2
  .byte  65,15,85,205                        // andnps        %xmm13,%xmm1
  .byte  15,86,202                           // orps          %xmm2,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  68,15,194,198,0                     // cmpeqps       %xmm6,%xmm8
  .byte  68,15,88,222                        // addps         %xmm6,%xmm11
  .byte  69,15,84,216                        // andps         %xmm8,%xmm11
  .byte  68,15,85,193                        // andnps        %xmm1,%xmm8
  .byte  69,15,86,195                        // orps          %xmm11,%xmm8
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_sse2
.globl _sk_hardlight_sse2
_sk_hardlight_sse2:
  .byte  15,41,116,36,232                    // movaps        %xmm6,-0x18(%rsp)
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,92,215                        // subps         %xmm7,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  69,15,40,203                        // movaps        %xmm11,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,88,200                        // addps         %xmm8,%xmm9
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,89,231                           // mulps         %xmm7,%xmm4
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  68,15,40,255                        // movaps        %xmm7,%xmm15
  .byte  68,15,92,253                        // subps         %xmm5,%xmm15
  .byte  69,15,89,248                        // mulps         %xmm8,%xmm15
  .byte  69,15,88,255                        // addps         %xmm15,%xmm15
  .byte  68,15,40,228                        // movaps        %xmm4,%xmm12
  .byte  69,15,92,231                        // subps         %xmm15,%xmm12
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  68,15,194,195,2                     // cmpleps       %xmm3,%xmm8
  .byte  15,89,197                           // mulps         %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  65,15,84,192                        // andps         %xmm8,%xmm0
  .byte  69,15,85,196                        // andnps        %xmm12,%xmm8
  .byte  68,15,86,192                        // orps          %xmm0,%xmm8
  .byte  69,15,40,251                        // movaps        %xmm11,%xmm15
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  68,15,89,223                        // mulps         %xmm7,%xmm11
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  68,15,89,254                        // mulps         %xmm6,%xmm15
  .byte  68,15,88,248                        // addps         %xmm0,%xmm15
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  68,15,92,238                        // subps         %xmm6,%xmm13
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  65,15,92,197                        // subps         %xmm13,%xmm0
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  68,15,194,203,2                     // cmpleps       %xmm3,%xmm9
  .byte  15,89,206                           // mulps         %xmm6,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  65,15,84,201                        // andps         %xmm9,%xmm1
  .byte  68,15,85,200                        // andnps        %xmm0,%xmm9
  .byte  68,15,86,201                        // orps          %xmm1,%xmm9
  .byte  69,15,88,207                        // addps         %xmm15,%xmm9
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  68,15,40,108,36,232                 // movaps        -0x18(%rsp),%xmm13
  .byte  69,15,89,229                        // mulps         %xmm13,%xmm12
  .byte  69,15,88,226                        // addps         %xmm10,%xmm12
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  69,15,88,210                        // addps         %xmm10,%xmm10
  .byte  68,15,194,211,2                     // cmpleps       %xmm3,%xmm10
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,194                           // subps         %xmm2,%xmm0
  .byte  65,15,89,213                        // mulps         %xmm13,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  68,15,89,240                        // mulps         %xmm0,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  65,15,92,230                        // subps         %xmm14,%xmm4
  .byte  65,15,84,210                        // andps         %xmm10,%xmm2
  .byte  68,15,85,212                        // andnps        %xmm4,%xmm10
  .byte  68,15,86,210                        // orps          %xmm2,%xmm10
  .byte  69,15,88,212                        // addps         %xmm12,%xmm10
  .byte  65,15,88,219                        // addps         %xmm11,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,40,238                           // movaps        %xmm6,%xmm5
  .byte  65,15,40,245                        // movaps        %xmm13,%xmm6
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_sse2
.globl _sk_overlay_sse2
_sk_overlay_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,220                        // mulps         %xmm4,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,92,224                        // subps         %xmm0,%xmm12
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,92,236                        // subps         %xmm4,%xmm13
  .byte  68,15,40,244                        // movaps        %xmm4,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  68,15,194,247,2                     // cmpleps       %xmm7,%xmm14
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  69,15,89,236                        // mulps         %xmm12,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  69,15,40,226                        // movaps        %xmm10,%xmm12
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  65,15,84,198                        // andps         %xmm14,%xmm0
  .byte  69,15,85,244                        // andnps        %xmm12,%xmm14
  .byte  65,15,86,198                        // orps          %xmm14,%xmm0
  .byte  65,15,88,195                        // addps         %xmm11,%xmm0
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  69,15,40,224                        // movaps        %xmm8,%xmm12
  .byte  68,15,89,229                        // mulps         %xmm5,%xmm12
  .byte  69,15,88,227                        // addps         %xmm11,%xmm12
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,92,217                        // subps         %xmm1,%xmm11
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,92,237                        // subps         %xmm5,%xmm13
  .byte  68,15,40,245                        // movaps        %xmm5,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  68,15,194,247,2                     // cmpleps       %xmm7,%xmm14
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  69,15,89,235                        // mulps         %xmm11,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  69,15,92,221                        // subps         %xmm13,%xmm11
  .byte  65,15,84,206                        // andps         %xmm14,%xmm1
  .byte  69,15,85,243                        // andnps        %xmm11,%xmm14
  .byte  65,15,86,206                        // orps          %xmm14,%xmm1
  .byte  65,15,88,204                        // addps         %xmm12,%xmm1
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,222                        // mulps         %xmm6,%xmm11
  .byte  69,15,88,217                        // addps         %xmm9,%xmm11
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,202                        // subps         %xmm2,%xmm9
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,92,230                        // subps         %xmm6,%xmm12
  .byte  68,15,40,238                        // movaps        %xmm6,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  68,15,194,239,2                     // cmpleps       %xmm7,%xmm13
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,88,228                        // addps         %xmm12,%xmm12
  .byte  69,15,92,212                        // subps         %xmm12,%xmm10
  .byte  65,15,84,213                        // andps         %xmm13,%xmm2
  .byte  69,15,85,234                        // andnps        %xmm10,%xmm13
  .byte  65,15,86,213                        // orps          %xmm13,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_sse2
.globl _sk_softlight_sse2
_sk_softlight_sse2:
  .byte  15,41,84,36,232                     // movaps        %xmm2,-0x18(%rsp)
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  69,15,87,228                        // xorps         %xmm12,%xmm12
  .byte  68,15,194,231,1                     // cmpltps       %xmm7,%xmm12
  .byte  68,15,40,212                        // movaps        %xmm4,%xmm10
  .byte  68,15,94,215                        // divps         %xmm7,%xmm10
  .byte  69,15,84,212                        // andps         %xmm12,%xmm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  69,15,92,242                        // subps         %xmm10,%xmm14
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  69,15,40,234                        // movaps        %xmm10,%xmm13
  .byte  65,15,82,194                        // rsqrtps       %xmm10,%xmm0
  .byte  68,15,83,248                        // rcpps         %xmm0,%xmm15
  .byte  69,15,92,250                        // subps         %xmm10,%xmm15
  .byte  69,15,88,210                        // addps         %xmm10,%xmm10
  .byte  69,15,88,210                        // addps         %xmm10,%xmm10
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  69,15,92,217                        // subps         %xmm9,%xmm11
  .byte  68,15,89,216                        // mulps         %xmm0,%xmm11
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,234                        // mulps         %xmm10,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  15,40,204                           // movaps        %xmm4,%xmm1
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  15,88,228                           // addps         %xmm4,%xmm4
  .byte  15,88,228                           // addps         %xmm4,%xmm4
  .byte  15,194,231,2                        // cmpleps       %xmm7,%xmm4
  .byte  68,15,84,236                        // andps         %xmm4,%xmm13
  .byte  65,15,85,231                        // andnps        %xmm15,%xmm4
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  65,15,86,229                        // orps          %xmm13,%xmm4
  .byte  68,15,40,232                        // movaps        %xmm0,%xmm13
  .byte  68,15,92,235                        // subps         %xmm3,%xmm13
  .byte  69,15,89,245                        // mulps         %xmm13,%xmm14
  .byte  68,15,89,239                        // mulps         %xmm7,%xmm13
  .byte  65,15,89,229                        // mulps         %xmm13,%xmm4
  .byte  65,15,88,227                        // addps         %xmm11,%xmm4
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  69,15,40,251                        // movaps        %xmm11,%xmm15
  .byte  15,41,76,36,216                     // movaps        %xmm1,-0x28(%rsp)
  .byte  68,15,89,249                        // mulps         %xmm1,%xmm15
  .byte  69,15,40,233                        // movaps        %xmm9,%xmm13
  .byte  68,15,92,239                        // subps         %xmm7,%xmm13
  .byte  69,15,89,197                        // mulps         %xmm13,%xmm8
  .byte  69,15,88,199                        // addps         %xmm15,%xmm8
  .byte  68,15,88,243                        // addps         %xmm3,%xmm14
  .byte  68,15,89,241                        // mulps         %xmm1,%xmm14
  .byte  15,194,195,2                        // cmpleps       %xmm3,%xmm0
  .byte  68,15,84,240                        // andps         %xmm0,%xmm14
  .byte  15,85,196                           // andnps        %xmm4,%xmm0
  .byte  65,15,86,198                        // orps          %xmm14,%xmm0
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  15,41,108,36,200                    // movaps        %xmm5,-0x38(%rsp)
  .byte  68,15,40,197                        // movaps        %xmm5,%xmm8
  .byte  68,15,94,199                        // divps         %xmm7,%xmm8
  .byte  69,15,84,196                        // andps         %xmm12,%xmm8
  .byte  69,15,40,240                        // movaps        %xmm8,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  65,15,40,230                        // movaps        %xmm14,%xmm4
  .byte  15,89,228                           // mulps         %xmm4,%xmm4
  .byte  65,15,88,230                        // addps         %xmm14,%xmm4
  .byte  69,15,40,248                        // movaps        %xmm8,%xmm15
  .byte  69,15,92,249                        // subps         %xmm9,%xmm15
  .byte  68,15,89,252                        // mulps         %xmm4,%xmm15
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  69,15,92,240                        // subps         %xmm8,%xmm14
  .byte  65,15,82,224                        // rsqrtps       %xmm8,%xmm4
  .byte  15,83,228                           // rcpps         %xmm4,%xmm4
  .byte  65,15,92,224                        // subps         %xmm8,%xmm4
  .byte  69,15,89,194                        // mulps         %xmm10,%xmm8
  .byte  69,15,88,199                        // addps         %xmm15,%xmm8
  .byte  68,15,40,253                        // movaps        %xmm5,%xmm15
  .byte  69,15,88,255                        // addps         %xmm15,%xmm15
  .byte  69,15,88,255                        // addps         %xmm15,%xmm15
  .byte  68,15,194,255,2                     // cmpleps       %xmm7,%xmm15
  .byte  69,15,84,199                        // andps         %xmm15,%xmm8
  .byte  68,15,85,252                        // andnps        %xmm4,%xmm15
  .byte  69,15,86,248                        // orps          %xmm8,%xmm15
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,40,224                        // movaps        %xmm8,%xmm4
  .byte  15,92,227                           // subps         %xmm3,%xmm4
  .byte  68,15,89,244                        // mulps         %xmm4,%xmm14
  .byte  15,89,231                           // mulps         %xmm7,%xmm4
  .byte  68,15,89,252                        // mulps         %xmm4,%xmm15
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  68,15,88,252                        // addps         %xmm4,%xmm15
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  65,15,89,213                        // mulps         %xmm13,%xmm2
  .byte  15,88,212                           // addps         %xmm4,%xmm2
  .byte  68,15,88,243                        // addps         %xmm3,%xmm14
  .byte  68,15,89,245                        // mulps         %xmm5,%xmm14
  .byte  68,15,194,195,2                     // cmpleps       %xmm3,%xmm8
  .byte  69,15,84,240                        // andps         %xmm8,%xmm14
  .byte  69,15,85,199                        // andnps        %xmm15,%xmm8
  .byte  69,15,86,198                        // orps          %xmm14,%xmm8
  .byte  68,15,88,194                        // addps         %xmm2,%xmm8
  .byte  68,15,40,246                        // movaps        %xmm6,%xmm14
  .byte  65,15,40,206                        // movaps        %xmm14,%xmm1
  .byte  15,94,207                           // divps         %xmm7,%xmm1
  .byte  65,15,84,204                        // andps         %xmm12,%xmm1
  .byte  15,40,225                           // movaps        %xmm1,%xmm4
  .byte  65,15,92,225                        // subps         %xmm9,%xmm4
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  15,82,241                           // rsqrtps       %xmm1,%xmm6
  .byte  15,83,246                           // rcpps         %xmm6,%xmm6
  .byte  15,92,241                           // subps         %xmm1,%xmm6
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,89,237                           // mulps         %xmm5,%xmm5
  .byte  15,88,233                           // addps         %xmm1,%xmm5
  .byte  15,89,236                           // mulps         %xmm4,%xmm5
  .byte  68,15,88,213                        // addps         %xmm5,%xmm10
  .byte  65,15,40,238                        // movaps        %xmm14,%xmm5
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,194,207,2                        // cmpleps       %xmm7,%xmm1
  .byte  68,15,84,209                        // andps         %xmm1,%xmm10
  .byte  15,85,206                           // andnps        %xmm6,%xmm1
  .byte  15,40,84,36,232                     // movaps        -0x18(%rsp),%xmm2
  .byte  68,15,89,234                        // mulps         %xmm2,%xmm13
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  65,15,86,202                        // orps          %xmm10,%xmm1
  .byte  15,40,226                           // movaps        %xmm2,%xmm4
  .byte  15,92,227                           // subps         %xmm3,%xmm4
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  15,89,231                           // mulps         %xmm7,%xmm4
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  15,88,204                           // addps         %xmm4,%xmm1
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  65,15,88,229                        // addps         %xmm13,%xmm4
  .byte  68,15,88,203                        // addps         %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,194,211,2                        // cmpleps       %xmm3,%xmm2
  .byte  68,15,84,202                        // andps         %xmm2,%xmm9
  .byte  15,85,209                           // andnps        %xmm1,%xmm2
  .byte  65,15,86,209                        // orps          %xmm9,%xmm2
  .byte  15,88,212                           // addps         %xmm4,%xmm2
  .byte  68,15,89,223                        // mulps         %xmm7,%xmm11
  .byte  65,15,88,219                        // addps         %xmm11,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,100,36,216                    // movaps        -0x28(%rsp),%xmm4
  .byte  15,40,108,36,200                    // movaps        -0x38(%rsp),%xmm5
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_sse2
.globl _sk_clamp_0_sse2
_sk_clamp_0_sse2:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  65,15,95,192                        // maxps         %xmm8,%xmm0
  .byte  65,15,95,200                        // maxps         %xmm8,%xmm1
  .byte  65,15,95,208                        // maxps         %xmm8,%xmm2
  .byte  65,15,95,216                        // maxps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_sse2
.globl _sk_clamp_1_sse2
_sk_clamp_1_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  65,15,93,208                        // minps         %xmm8,%xmm2
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_sse2
.globl _sk_clamp_a_sse2
_sk_clamp_a_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  15,93,195                           // minps         %xmm3,%xmm0
  .byte  15,93,203                           // minps         %xmm3,%xmm1
  .byte  15,93,211                           // minps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_sse2
.globl _sk_set_rgb_sse2
_sk_set_rgb_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_sse2
.globl _sk_swap_rb_sse2
_sk_swap_rb_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_sse2
.globl _sk_swap_sse2
_sk_swap_sse2:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,40,202                        // movaps        %xmm2,%xmm9
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  68,15,40,216                        // movaps        %xmm0,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  65,15,40,234                        // movaps        %xmm10,%xmm5
  .byte  65,15,40,241                        // movaps        %xmm9,%xmm6
  .byte  65,15,40,248                        // movaps        %xmm8,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_sse2
.globl _sk_move_src_dst_sse2
_sk_move_src_dst_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  15,40,251                           // movaps        %xmm3,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_sse2
.globl _sk_move_dst_src_sse2
_sk_move_dst_src_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_sse2
.globl _sk_premul_sse2
_sk_premul_sse2:
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_sse2
.globl _sk_unpremul_sse2
_sk_unpremul_sse2:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,94,203                        // divps         %xmm3,%xmm9
  .byte  68,15,194,195,4                     // cmpneqps      %xmm3,%xmm8
  .byte  69,15,84,193                        // andps         %xmm9,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_sse2
.globl _sk_from_srgb_sse2
_sk_from_srgb_sse2:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  69,15,89,228                        // mulps         %xmm12,%xmm12
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,89,240                        // mulps         %xmm0,%xmm14
  .byte  69,15,88,242                        // addps         %xmm10,%xmm14
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,244                        // mulps         %xmm12,%xmm14
  .byte  69,15,88,243                        // addps         %xmm11,%xmm14
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  65,15,194,196,1                     // cmpltps       %xmm12,%xmm0
  .byte  68,15,84,232                        // andps         %xmm0,%xmm13
  .byte  65,15,85,198                        // andnps        %xmm14,%xmm0
  .byte  65,15,86,197                        // orps          %xmm13,%xmm0
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  68,15,89,233                        // mulps         %xmm1,%xmm13
  .byte  68,15,40,241                        // movaps        %xmm1,%xmm14
  .byte  69,15,89,246                        // mulps         %xmm14,%xmm14
  .byte  69,15,40,249                        // movaps        %xmm9,%xmm15
  .byte  68,15,89,249                        // mulps         %xmm1,%xmm15
  .byte  69,15,88,250                        // addps         %xmm10,%xmm15
  .byte  69,15,89,254                        // mulps         %xmm14,%xmm15
  .byte  69,15,88,251                        // addps         %xmm11,%xmm15
  .byte  65,15,194,204,1                     // cmpltps       %xmm12,%xmm1
  .byte  68,15,84,233                        // andps         %xmm1,%xmm13
  .byte  65,15,85,207                        // andnps        %xmm15,%xmm1
  .byte  65,15,86,205                        // orps          %xmm13,%xmm1
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  68,15,40,234                        // movaps        %xmm2,%xmm13
  .byte  69,15,89,237                        // mulps         %xmm13,%xmm13
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,205                        // mulps         %xmm13,%xmm9
  .byte  69,15,88,203                        // addps         %xmm11,%xmm9
  .byte  65,15,194,212,1                     // cmpltps       %xmm12,%xmm2
  .byte  68,15,84,194                        // andps         %xmm2,%xmm8
  .byte  65,15,85,209                        // andnps        %xmm9,%xmm2
  .byte  65,15,86,208                        // orps          %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_sse2
.globl _sk_to_srgb_sse2
_sk_to_srgb_sse2:
  .byte  68,15,82,192                        // rsqrtps       %xmm0,%xmm8
  .byte  69,15,83,248                        // rcpps         %xmm8,%xmm15
  .byte  69,15,82,232                        // rsqrtps       %xmm8,%xmm13
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,240                        // movaps        %xmm8,%xmm14
  .byte  68,15,89,240                        // mulps         %xmm0,%xmm14
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,89,251                        // mulps         %xmm11,%xmm15
  .byte  69,15,88,252                        // addps         %xmm12,%xmm15
  .byte  69,15,89,234                        // mulps         %xmm10,%xmm13
  .byte  69,15,88,239                        // addps         %xmm15,%xmm13
  .byte  69,15,40,249                        // movaps        %xmm9,%xmm15
  .byte  69,15,93,253                        // minps         %xmm13,%xmm15
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  65,15,194,197,1                     // cmpltps       %xmm13,%xmm0
  .byte  68,15,84,240                        // andps         %xmm0,%xmm14
  .byte  65,15,85,199                        // andnps        %xmm15,%xmm0
  .byte  65,15,86,198                        // orps          %xmm14,%xmm0
  .byte  68,15,82,241                        // rsqrtps       %xmm1,%xmm14
  .byte  69,15,83,254                        // rcpps         %xmm14,%xmm15
  .byte  69,15,82,246                        // rsqrtps       %xmm14,%xmm14
  .byte  69,15,89,251                        // mulps         %xmm11,%xmm15
  .byte  69,15,88,252                        // addps         %xmm12,%xmm15
  .byte  69,15,89,242                        // mulps         %xmm10,%xmm14
  .byte  69,15,88,247                        // addps         %xmm15,%xmm14
  .byte  69,15,40,249                        // movaps        %xmm9,%xmm15
  .byte  69,15,93,254                        // minps         %xmm14,%xmm15
  .byte  69,15,40,240                        // movaps        %xmm8,%xmm14
  .byte  68,15,89,241                        // mulps         %xmm1,%xmm14
  .byte  65,15,194,205,1                     // cmpltps       %xmm13,%xmm1
  .byte  68,15,84,241                        // andps         %xmm1,%xmm14
  .byte  65,15,85,207                        // andnps        %xmm15,%xmm1
  .byte  65,15,86,206                        // orps          %xmm14,%xmm1
  .byte  68,15,82,242                        // rsqrtps       %xmm2,%xmm14
  .byte  69,15,83,254                        // rcpps         %xmm14,%xmm15
  .byte  69,15,89,251                        // mulps         %xmm11,%xmm15
  .byte  69,15,88,252                        // addps         %xmm12,%xmm15
  .byte  69,15,82,222                        // rsqrtps       %xmm14,%xmm11
  .byte  69,15,89,218                        // mulps         %xmm10,%xmm11
  .byte  69,15,88,223                        // addps         %xmm15,%xmm11
  .byte  69,15,93,203                        // minps         %xmm11,%xmm9
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  65,15,194,213,1                     // cmpltps       %xmm13,%xmm2
  .byte  68,15,84,194                        // andps         %xmm2,%xmm8
  .byte  65,15,85,209                        // andnps        %xmm9,%xmm2
  .byte  65,15,86,208                        // orps          %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_2dot2_sse2
.globl _sk_from_2dot2_sse2
_sk_from_2dot2_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  65,15,82,192                        // rsqrtps       %xmm8,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  68,15,82,200                        // rsqrtps       %xmm0,%xmm9
  .byte  65,15,82,193                        // rsqrtps       %xmm9,%xmm0
  .byte  68,15,82,208                        // rsqrtps       %xmm0,%xmm10
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  65,15,95,194                        // maxps         %xmm10,%xmm0
  .byte  68,15,82,193                        // rsqrtps       %xmm1,%xmm8
  .byte  69,15,82,192                        // rsqrtps       %xmm8,%xmm8
  .byte  69,15,82,192                        // rsqrtps       %xmm8,%xmm8
  .byte  69,15,82,200                        // rsqrtps       %xmm8,%xmm9
  .byte  69,15,82,193                        // rsqrtps       %xmm9,%xmm8
  .byte  69,15,82,216                        // rsqrtps       %xmm8,%xmm11
  .byte  15,89,201                           // mulps         %xmm1,%xmm1
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  69,15,89,195                        // mulps         %xmm11,%xmm8
  .byte  69,15,95,194                        // maxps         %xmm10,%xmm8
  .byte  15,82,202                           // rsqrtps       %xmm2,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  68,15,82,217                        // rsqrtps       %xmm1,%xmm11
  .byte  65,15,82,203                        // rsqrtps       %xmm11,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,89,210                           // mulps         %xmm2,%xmm2
  .byte  69,15,40,203                        // movaps        %xmm11,%xmm9
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,95,202                        // maxps         %xmm10,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_2dot2_sse2
.globl _sk_to_2dot2_sse2
_sk_to_2dot2_sse2:
  .byte  68,15,82,192                        // rsqrtps       %xmm0,%xmm8
  .byte  65,15,82,192                        // rsqrtps       %xmm8,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  68,15,82,200                        // rsqrtps       %xmm0,%xmm9
  .byte  69,15,83,192                        // rcpps         %xmm8,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,83,193                        // rcpps         %xmm9,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  65,15,95,192                        // maxps         %xmm8,%xmm0
  .byte  68,15,82,201                        // rsqrtps       %xmm1,%xmm9
  .byte  65,15,82,201                        // rsqrtps       %xmm9,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  15,82,201                           // rsqrtps       %xmm1,%xmm1
  .byte  68,15,82,209                        // rsqrtps       %xmm1,%xmm10
  .byte  69,15,83,201                        // rcpps         %xmm9,%xmm9
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  65,15,83,202                        // rcpps         %xmm10,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,95,200                        // maxps         %xmm8,%xmm1
  .byte  68,15,82,202                        // rsqrtps       %xmm2,%xmm9
  .byte  65,15,82,209                        // rsqrtps       %xmm9,%xmm2
  .byte  15,82,210                           // rsqrtps       %xmm2,%xmm2
  .byte  15,82,210                           // rsqrtps       %xmm2,%xmm2
  .byte  15,82,210                           // rsqrtps       %xmm2,%xmm2
  .byte  68,15,82,210                        // rsqrtps       %xmm2,%xmm10
  .byte  69,15,83,201                        // rcpps         %xmm9,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  65,15,83,210                        // rcpps         %xmm10,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,95,208                        // maxps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_sse2
.globl _sk_rgb_to_hsl_sse2
_sk_rgb_to_hsl_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  69,15,95,209                        // maxps         %xmm9,%xmm10
  .byte  68,15,95,210                        // maxps         %xmm2,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  69,15,93,217                        // minps         %xmm9,%xmm11
  .byte  68,15,93,218                        // minps         %xmm2,%xmm11
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  65,15,92,203                        // subps         %xmm11,%xmm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,94,225                        // divps         %xmm1,%xmm12
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  65,15,194,192,0                     // cmpeqps       %xmm8,%xmm0
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,194,242,1                     // cmpltps       %xmm2,%xmm14
  .byte  185,0,0,192,64                      // mov           $0x40c00000,%ecx
  .byte  102,68,15,110,233                   // movd          %ecx,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,84,238                        // andps         %xmm14,%xmm13
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,92,242                        // subps         %xmm2,%xmm14
  .byte  69,15,89,244                        // mulps         %xmm12,%xmm14
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  69,15,40,242                        // movaps        %xmm10,%xmm14
  .byte  69,15,194,241,0                     // cmpeqps       %xmm9,%xmm14
  .byte  65,15,92,208                        // subps         %xmm8,%xmm2
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  65,15,89,212                        // mulps         %xmm12,%xmm2
  .byte  185,0,0,0,64                        // mov           $0x40000000,%ecx
  .byte  69,15,89,196                        // mulps         %xmm12,%xmm8
  .byte  184,0,0,128,64                      // mov           $0x40800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,200                        // addps         %xmm8,%xmm9
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  65,15,84,214                        // andps         %xmm14,%xmm2
  .byte  69,15,85,241                        // andnps        %xmm9,%xmm14
  .byte  68,15,86,242                        // orps          %xmm2,%xmm14
  .byte  68,15,84,232                        // andps         %xmm0,%xmm13
  .byte  65,15,85,198                        // andnps        %xmm14,%xmm0
  .byte  102,65,15,110,208                   // movd          %r8d,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,86,197                        // orps          %xmm13,%xmm0
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  69,15,194,203,4                     // cmpneqps      %xmm11,%xmm9
  .byte  65,15,84,193                        // andps         %xmm9,%xmm0
  .byte  15,89,194                           // mulps         %xmm2,%xmm0
  .byte  69,15,92,194                        // subps         %xmm10,%xmm8
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,92,195                        // subps         %xmm11,%xmm8
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,89,212                        // mulps         %xmm12,%xmm2
  .byte  68,15,194,226,1                     // cmpltps       %xmm2,%xmm12
  .byte  69,15,84,196                        // andps         %xmm12,%xmm8
  .byte  69,15,85,226                        // andnps        %xmm10,%xmm12
  .byte  69,15,86,224                        // orps          %xmm8,%xmm12
  .byte  65,15,94,204                        // divps         %xmm12,%xmm1
  .byte  65,15,84,201                        // andps         %xmm9,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_sse2
.globl _sk_hsl_to_rgb_sse2
_sk_hsl_to_rgb_sse2:
  .byte  15,41,124,36,232                    // movaps        %xmm7,-0x18(%rsp)
  .byte  15,41,116,36,216                    // movaps        %xmm6,-0x28(%rsp)
  .byte  15,41,108,36,200                    // movaps        %xmm5,-0x38(%rsp)
  .byte  15,41,100,36,184                    // movaps        %xmm4,-0x48(%rsp)
  .byte  15,41,92,36,168                     // movaps        %xmm3,-0x58(%rsp)
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  15,40,240                           // movaps        %xmm0,%xmm6
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,68,15,110,240                   // movd          %eax,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  69,15,194,206,1                     // cmpltps       %xmm14,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  69,15,87,219                        // xorps         %xmm11,%xmm11
  .byte  68,15,194,218,0                     // cmpeqps       %xmm2,%xmm11
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  65,15,89,218                        // mulps         %xmm10,%xmm3
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  65,15,84,193                        // andps         %xmm9,%xmm0
  .byte  68,15,85,202                        // andnps        %xmm2,%xmm9
  .byte  68,15,86,200                        // orps          %xmm0,%xmm9
  .byte  184,0,0,0,64                        // mov           $0x40000000,%eax
  .byte  185,171,170,170,62                  // mov           $0x3eaaaaab,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,41,68,36,152                  // movaps        %xmm8,-0x68(%rsp)
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  102,15,110,233                      // movd          %ecx,%xmm5
  .byte  15,198,237,0                        // shufps        $0x0,%xmm5,%xmm5
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  65,15,194,192,1                     // cmpltps       %xmm8,%xmm0
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  65,15,92,220                        // subps         %xmm12,%xmm3
  .byte  15,84,216                           // andps         %xmm0,%xmm3
  .byte  65,15,85,192                        // andnps        %xmm8,%xmm0
  .byte  15,86,195                           // orps          %xmm3,%xmm0
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  15,194,221,1                        // cmpltps       %xmm5,%xmm3
  .byte  65,15,40,212                        // movaps        %xmm12,%xmm2
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  15,84,211                           // andps         %xmm3,%xmm2
  .byte  15,85,216                           // andnps        %xmm0,%xmm3
  .byte  15,86,218                           // orps          %xmm2,%xmm3
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,89,234                        // mulps         %xmm10,%xmm13
  .byte  69,15,92,233                        // subps         %xmm9,%xmm13
  .byte  184,171,170,42,62                   // mov           $0x3e2aaaab,%eax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,92,197                        // subps         %xmm13,%xmm0
  .byte  185,0,0,192,64                      // mov           $0x40c00000,%ecx
  .byte  102,68,15,110,249                   // movd          %ecx,%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  68,15,89,248                        // mulps         %xmm0,%xmm15
  .byte  185,171,170,42,63                   // mov           $0x3f2aaaab,%ecx
  .byte  102,15,110,225                      // movd          %ecx,%xmm4
  .byte  15,198,228,0                        // shufps        $0x0,%xmm4,%xmm4
  .byte  15,40,212                           // movaps        %xmm4,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,194,220,1                        // cmpltps       %xmm4,%xmm3
  .byte  65,15,89,215                        // mulps         %xmm15,%xmm2
  .byte  65,15,88,213                        // addps         %xmm13,%xmm2
  .byte  15,84,211                           // andps         %xmm3,%xmm2
  .byte  65,15,85,221                        // andnps        %xmm13,%xmm3
  .byte  15,86,218                           // orps          %xmm2,%xmm3
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,84,208                           // andps         %xmm0,%xmm2
  .byte  15,85,195                           // andnps        %xmm3,%xmm0
  .byte  15,86,194                           // orps          %xmm2,%xmm0
  .byte  102,15,110,248                      // movd          %eax,%xmm7
  .byte  15,198,255,0                        // shufps        $0x0,%xmm7,%xmm7
  .byte  15,194,207,1                        // cmpltps       %xmm7,%xmm1
  .byte  69,15,89,199                        // mulps         %xmm15,%xmm8
  .byte  69,15,88,197                        // addps         %xmm13,%xmm8
  .byte  68,15,84,193                        // andps         %xmm1,%xmm8
  .byte  15,85,200                           // andnps        %xmm0,%xmm1
  .byte  65,15,86,200                        // orps          %xmm8,%xmm1
  .byte  69,15,40,195                        // movaps        %xmm11,%xmm8
  .byte  68,15,85,193                        // andnps        %xmm1,%xmm8
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  15,194,198,1                        // cmpltps       %xmm6,%xmm0
  .byte  15,40,206                           // movaps        %xmm6,%xmm1
  .byte  65,15,92,204                        // subps         %xmm12,%xmm1
  .byte  15,84,200                           // andps         %xmm0,%xmm1
  .byte  15,85,198                           // andnps        %xmm6,%xmm0
  .byte  15,86,193                           // orps          %xmm1,%xmm0
  .byte  15,40,206                           // movaps        %xmm6,%xmm1
  .byte  15,194,205,1                        // cmpltps       %xmm5,%xmm1
  .byte  65,15,40,212                        // movaps        %xmm12,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,84,209                           // andps         %xmm1,%xmm2
  .byte  15,85,200                           // andnps        %xmm0,%xmm1
  .byte  15,86,202                           // orps          %xmm2,%xmm1
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  15,40,217                           // movaps        %xmm1,%xmm3
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  15,194,204,1                        // cmpltps       %xmm4,%xmm1
  .byte  65,15,89,199                        // mulps         %xmm15,%xmm0
  .byte  65,15,88,197                        // addps         %xmm13,%xmm0
  .byte  15,84,193                           // andps         %xmm1,%xmm0
  .byte  65,15,85,205                        // andnps        %xmm13,%xmm1
  .byte  15,86,200                           // orps          %xmm0,%xmm1
  .byte  65,15,194,214,1                     // cmpltps       %xmm14,%xmm2
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,84,194                           // andps         %xmm2,%xmm0
  .byte  15,85,209                           // andnps        %xmm1,%xmm2
  .byte  15,86,208                           // orps          %xmm0,%xmm2
  .byte  15,194,223,1                        // cmpltps       %xmm7,%xmm3
  .byte  65,15,40,199                        // movaps        %xmm15,%xmm0
  .byte  15,89,198                           // mulps         %xmm6,%xmm0
  .byte  65,15,88,197                        // addps         %xmm13,%xmm0
  .byte  15,84,195                           // andps         %xmm3,%xmm0
  .byte  15,85,218                           // andnps        %xmm2,%xmm3
  .byte  15,86,216                           // orps          %xmm0,%xmm3
  .byte  65,15,40,203                        // movaps        %xmm11,%xmm1
  .byte  15,85,203                           // andnps        %xmm3,%xmm1
  .byte  15,92,116,36,152                    // subps         -0x68(%rsp),%xmm6
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,194,197,1                        // cmpltps       %xmm5,%xmm0
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  65,15,92,212                        // subps         %xmm12,%xmm2
  .byte  65,15,40,220                        // movaps        %xmm12,%xmm3
  .byte  68,15,194,230,1                     // cmpltps       %xmm6,%xmm12
  .byte  65,15,84,212                        // andps         %xmm12,%xmm2
  .byte  68,15,85,230                        // andnps        %xmm6,%xmm12
  .byte  68,15,86,226                        // orps          %xmm2,%xmm12
  .byte  15,88,222                           // addps         %xmm6,%xmm3
  .byte  15,84,216                           // andps         %xmm0,%xmm3
  .byte  65,15,85,196                        // andnps        %xmm12,%xmm0
  .byte  15,86,195                           // orps          %xmm3,%xmm0
  .byte  15,40,232                           // movaps        %xmm0,%xmm5
  .byte  15,194,239,1                        // cmpltps       %xmm7,%xmm5
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,194,212,1                        // cmpltps       %xmm4,%xmm2
  .byte  15,92,224                           // subps         %xmm0,%xmm4
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  65,15,89,247                        // mulps         %xmm15,%xmm6
  .byte  65,15,89,231                        // mulps         %xmm15,%xmm4
  .byte  65,15,88,245                        // addps         %xmm13,%xmm6
  .byte  65,15,88,229                        // addps         %xmm13,%xmm4
  .byte  15,84,226                           // andps         %xmm2,%xmm4
  .byte  65,15,85,213                        // andnps        %xmm13,%xmm2
  .byte  15,86,212                           // orps          %xmm4,%xmm2
  .byte  68,15,84,200                        // andps         %xmm0,%xmm9
  .byte  15,85,194                           // andnps        %xmm2,%xmm0
  .byte  65,15,86,193                        // orps          %xmm9,%xmm0
  .byte  15,84,245                           // andps         %xmm5,%xmm6
  .byte  15,85,232                           // andnps        %xmm0,%xmm5
  .byte  15,86,238                           // orps          %xmm6,%xmm5
  .byte  69,15,84,211                        // andps         %xmm11,%xmm10
  .byte  68,15,85,221                        // andnps        %xmm5,%xmm11
  .byte  69,15,86,194                        // orps          %xmm10,%xmm8
  .byte  65,15,86,202                        // orps          %xmm10,%xmm1
  .byte  69,15,86,211                        // orps          %xmm11,%xmm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,40,92,36,168                     // movaps        -0x58(%rsp),%xmm3
  .byte  15,40,100,36,184                    // movaps        -0x48(%rsp),%xmm4
  .byte  15,40,108,36,200                    // movaps        -0x38(%rsp),%xmm5
  .byte  15,40,116,36,216                    // movaps        -0x28(%rsp),%xmm6
  .byte  15,40,124,36,232                    // movaps        -0x18(%rsp),%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_sse2
.globl _sk_scale_1_float_sse2
_sk_scale_1_float_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_sse2
.globl _sk_scale_u8_sse2
_sk_scale_u8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,110,4,56                  // movd          (%rax,%rdi,1),%xmm8
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,69,15,96,193                    // punpcklbw     %xmm9,%xmm8
  .byte  102,69,15,97,193                    // punpcklwd     %xmm9,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_1_float_sse2
.globl _sk_lerp_1_float_sse2
_sk_lerp_1_float_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_sse2
.globl _sk_lerp_u8_sse2
_sk_lerp_u8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,110,4,56                  // movd          (%rax,%rdi,1),%xmm8
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,69,15,96,193                    // punpcklbw     %xmm9,%xmm8
  .byte  102,69,15,97,193                    // punpcklwd     %xmm9,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_565_sse2
.globl _sk_lerp_565_sse2
_sk_lerp_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,68,15,126,4,120                 // movq          (%rax,%rdi,2),%xmm8
  .byte  102,15,239,219                      // pxor          %xmm3,%xmm3
  .byte  102,68,15,97,195                    // punpcklwd     %xmm3,%xmm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,203                        // mulps         %xmm11,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_sse2
.globl _sk_load_tables_sse2
_sk_load_tables_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  243,68,15,111,4,185                 // movdqu        (%rcx,%rdi,4),%xmm8
  .byte  185,255,0,0,0                       // mov           $0xff,%ecx
  .byte  102,15,110,193                      // movd          %ecx,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,65,15,114,209,8                 // psrld         $0x8,%xmm9
  .byte  102,68,15,219,200                   // pand          %xmm0,%xmm9
  .byte  102,69,15,111,208                   // movdqa        %xmm8,%xmm10
  .byte  102,65,15,114,210,16                // psrld         $0x10,%xmm10
  .byte  102,68,15,219,208                   // pand          %xmm0,%xmm10
  .byte  102,65,15,219,192                   // pand          %xmm8,%xmm0
  .byte  102,15,112,216,78                   // pshufd        $0x4e,%xmm0,%xmm3
  .byte  102,72,15,126,217                   // movq          %xmm3,%rcx
  .byte  65,137,201                          // mov           %ecx,%r9d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,194                   // movq          %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  243,67,15,16,28,144                 // movss         (%r8,%r10,4),%xmm3
  .byte  243,65,15,16,4,136                  // movss         (%r8,%rcx,4),%xmm0
  .byte  15,20,216                           // unpcklps      %xmm0,%xmm3
  .byte  243,67,15,16,4,152                  // movss         (%r8,%r11,4),%xmm0
  .byte  243,67,15,16,12,136                 // movss         (%r8,%r9,4),%xmm1
  .byte  15,20,193                           // unpcklps      %xmm1,%xmm0
  .byte  15,20,195                           // unpcklps      %xmm3,%xmm0
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  102,65,15,112,201,78                // pshufd        $0x4e,%xmm9,%xmm1
  .byte  102,73,15,126,202                   // movq          %xmm1,%r10
  .byte  77,137,209                          // mov           %r10,%r9
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  102,76,15,126,201                   // movq          %xmm9,%rcx
  .byte  65,137,203                          // mov           %ecx,%r11d
  .byte  65,129,227,255,255,255,0            // and           $0xffffff,%r11d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  65,129,226,255,255,255,0            // and           $0xffffff,%r10d
  .byte  243,65,15,16,28,8                   // movss         (%r8,%rcx,1),%xmm3
  .byte  243,67,15,16,12,136                 // movss         (%r8,%r9,4),%xmm1
  .byte  15,20,217                           // unpcklps      %xmm1,%xmm3
  .byte  243,67,15,16,12,152                 // movss         (%r8,%r11,4),%xmm1
  .byte  243,67,15,16,20,144                 // movss         (%r8,%r10,4),%xmm2
  .byte  15,20,202                           // unpcklps      %xmm2,%xmm1
  .byte  15,20,203                           // unpcklps      %xmm3,%xmm1
  .byte  76,139,72,24                        // mov           0x18(%rax),%r9
  .byte  102,65,15,112,210,78                // pshufd        $0x4e,%xmm10,%xmm2
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  68,15,183,193                       // movzwl        %cx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,76,15,126,208                   // movq          %xmm10,%rax
  .byte  68,15,183,208                       // movzwl        %ax,%r10d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  243,69,15,16,12,1                   // movss         (%r9,%rax,1),%xmm9
  .byte  243,65,15,16,20,137                 // movss         (%r9,%rcx,4),%xmm2
  .byte  68,15,20,202                        // unpcklps      %xmm2,%xmm9
  .byte  243,67,15,16,20,145                 // movss         (%r9,%r10,4),%xmm2
  .byte  243,67,15,16,28,129                 // movss         (%r9,%r8,4),%xmm3
  .byte  15,20,211                           // unpcklps      %xmm3,%xmm2
  .byte  65,15,20,209                        // unpcklps      %xmm9,%xmm2
  .byte  102,65,15,114,208,24                // psrld         $0x18,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_sse2
.globl _sk_byte_tables_sse2
_sk_byte_tables_sse2:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  71,15,182,20,22                     // movzbl        (%r14,%r10,1),%r10d
  .byte  67,15,182,28,30                     // movzbl        (%r14,%r11,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,6                       // movzbl        (%r14,%r8,1),%r8d
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,193,0                    // pinsrw        $0x0,%ecx,%xmm0
  .byte  102,15,196,195,1                    // pinsrw        $0x1,%ebx,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,96,193                    // punpcklbw     %xmm9,%xmm0
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,201,78                   // pshufd        $0x4e,%xmm1,%xmm1
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,28,25                     // movzbl        (%r9,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,201,0                    // pinsrw        $0x0,%ecx,%xmm1
  .byte  102,15,196,203,1                    // pinsrw        $0x1,%ebx,%xmm1
  .byte  102,65,15,96,201                    // punpcklbw     %xmm9,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,202                        // mulps         %xmm10,%xmm1
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,126,211                   // movq          %xmm2,%rbx
  .byte  65,137,216                          // mov           %ebx,%r8d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,15,112,210,78                   // pshufd        $0x4e,%xmm2,%xmm2
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,209                            // or            %r10d,%ecx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,28,25                     // movzbl        (%r9,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,195                            // or            %r8d,%ebx
  .byte  102,15,196,211,0                    // pinsrw        $0x0,%ebx,%xmm2
  .byte  102,15,196,209,1                    // pinsrw        $0x1,%ecx,%xmm2
  .byte  102,65,15,96,209                    // punpcklbw     %xmm9,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,65,15,91,216                    // cvtps2dq      %xmm8,%xmm3
  .byte  102,72,15,126,217                   // movq          %xmm3,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,219,78                   // pshufd        $0x4e,%xmm3,%xmm3
  .byte  102,72,15,126,219                   // movq          %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  70,15,182,12,8                      // movzbl        (%rax,%r9,1),%r9d
  .byte  15,182,28,24                        // movzbl        (%rax,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,203                            // or            %r9d,%ebx
  .byte  70,15,182,4,0                       // movzbl        (%rax,%r8,1),%r8d
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,216,0                    // pinsrw        $0x0,%eax,%xmm3
  .byte  102,15,196,219,1                    // pinsrw        $0x1,%ebx,%xmm3
  .byte  102,65,15,96,217                    // punpcklbw     %xmm9,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,218                        // mulps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_sse2
.globl _sk_byte_tables_rgb_sse2
_sk_byte_tables_rgb_sse2:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  139,72,24                           // mov           0x18(%rax),%ecx
  .byte  255,201                             // dec           %ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  71,15,182,20,22                     // movzbl        (%r14,%r10,1),%r10d
  .byte  67,15,182,28,30                     // movzbl        (%r14,%r11,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,6                       // movzbl        (%r14,%r8,1),%r8d
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,193,0                    // pinsrw        $0x0,%ecx,%xmm0
  .byte  102,15,196,195,1                    // pinsrw        $0x1,%ebx,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,96,193                    // punpcklbw     %xmm9,%xmm0
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,201,78                   // pshufd        $0x4e,%xmm1,%xmm1
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,28,25                     // movzbl        (%r9,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,201,0                    // pinsrw        $0x0,%ecx,%xmm1
  .byte  102,15,196,203,1                    // pinsrw        $0x1,%ebx,%xmm1
  .byte  102,65,15,96,201                    // punpcklbw     %xmm9,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,202                        // mulps         %xmm10,%xmm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,210,78                   // pshufd        $0x4e,%xmm2,%xmm2
  .byte  102,72,15,126,211                   // movq          %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  70,15,182,12,8                      // movzbl        (%rax,%r9,1),%r9d
  .byte  15,182,28,24                        // movzbl        (%rax,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,203                            // or            %r9d,%ebx
  .byte  70,15,182,4,0                       // movzbl        (%rax,%r8,1),%r8d
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,208,0                    // pinsrw        $0x0,%eax,%xmm2
  .byte  102,15,196,211,1                    // pinsrw        $0x1,%ebx,%xmm2
  .byte  102,65,15,96,209                    // punpcklbw     %xmm9,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_sse2
.globl _sk_load_a8_sse2
_sk_load_a8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,110,4,56                     // movd          (%rax,%rdi,1),%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_a8_sse2
.globl _sk_gather_a8_sse2
_sk_gather_a8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,209                            // or            %r10d,%ecx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,192,0                    // pinsrw        $0x0,%eax,%xmm0
  .byte  102,15,196,193,1                    // pinsrw        $0x1,%ecx,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,239,210                      // pxor          %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_sse2
.globl _sk_store_a8_sse2
_sk_store_a8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,69,15,103,192                   // packuswb      %xmm8,%xmm8
  .byte  102,68,15,126,4,56                  // movd          %xmm8,(%rax,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_g8_sse2
.globl _sk_load_g8_sse2
_sk_load_g8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,110,4,56                     // movd          (%rax,%rdi,1),%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_g8_sse2
.globl _sk_gather_g8_sse2
_sk_gather_g8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,209                            // or            %r10d,%ecx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,192,0                    // pinsrw        $0x0,%eax,%xmm0
  .byte  102,15,196,193,1                    // pinsrw        $0x1,%ecx,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_sse2
.globl _sk_gather_i8_sse2
_sk_gather_i8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            1d75 <_sk_gather_i8_sse2+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           1d77 <_sk_gather_i8_sse2+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,203                          // mov           %ecx,%r11d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,28,26                     // movzbl        (%r10,%r11,1),%r11d
  .byte  65,15,182,12,10                     // movzbl        (%r10,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,217                            // or            %r11d,%ecx
  .byte  71,15,182,12,10                     // movzbl        (%r10,%r9,1),%r9d
  .byte  65,15,182,4,2                       // movzbl        (%r10,%rax,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,200                            // or            %r9d,%eax
  .byte  102,15,196,192,0                    // pinsrw        $0x0,%eax,%xmm0
  .byte  102,15,196,193,1                    // pinsrw        $0x1,%ecx,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  68,15,182,200                       // movzbl        %al,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  77,139,64,8                         // mov           0x8(%r8),%r8
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  102,65,15,110,4,8                   // movd          (%r8,%rcx,1),%xmm0
  .byte  102,65,15,110,12,128                // movd          (%r8,%rax,4),%xmm1
  .byte  102,15,98,193                       // punpckldq     %xmm1,%xmm0
  .byte  102,67,15,110,28,144                // movd          (%r8,%r10,4),%xmm3
  .byte  102,67,15,110,12,136                // movd          (%r8,%r9,4),%xmm1
  .byte  102,15,98,217                       // punpckldq     %xmm1,%xmm3
  .byte  102,15,98,216                       // punpckldq     %xmm0,%xmm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,200                      // pand          %xmm0,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,15,219,208                      // pand          %xmm0,%xmm2
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_sse2
.globl _sk_load_565_sse2
_sk_load_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,126,20,120                   // movq          (%rax,%rdi,2),%xmm2
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,15,97,208                       // punpcklwd     %xmm0,%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_565_sse2
.globl _sk_gather_565_sse2
_sk_gather_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,196,20,81,0               // pinsrw        $0x0,(%r9,%r10,2),%xmm2
  .byte  102,65,15,196,20,73,1               // pinsrw        $0x1,(%r9,%rcx,2),%xmm2
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,15,196,209,2                    // pinsrw        $0x2,%ecx,%xmm2
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,15,196,208,3                    // pinsrw        $0x3,%eax,%xmm2
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,15,97,208                       // punpcklwd     %xmm0,%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_sse2
.globl _sk_store_565_sse2
_sk_store_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,248,65                      // mov           $0x41f80000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,11                // pslld         $0xb,%xmm9
  .byte  185,0,0,124,66                      // mov           $0x427c0000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,5                 // pslld         $0x5,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_4444_sse2
.globl _sk_load_4444_sse2
_sk_load_4444_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,68,15,126,12,120                // movq          (%rax,%rdi,2),%xmm9
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,68,15,97,200                    // punpcklwd     %xmm0,%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_4444_sse2
.globl _sk_gather_4444_sse2
_sk_gather_4444_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,71,15,196,12,81,0               // pinsrw        $0x0,(%r9,%r10,2),%xmm9
  .byte  102,69,15,196,12,73,1               // pinsrw        $0x1,(%r9,%rcx,2),%xmm9
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,68,15,196,201,2                 // pinsrw        $0x2,%ecx,%xmm9
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,68,15,196,200,3                 // pinsrw        $0x3,%eax,%xmm9
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,68,15,97,200                    // punpcklwd     %xmm0,%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_sse2
.globl _sk_store_4444_sse2
_sk_store_4444_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,112,65                      // mov           $0x41700000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,12                // pslld         $0xc,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,4                 // pslld         $0x4,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,193                    // orpd          %xmm9,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_8888_sse2
.globl _sk_load_8888_sse2
_sk_load_8888_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,28,184                   // movdqu        (%rax,%rdi,4),%xmm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,200                      // pand          %xmm0,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,15,219,208                      // pand          %xmm0,%xmm2
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_8888_sse2
.globl _sk_gather_8888_sse2
_sk_gather_8888_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,65,15,110,4,137                 // movd          (%r9,%rcx,4),%xmm0
  .byte  102,65,15,110,12,129                // movd          (%r9,%rax,4),%xmm1
  .byte  102,15,98,193                       // punpckldq     %xmm1,%xmm0
  .byte  102,67,15,110,28,145                // movd          (%r9,%r10,4),%xmm3
  .byte  102,67,15,110,12,129                // movd          (%r9,%r8,4),%xmm1
  .byte  102,15,98,217                       // punpckldq     %xmm1,%xmm3
  .byte  102,15,98,216                       // punpckldq     %xmm0,%xmm3
  .byte  184,255,0,0,0                       // mov           $0xff,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,200                      // pand          %xmm0,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,15,219,208                      // pand          %xmm0,%xmm2
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_sse2
.globl _sk_store_8888_sse2
_sk_store_8888_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,24                // pslld         $0x18,%xmm8
  .byte  102,69,15,235,193                   // por           %xmm9,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  243,68,15,127,4,184                 // movdqu        %xmm8,(%rax,%rdi,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f16_sse2
.globl _sk_load_f16_sse2
_sk_load_f16_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,68,15,111,192                   // movdqa        %xmm0,%xmm8
  .byte  102,68,15,97,193                    // punpcklwd     %xmm1,%xmm8
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,65,15,111,200                   // movdqa        %xmm8,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,68,15,105,192                   // punpckhwd     %xmm0,%xmm8
  .byte  184,0,4,0,4                         // mov           $0x4000400,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,216,0                    // pshufd        $0x0,%xmm0,%xmm3
  .byte  102,15,111,195                      // movdqa        %xmm3,%xmm0
  .byte  102,15,101,193                      // pcmpgtw       %xmm1,%xmm0
  .byte  102,15,223,193                      // pandn         %xmm1,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  102,15,114,240,13                   // pslld         $0xd,%xmm0
  .byte  184,0,0,128,119                     // mov           $0x77800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,68,15,112,210,0                 // pshufd        $0x0,%xmm2,%xmm10
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  102,15,112,209,78                   // pshufd        $0x4e,%xmm1,%xmm2
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,101,202                      // pcmpgtw       %xmm2,%xmm1
  .byte  102,15,223,202                      // pandn         %xmm2,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  102,15,114,241,13                   // pslld         $0xd,%xmm1
  .byte  65,15,89,202                        // mulps         %xmm10,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,65,15,101,208                   // pcmpgtw       %xmm8,%xmm2
  .byte  102,65,15,223,208                   // pandn         %xmm8,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  102,15,114,242,13                   // pslld         $0xd,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  102,69,15,112,192,78                // pshufd        $0x4e,%xmm8,%xmm8
  .byte  102,65,15,101,216                   // pcmpgtw       %xmm8,%xmm3
  .byte  102,65,15,223,216                   // pandn         %xmm8,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  102,15,114,243,13                   // pslld         $0xd,%xmm3
  .byte  65,15,89,218                        // mulps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_f16_sse2
.globl _sk_gather_f16_sse2
_sk_gather_f16_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,65,15,126,4,201                 // movq          (%r9,%rcx,8),%xmm0
  .byte  243,67,15,126,12,209                // movq          (%r9,%r10,8),%xmm1
  .byte  102,15,108,200                      // punpcklqdq    %xmm0,%xmm1
  .byte  243,65,15,126,4,193                 // movq          (%r9,%rax,8),%xmm0
  .byte  243,67,15,126,20,193                // movq          (%r9,%r8,8),%xmm2
  .byte  102,15,108,208                      // punpcklqdq    %xmm0,%xmm2
  .byte  102,68,15,111,193                   // movdqa        %xmm1,%xmm8
  .byte  102,68,15,97,194                    // punpcklwd     %xmm2,%xmm8
  .byte  102,15,105,202                      // punpckhwd     %xmm2,%xmm1
  .byte  102,65,15,111,208                   // movdqa        %xmm8,%xmm2
  .byte  102,15,97,209                       // punpcklwd     %xmm1,%xmm2
  .byte  102,68,15,105,193                   // punpckhwd     %xmm1,%xmm8
  .byte  184,0,4,0,4                         // mov           $0x4000400,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,216,0                    // pshufd        $0x0,%xmm0,%xmm3
  .byte  102,15,111,195                      // movdqa        %xmm3,%xmm0
  .byte  102,15,101,194                      // pcmpgtw       %xmm2,%xmm0
  .byte  102,15,223,194                      // pandn         %xmm2,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  102,15,114,240,13                   // pslld         $0xd,%xmm0
  .byte  184,0,0,128,119                     // mov           $0x77800000,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,68,15,112,209,0                 // pshufd        $0x0,%xmm1,%xmm10
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  102,15,112,210,78                   // pshufd        $0x4e,%xmm2,%xmm2
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,101,202                      // pcmpgtw       %xmm2,%xmm1
  .byte  102,15,223,202                      // pandn         %xmm2,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  102,15,114,241,13                   // pslld         $0xd,%xmm1
  .byte  65,15,89,202                        // mulps         %xmm10,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,65,15,101,208                   // pcmpgtw       %xmm8,%xmm2
  .byte  102,65,15,223,208                   // pandn         %xmm8,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  102,15,114,242,13                   // pslld         $0xd,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  102,69,15,112,192,78                // pshufd        $0x4e,%xmm8,%xmm8
  .byte  102,65,15,101,216                   // pcmpgtw       %xmm8,%xmm3
  .byte  102,65,15,223,216                   // pandn         %xmm8,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  102,15,114,243,13                   // pslld         $0xd,%xmm3
  .byte  65,15,89,218                        // mulps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_sse2
.globl _sk_store_f16_sse2
_sk_store_f16_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,128,7                       // mov           $0x7800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  102,69,15,112,200,0                 // pshufd        $0x0,%xmm8,%xmm9
  .byte  102,69,15,111,193                   // movdqa        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,65,15,114,208,13                // psrld         $0xd,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,69,15,111,209                   // movdqa        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,65,15,114,210,13                // psrld         $0xd,%xmm10
  .byte  102,65,15,114,242,16                // pslld         $0x10,%xmm10
  .byte  102,65,15,114,226,16                // psrad         $0x10,%xmm10
  .byte  102,69,15,107,210                   // packssdw      %xmm10,%xmm10
  .byte  102,69,15,111,217                   // movdqa        %xmm9,%xmm11
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  102,65,15,114,211,13                // psrld         $0xd,%xmm11
  .byte  102,65,15,114,243,16                // pslld         $0x10,%xmm11
  .byte  102,65,15,114,227,16                // psrad         $0x10,%xmm11
  .byte  102,69,15,107,219                   // packssdw      %xmm11,%xmm11
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  102,65,15,114,209,13                // psrld         $0xd,%xmm9
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  102,65,15,114,225,16                // psrad         $0x10,%xmm9
  .byte  102,69,15,107,201                   // packssdw      %xmm9,%xmm9
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,97,217                    // punpcklwd     %xmm9,%xmm11
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,203                    // punpckldq     %xmm11,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,195                   // punpckhdq     %xmm11,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_u16_be_sse2
.globl _sk_load_u16_be_sse2
_sk_load_u16_be_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,15,111,208                      // movdqa        %xmm0,%xmm2
  .byte  102,15,97,209                       // punpcklwd     %xmm1,%xmm2
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,15,111,202                      // movdqa        %xmm2,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,15,105,208                      // punpckhwd     %xmm0,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,15,113,240,8                    // psllw         $0x8,%xmm0
  .byte  102,15,112,217,78                   // pshufd        $0x4e,%xmm1,%xmm3
  .byte  102,15,113,209,8                    // psrlw         $0x8,%xmm1
  .byte  102,15,235,200                      // por           %xmm0,%xmm1
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  15,91,193                           // cvtdq2ps      %xmm1,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,15,235,217                      // por           %xmm1,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  15,91,203                           // cvtdq2ps      %xmm3,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,68,15,111,210                   // movdqa        %xmm2,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,15,112,218,78                   // pshufd        $0x4e,%xmm2,%xmm3
  .byte  102,15,113,210,8                    // psrlw         $0x8,%xmm2
  .byte  102,65,15,235,210                   // por           %xmm10,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,68,15,111,211                   // movdqa        %xmm3,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,65,15,235,218                   // por           %xmm10,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_u16_be_sse2
.globl _sk_store_u16_be_sse2
_sk_store_u16_be_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,255,127,71                    // mov           $0x477fff00,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,69,15,111,208                   // movdqa        %xmm8,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,65,15,113,208,8                 // psrlw         $0x8,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,16                // pslld         $0x10,%xmm10
  .byte  102,65,15,114,226,16                // psrad         $0x10,%xmm10
  .byte  102,69,15,107,210                   // packssdw      %xmm10,%xmm10
  .byte  102,69,15,111,218                   // movdqa        %xmm10,%xmm11
  .byte  102,65,15,113,243,8                 // psllw         $0x8,%xmm11
  .byte  102,65,15,113,210,8                 // psrlw         $0x8,%xmm10
  .byte  102,69,15,235,211                   // por           %xmm11,%xmm10
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  102,69,15,91,219                    // cvtps2dq      %xmm11,%xmm11
  .byte  102,65,15,114,243,16                // pslld         $0x10,%xmm11
  .byte  102,65,15,114,227,16                // psrad         $0x10,%xmm11
  .byte  102,69,15,107,219                   // packssdw      %xmm11,%xmm11
  .byte  102,69,15,111,227                   // movdqa        %xmm11,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,211,8                 // psrlw         $0x8,%xmm11
  .byte  102,69,15,235,220                   // por           %xmm12,%xmm11
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  102,65,15,114,225,16                // psrad         $0x10,%xmm9
  .byte  102,69,15,107,201                   // packssdw      %xmm9,%xmm9
  .byte  102,69,15,111,225                   // movdqa        %xmm9,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,209,8                 // psrlw         $0x8,%xmm9
  .byte  102,69,15,235,204                   // por           %xmm12,%xmm9
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,97,217                    // punpcklwd     %xmm9,%xmm11
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,203                    // punpckldq     %xmm11,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,195                   // punpckhdq     %xmm11,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f32_sse2
.globl _sk_load_f32_sse2
_sk_load_f32_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,16,4,8                        // movups        (%rax,%rcx,1),%xmm8
  .byte  15,16,68,8,16                       // movups        0x10(%rax,%rcx,1),%xmm0
  .byte  15,16,92,8,32                       // movups        0x20(%rax,%rcx,1),%xmm3
  .byte  68,15,16,76,8,48                    // movups        0x30(%rax,%rcx,1),%xmm9
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,20,208                           // unpcklps      %xmm0,%xmm2
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  65,15,20,201                        // unpcklps      %xmm9,%xmm1
  .byte  68,15,21,192                        // unpckhps      %xmm0,%xmm8
  .byte  65,15,21,217                        // unpckhps      %xmm9,%xmm3
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,15,20,193                       // unpcklpd      %xmm1,%xmm0
  .byte  15,18,202                           // movhlps       %xmm2,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  102,15,20,211                       // unpcklpd      %xmm3,%xmm2
  .byte  65,15,18,216                        // movhlps       %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f32_sse2
.globl _sk_store_f32_sse2
_sk_store_f32_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  68,15,20,201                        // unpcklps      %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,40,218                        // movaps        %xmm2,%xmm11
  .byte  68,15,20,219                        // unpcklps      %xmm3,%xmm11
  .byte  68,15,21,193                        // unpckhps      %xmm1,%xmm8
  .byte  68,15,21,211                        // unpckhps      %xmm3,%xmm10
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  102,69,15,20,227                    // unpcklpd      %xmm11,%xmm12
  .byte  69,15,18,217                        // movhlps       %xmm9,%xmm11
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  102,69,15,20,202                    // unpcklpd      %xmm10,%xmm9
  .byte  69,15,18,208                        // movhlps       %xmm8,%xmm10
  .byte  102,68,15,17,36,8                   // movupd        %xmm12,(%rax,%rcx,1)
  .byte  68,15,17,92,8,16                    // movups        %xmm11,0x10(%rax,%rcx,1)
  .byte  102,68,15,17,76,8,32                // movupd        %xmm9,0x20(%rax,%rcx,1)
  .byte  68,15,17,84,8,48                    // movups        %xmm10,0x30(%rax,%rcx,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_x_sse2
.globl _sk_clamp_x_sse2
_sk_clamp_x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,192                        // maxps         %xmm0,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,192                      // pcmpeqd       %xmm0,%xmm0
  .byte  102,65,15,254,193                   // paddd         %xmm9,%xmm0
  .byte  68,15,93,192                        // minps         %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_sse2
.globl _sk_clamp_y_sse2
_sk_clamp_y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,193                        // maxps         %xmm1,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,201                      // pcmpeqd       %xmm1,%xmm1
  .byte  102,65,15,254,201                   // paddd         %xmm9,%xmm1
  .byte  68,15,93,193                        // minps         %xmm1,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_sse2
.globl _sk_repeat_x_sse2
_sk_repeat_x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,194,202,1                     // cmpltps       %xmm10,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,84,217                        // andps         %xmm9,%xmm11
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,194                        // subps         %xmm10,%xmm0
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,193                        // minps         %xmm9,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_sse2
.globl _sk_repeat_y_sse2
_sk_repeat_y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,194,202,1                     // cmpltps       %xmm10,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,84,217                        // andps         %xmm9,%xmm11
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,202                        // subps         %xmm10,%xmm1
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,201                        // minps         %xmm9,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_sse2
.globl _sk_mirror_x_sse2
_sk_mirror_x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,92,192                        // subps         %xmm8,%xmm0
  .byte  243,69,15,88,201                    // addss         %xmm9,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,40,208                        // movaps        %xmm0,%xmm10
  .byte  69,15,94,209                        // divps         %xmm9,%xmm10
  .byte  243,69,15,91,218                    // cvttps2dq     %xmm10,%xmm11
  .byte  69,15,91,219                        // cvtdq2ps      %xmm11,%xmm11
  .byte  69,15,194,211,1                     // cmpltps       %xmm11,%xmm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,84,226                        // andps         %xmm10,%xmm12
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  65,15,92,195                        // subps         %xmm11,%xmm0
  .byte  65,15,92,192                        // subps         %xmm8,%xmm0
  .byte  68,15,92,208                        // subps         %xmm0,%xmm10
  .byte  65,15,84,194                        // andps         %xmm10,%xmm0
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,193                        // minps         %xmm9,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_sse2
.globl _sk_mirror_y_sse2
_sk_mirror_y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  243,69,15,88,201                    // addss         %xmm9,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  69,15,94,209                        // divps         %xmm9,%xmm10
  .byte  243,69,15,91,218                    // cvttps2dq     %xmm10,%xmm11
  .byte  69,15,91,219                        // cvtdq2ps      %xmm11,%xmm11
  .byte  69,15,194,211,1                     // cmpltps       %xmm11,%xmm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,84,226                        // andps         %xmm10,%xmm12
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  65,15,92,203                        // subps         %xmm11,%xmm1
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,92,209                        // subps         %xmm1,%xmm10
  .byte  65,15,84,202                        // andps         %xmm10,%xmm1
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,201                        // minps         %xmm9,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_sse2
.globl _sk_luminance_to_alpha_sse2
_sk_luminance_to_alpha_sse2:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  15,88,195                           // addps         %xmm3,%xmm0
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,218                           // mulps         %xmm2,%xmm3
  .byte  15,88,216                           // addps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_sse2
.globl _sk_matrix_2x3_sse2
_sk_matrix_2x3_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,16                  // movss         0x10(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_sse2
.globl _sk_matrix_3x4_sse2
_sk_matrix_3x4_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,36                  // movss         0x24(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_sse2
.globl _sk_matrix_4x5_sse2
_sk_matrix_4x5_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,32                  // movss         0x20(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,48                  // movss         0x30(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,64                 // movss         0x40(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,20                  // movss         0x14(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,36                  // movss         0x24(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,52                  // movss         0x34(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,68                 // movss         0x44(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,56                 // movss         0x38(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,72                 // movss         0x48(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  243,68,15,16,88,12                  // movss         0xc(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,28                  // movss         0x1c(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,60                 // movss         0x3c(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  243,68,15,16,120,76                 // movss         0x4c(%rax),%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,247                        // addps         %xmm15,%xmm14
  .byte  68,15,89,234                        // mulps         %xmm2,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,216                        // mulps         %xmm8,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_sse2
.globl _sk_matrix_perspective_sse2
_sk_matrix_perspective_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,68,15,16,72,4                   // movss         0x4(%rax),%xmm9
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  243,68,15,16,80,24                  // movss         0x18(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,83,202                        // rcpps         %xmm10,%xmm1
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_sse2
.globl _sk_linear_gradient_sse2
_sk_linear_gradient_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,72,16                  // movss         0x10(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,20                  // movss         0x14(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,28                  // movss         0x1c(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,132,15,1,0,0                     // je            30a0 <_sk_linear_gradient_sse2+0x149>
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  243,68,15,16,112,224                // movss         -0x20(%rax),%xmm14
  .byte  243,68,15,16,104,228                // movss         -0x1c(%rax),%xmm13
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  69,15,40,252                        // movaps        %xmm12,%xmm15
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  69,15,194,230,1                     // cmpltps       %xmm14,%xmm12
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,196                        // andps         %xmm12,%xmm8
  .byte  69,15,86,198                        // orps          %xmm14,%xmm8
  .byte  243,68,15,16,104,232                // movss         -0x18(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  65,15,84,204                        // andps         %xmm12,%xmm1
  .byte  65,15,86,206                        // orps          %xmm14,%xmm1
  .byte  243,68,15,16,104,236                // movss         -0x14(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  65,15,84,212                        // andps         %xmm12,%xmm2
  .byte  65,15,86,214                        // orps          %xmm14,%xmm2
  .byte  243,68,15,16,104,240                // movss         -0x10(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  65,15,84,220                        // andps         %xmm12,%xmm3
  .byte  65,15,86,222                        // orps          %xmm14,%xmm3
  .byte  243,68,15,16,104,244                // movss         -0xc(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,204                        // andps         %xmm12,%xmm9
  .byte  69,15,86,206                        // orps          %xmm14,%xmm9
  .byte  243,68,15,16,104,248                // movss         -0x8(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,212                        // andps         %xmm12,%xmm10
  .byte  69,15,86,214                        // orps          %xmm14,%xmm10
  .byte  243,68,15,16,104,252                // movss         -0x4(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,220                        // andps         %xmm12,%xmm11
  .byte  69,15,86,222                        // orps          %xmm14,%xmm11
  .byte  243,68,15,16,40                     // movss         (%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,84,252                        // andps         %xmm12,%xmm15
  .byte  69,15,85,229                        // andnps        %xmm13,%xmm12
  .byte  69,15,86,231                        // orps          %xmm15,%xmm12
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  72,255,201                          // dec           %rcx
  .byte  15,133,8,255,255,255                // jne           2fa6 <_sk_linear_gradient_sse2+0x4f>
  .byte  235,13                              // jmp           30ad <_sk_linear_gradient_sse2+0x156>
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  15,89,200                           // mulps         %xmm0,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  15,89,208                           // mulps         %xmm0,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  65,15,88,220                        // addps         %xmm12,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_sse2
.globl _sk_linear_gradient_2stops_sse2
_sk_linear_gradient_2stops_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,15,16,80,16                     // movss         0x10(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,20                     // movss         0x14(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,24                     // movss         0x18(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,211                           // addps         %xmm3,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  243,68,15,16,72,28                  // movss         0x1c(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_sse2
.globl _sk_save_xy_sse2
_sk_save_xy_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,88,200                        // addps         %xmm0,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  69,15,194,218,1                     // cmpltps       %xmm10,%xmm11
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,225                   // movd          %ecx,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,84,220                        // andps         %xmm12,%xmm11
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  69,15,92,202                        // subps         %xmm10,%xmm9
  .byte  68,15,88,193                        // addps         %xmm1,%xmm8
  .byte  243,69,15,91,208                    // cvttps2dq     %xmm8,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  69,15,194,218,1                     // cmpltps       %xmm10,%xmm11
  .byte  69,15,84,220                        // andps         %xmm12,%xmm11
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  69,15,92,194                        // subps         %xmm10,%xmm8
  .byte  15,17,0                             // movups        %xmm0,(%rax)
  .byte  15,17,72,32                         // movups        %xmm1,0x20(%rax)
  .byte  68,15,17,72,64                      // movups        %xmm9,0x40(%rax)
  .byte  68,15,17,64,96                      // movups        %xmm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_sse2
.globl _sk_accumulate_sse2
_sk_accumulate_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,15,16,128,128,0,0,0              // movups        0x80(%rax),%xmm8
  .byte  68,15,16,136,160,0,0,0              // movups        0xa0(%rax),%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,88,224                        // addps         %xmm8,%xmm4
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  65,15,88,232                        // addps         %xmm8,%xmm5
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  65,15,88,240                        // addps         %xmm8,%xmm6
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  65,15,88,249                        // addps         %xmm9,%xmm7
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_sse2
.globl _sk_bilinear_nx_sse2
_sk_bilinear_nx_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_sse2
.globl _sk_bilinear_px_sse2
_sk_bilinear_px_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_sse2
.globl _sk_bilinear_ny_sse2
_sk_bilinear_ny_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_sse2
.globl _sk_bilinear_py_sse2
_sk_bilinear_py_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_sse2
.globl _sk_bicubic_n3x_sse2
_sk_bicubic_n3x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_sse2
.globl _sk_bicubic_n1x_sse2
_sk_bicubic_n1x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_sse2
.globl _sk_bicubic_p1x_sse2
_sk_bicubic_p1x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,128,0,0,0              // movups        %xmm10,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_sse2
.globl _sk_bicubic_p3x_sse2
_sk_bicubic_p3x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_sse2
.globl _sk_bicubic_n3y_sse2
_sk_bicubic_n3y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_sse2
.globl _sk_bicubic_n1y_sse2
_sk_bicubic_n1y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_sse2
.globl _sk_bicubic_p1y_sse2
_sk_bicubic_p1y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,160,0,0,0              // movups        %xmm10,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_sse2
.globl _sk_bicubic_p3y_sse2
_sk_bicubic_p3y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
#endif
